/**
 * useAudioOutput - éŸ³é¢‘è¾“å‡ºæ’­æ”¾ç®¡ç†
 *
 * èŒè´£ï¼š
 * - ç®¡ç† AudioContext ç”Ÿå‘½å‘¨æœŸ
 * - æ’­æ”¾æ¥è‡ª Gemini çš„ PCM éŸ³é¢‘
 * - å¤„ç†æ‰“æ–­ï¼ˆåœæ­¢æ’­æ”¾ï¼‰
 *
 * è®¾è®¡å†³ç­–ï¼š
 * - AudioContext å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­åˆ›å»º
 * - æä¾› ensureReady æ–¹æ³•ç”¨äºé¢„åˆå§‹åŒ–
 */

import { useState, useRef, useCallback } from 'react';
import { AudioStreamer } from '../../../lib/audio-streamer';
import { base64ToArrayBuffer, devLog } from '../utils';
import {
  ensureAudioSessionReady,
  resetAudioSessionReady,
  waitForAudioSessionReady,
} from '../../../lib/native-audio-session';

interface UseAudioOutputOptions {
  sampleRate?: number;
  onPlaybackComplete?: () => void;
}

interface UseAudioOutputReturn {
  // State
  isSpeaking: boolean;

  // Actions
  ensureReady: () => Promise<AudioContext>;
  playAudio: (base64Data: string) => void;
  stop: () => void;
  markTurnComplete: () => void;  // æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
  cleanup: () => void;

  // Refs
  audioContextRef: React.MutableRefObject<AudioContext | null>;
  streamerRef: React.MutableRefObject<AudioStreamer | null>;
}

export function useAudioOutput(
  options: UseAudioOutputOptions = {}
): UseAudioOutputReturn {
  const { sampleRate = 24000, onPlaybackComplete } = options;

  // State
  const [isSpeaking, setIsSpeaking] = useState(false);

  // Refs
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamerRef = useRef<AudioStreamer | null>(null);
  /** å¹¶å‘é”ï¼šé˜²æ­¢ camera/mic çš„ toggle å¹¶è¡Œè°ƒç”¨ ensureReady å¯¼è‡´ç«æ€ */
  const ensureReadyPromiseRef = useRef<Promise<AudioContext> | null>(null);

  /**
   * å¸¦è¶…æ—¶çš„ AudioContext.resume()
   * é˜²æ­¢ iOS WebKit ä¸­ resume() æ°¸è¿œä¸è¿”å›çš„ bug
   * @param ctx - è¦ resume çš„ AudioContext
   * @param timeoutMs - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   */
  const resumeWithTimeout = async (ctx: AudioContext, timeoutMs = 3000): Promise<void> => {
    return Promise.race([
      ctx.resume(),
      new Promise<never>((_, reject) =>
        setTimeout(() => reject(new Error(`AudioContext.resume() è¶…æ—¶ (${timeoutMs}ms)`)), timeoutMs)
      ),
    ]);
  };

  /**
   * åˆ›å»ºæ–°çš„ AudioContext å¹¶ç»‘å®š AudioStreamer
   */
  const createAudioContext = (rate: number, completeCb?: () => void): AudioContext => {
    const ctx = new AudioContext({ sampleRate: rate });
    audioContextRef.current = ctx;
    streamerRef.current = new AudioStreamer(ctx);
    if (completeCb) {
      streamerRef.current.onComplete = completeCb;
    }
    return ctx;
  };

  /**
   * ç¡®ä¿ AudioContext å·²å‡†å¤‡å°±ç»ªï¼ˆå†…éƒ¨å®ç°ï¼Œä¸å«å¹¶å‘é”ï¼‰ã€‚
   *
   * ä¸‰å±‚é˜²æŠ¤ + é‡è¯•å¾ªç¯ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰ï¼š
   * 1. å…ˆç­‰å¾… iOS åŸç”ŸéŸ³é¢‘ä¼šè¯å°±ç»ªï¼ˆensureAudioSessionReadyï¼‰
   * 2. åˆ›å»º AudioContext å¹¶ resume
   * 3. å¤±è´¥æ—¶é‡ç½® stale flag â†’ å®é™…ç­‰å¾… iOS äº‹ä»¶ â†’ é‡è¯•
   */
  const ensureReadyInternal = async (): Promise<AudioContext> => {
    const startTime = performance.now();
    const MAX_ATTEMPTS = 3;
    devLog(`ğŸ”Š [ensureReady] å¼€å§‹ | ç°æœ‰ AudioContext çŠ¶æ€: ${audioContextRef.current?.state ?? 'null'}`);

    // ç¬¬ 1 å±‚é˜²æŠ¤ï¼šç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ª
    devLog('ğŸ”Š [ensureReady] ç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ª...');
    await ensureAudioSessionReady();

    for (let attempt = 1; attempt <= MAX_ATTEMPTS; attempt++) {
      devLog(`ğŸ”Š [ensureReady] å°è¯• ${attempt}/${MAX_ATTEMPTS}`);

      // åˆ›å»º AudioContextï¼ˆå¦‚æœéœ€è¦ï¼‰
      if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
        try {
          createAudioContext(sampleRate, onPlaybackComplete);
          devLog(`ğŸ”Š [ensureReady] AudioContext åˆ›å»ºå®Œæˆ, çŠ¶æ€: ${audioContextRef.current!.state}`);
        } catch (createErr) {
          console.error('ğŸ”Š [ensureReady] âŒ AudioContext åˆ›å»ºå¤±è´¥:', createErr);
          throw createErr;
        }
      }

      // å·²ç»åœ¨è¿è¡Œï¼Œç›´æ¥è¿”å›
      if (audioContextRef.current!.state === 'running') {
        const elapsed = performance.now() - startTime;
        devLog(`ğŸ”Š [ensureReady] å·²åœ¨è¿è¡Œ - è€—æ—¶: ${elapsed.toFixed(1)}ms`);
        return audioContextRef.current!;
      }

      // å°è¯• resume
      if (audioContextRef.current!.state === 'suspended') {
        devLog('ğŸ”Š [ensureReady] AudioContext.resume() å¼€å§‹...');
        try {
          await resumeWithTimeout(audioContextRef.current!);
          devLog(`ğŸ”Š [ensureReady] AudioContext.resume() å®Œæˆ, çŠ¶æ€: ${audioContextRef.current!.state}`);
          const elapsed = performance.now() - startTime;
          devLog(`ğŸ”Š [ensureReady] ç»“æŸ - æ€»è€—æ—¶: ${elapsed.toFixed(1)}ms, æœ€ç»ˆçŠ¶æ€: ${audioContextRef.current!.state}`);
          return audioContextRef.current!;
        } catch (resumeErr) {
          console.warn(`ğŸ”Š [ensureReady] âš ï¸ å°è¯• ${attempt} resume() å¤±è´¥:`, resumeErr);

          // é”€æ¯ç ´æŸçš„ AudioContext
          try {
            audioContextRef.current!.close();
          } catch { /* å¿½ç•¥å…³é—­é”™è¯¯ */ }
          audioContextRef.current = null;
          streamerRef.current = null;

          if (attempt < MAX_ATTEMPTS) {
            // é‡ç½® stale flagï¼Œå¼ºåˆ¶ä¸‹æ¬¡å®é™…ç­‰å¾… iOS äº‹ä»¶
            resetAudioSessionReady();
            devLog(`ğŸ”Š [ensureReady] å·²é‡ç½® audio session flagï¼Œç­‰å¾… iOS é‡æ–°å‘é€å°±ç»ªäº‹ä»¶...`);
            await waitForAudioSessionReady(3000);
          } else {
            const elapsed = performance.now() - startTime;
            console.error(`ğŸ”Š [ensureReady] âŒ ${MAX_ATTEMPTS} æ¬¡å°è¯•å‡å¤±è´¥ - æ€»è€—æ—¶: ${elapsed.toFixed(1)}ms`);
            throw resumeErr;
          }
        }
      }
    }

    // ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œï¼Œä½† TypeScript éœ€è¦
    throw new Error('ğŸ”Š [ensureReady] æ„å¤–é€€å‡ºé‡è¯•å¾ªç¯');
  };

  /**
   * ç¡®ä¿ AudioContext å·²å‡†å¤‡å°±ç»ªï¼ˆå¸¦å¹¶å‘é”ï¼‰ã€‚
   * å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ã€‚
   *
   * camera å’Œ mic çš„ toggleCamera/toggleMicrophone å¯èƒ½å¹¶è¡Œè°ƒç”¨æ­¤æ–¹æ³•ï¼Œ
   * ä½¿ç”¨å…±äº« Promise ref é˜²æ­¢é‡å…¥ï¼Œç¬¬äºŒä¸ªè°ƒç”¨å¤ç”¨ç¬¬ä¸€ä¸ªçš„ç»“æœã€‚
   */
  const ensureReady = useCallback(async (): Promise<AudioContext> => {
    // å¹¶å‘é”ï¼šå¦‚æœå·²æœ‰è°ƒç”¨åœ¨è¿›è¡Œä¸­ï¼Œå¤ç”¨å…¶ç»“æœ
    if (ensureReadyPromiseRef.current) {
      devLog('ğŸ”Š [ensureReady] å·²æœ‰å¹¶å‘è°ƒç”¨ï¼Œå¤ç”¨å…¶ç»“æœ');
      return ensureReadyPromiseRef.current;
    }

    const promise = ensureReadyInternal().finally(() => {
      ensureReadyPromiseRef.current = null;
    });
    ensureReadyPromiseRef.current = promise;
    return promise;
  }, [sampleRate, onPlaybackComplete]);

  /**
   * æ’­æ”¾ base64 ç¼–ç çš„ PCM éŸ³é¢‘
   */
  const playAudio = useCallback((base64Data: string) => {
    if (!streamerRef.current || !audioContextRef.current) {
      devLog('âš ï¸ AudioContext not ready, cannot play audio');
      return;
    }

    if (audioContextRef.current.state === 'closed') {
      devLog('âš ï¸ AudioContext is closed, cannot play audio');
      return;
    }

    setIsSpeaking(true);
    const arrayBuffer = base64ToArrayBuffer(base64Data);
    streamerRef.current.addPCM16(new Uint8Array(arrayBuffer));
  }, []);

  /**
   * åœæ­¢æ’­æ”¾ï¼ˆç”¨äºæ‰“æ–­ï¼‰
   */
  const stop = useCallback(() => {
    streamerRef.current?.stop();
    setIsSpeaking(false);
  }, []);

  /**
   * æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
   * å½“ Gemini å‘é€ turnComplete æ—¶è°ƒç”¨
   */
  const markTurnComplete = useCallback(() => {
    setIsSpeaking(false);
  }, []);

  /**
   * æ¸…ç†èµ„æº
   */
  const cleanup = useCallback(() => {
    // åœæ­¢æ’­æ”¾
    streamerRef.current?.stop();
    streamerRef.current = null;

    // å…³é—­ AudioContext
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      devLog('ğŸ”Š AudioContext closed');
    }
    audioContextRef.current = null;

    setIsSpeaking(false);
  }, []);

  return {
    // State
    isSpeaking,

    // Actions
    ensureReady,
    playAudio,
    stop,
    markTurnComplete,
    cleanup,

    // Refs
    audioContextRef,
    streamerRef,
  };
}
