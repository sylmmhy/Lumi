/**
 * useAudioOutput - éŸ³é¢‘è¾“å‡ºæ’­æ”¾ç®¡ç†
 *
 * èŒè´£ï¼š
 * - ç®¡ç† AudioContext ç”Ÿå‘½å‘¨æœŸ
 * - æ’­æ”¾æ¥è‡ª Gemini çš„ PCM éŸ³é¢‘
 * - å¤„ç†æ‰“æ–­ï¼ˆåœæ­¢æ’­æ”¾ï¼‰
 *
 * è®¾è®¡å†³ç­–ï¼š
 * - AudioContext å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­åˆ›å»º
 * - æä¾› ensureReady æ–¹æ³•ç”¨äºé¢„åˆå§‹åŒ–
 */

import { useState, useRef, useCallback } from 'react';
import { AudioStreamer } from '../../../lib/audio-streamer';
import { base64ToArrayBuffer, devLog } from '../utils';

interface UseAudioOutputOptions {
  sampleRate?: number;
  onPlaybackComplete?: () => void;
}

interface UseAudioOutputReturn {
  // State
  isSpeaking: boolean;

  // Actions
  ensureReady: () => Promise<AudioContext>;
  playAudio: (base64Data: string) => void;
  stop: () => void;
  markTurnComplete: () => void;  // æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
  cleanup: () => void;

  // Refs
  audioContextRef: React.MutableRefObject<AudioContext | null>;
  streamerRef: React.MutableRefObject<AudioStreamer | null>;
}

export function useAudioOutput(
  options: UseAudioOutputOptions = {}
): UseAudioOutputReturn {
  const { sampleRate = 24000, onPlaybackComplete } = options;

  // State
  const [isSpeaking, setIsSpeaking] = useState(false);

  // Refs
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamerRef = useRef<AudioStreamer | null>(null);

  /**
   * ç¡®ä¿ AudioContext å·²å‡†å¤‡å°±ç»ª
   * å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨
   */
  const ensureReady = useCallback(async (): Promise<AudioContext> => {
    if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
      audioContextRef.current = new AudioContext({ sampleRate });
      streamerRef.current = new AudioStreamer(audioContextRef.current);

      if (onPlaybackComplete) {
        streamerRef.current.onComplete = onPlaybackComplete;
      }

      devLog('ğŸ”Š AudioContext created:', audioContextRef.current.state);
    }

    if (audioContextRef.current.state === 'suspended') {
      await audioContextRef.current.resume();
      devLog('ğŸ”Š AudioContext resumed:', audioContextRef.current.state);
    }

    return audioContextRef.current;
  }, [sampleRate, onPlaybackComplete]);

  /**
   * æ’­æ”¾ base64 ç¼–ç çš„ PCM éŸ³é¢‘
   */
  const playAudio = useCallback((base64Data: string) => {
    if (!streamerRef.current || !audioContextRef.current) {
      devLog('âš ï¸ AudioContext not ready, cannot play audio');
      return;
    }

    if (audioContextRef.current.state === 'closed') {
      devLog('âš ï¸ AudioContext is closed, cannot play audio');
      return;
    }

    setIsSpeaking(true);
    const arrayBuffer = base64ToArrayBuffer(base64Data);
    streamerRef.current.addPCM16(new Uint8Array(arrayBuffer));
  }, []);

  /**
   * åœæ­¢æ’­æ”¾ï¼ˆç”¨äºæ‰“æ–­ï¼‰
   */
  const stop = useCallback(() => {
    streamerRef.current?.stop();
    setIsSpeaking(false);
  }, []);

  /**
   * æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
   * å½“ Gemini å‘é€ turnComplete æ—¶è°ƒç”¨
   */
  const markTurnComplete = useCallback(() => {
    setIsSpeaking(false);
  }, []);

  /**
   * æ¸…ç†èµ„æº
   */
  const cleanup = useCallback(() => {
    // åœæ­¢æ’­æ”¾
    streamerRef.current?.stop();
    streamerRef.current = null;

    // å…³é—­ AudioContext
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      devLog('ğŸ”Š AudioContext closed');
    }
    audioContextRef.current = null;

    setIsSpeaking(false);
  }, []);

  return {
    // State
    isSpeaking,

    // Actions
    ensureReady,
    playAudio,
    stop,
    markTurnComplete,
    cleanup,

    // Refs
    audioContextRef,
    streamerRef,
  };
}
