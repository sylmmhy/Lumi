/**
 * useAudioOutput - éŸ³é¢‘è¾“å‡ºæ’­æ”¾ç®¡ç†
 *
 * èŒè´£ï¼š
 * - ç®¡ç† AudioContext ç”Ÿå‘½å‘¨æœŸ
 * - æ’­æ”¾æ¥è‡ª Gemini çš„ PCM éŸ³é¢‘
 * - å¤„ç†æ‰“æ–­ï¼ˆåœæ­¢æ’­æ”¾ï¼‰
 *
 * è®¾è®¡å†³ç­–ï¼š
 * - AudioContext å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­åˆ›å»º
 * - æä¾› ensureReady æ–¹æ³•ç”¨äºé¢„åˆå§‹åŒ–
 */

import { useState, useRef, useCallback } from 'react';
import { AudioStreamer } from '../../../lib/audio-streamer';
import { base64ToArrayBuffer, devLog } from '../utils';
import { ensureAudioSessionReady } from '../../../lib/native-audio-session';

interface UseAudioOutputOptions {
  sampleRate?: number;
  onPlaybackComplete?: () => void;
}

interface UseAudioOutputReturn {
  // State
  isSpeaking: boolean;

  // Actions
  ensureReady: () => Promise<AudioContext>;
  playAudio: (base64Data: string) => void;
  stop: () => void;
  markTurnComplete: () => void;  // æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
  cleanup: () => void;

  // Refs
  audioContextRef: React.MutableRefObject<AudioContext | null>;
  streamerRef: React.MutableRefObject<AudioStreamer | null>;
}

export function useAudioOutput(
  options: UseAudioOutputOptions = {}
): UseAudioOutputReturn {
  const { sampleRate = 24000, onPlaybackComplete } = options;

  // State
  const [isSpeaking, setIsSpeaking] = useState(false);

  // Refs
  const audioContextRef = useRef<AudioContext | null>(null);
  const streamerRef = useRef<AudioStreamer | null>(null);

  /**
   * å¸¦è¶…æ—¶çš„ AudioContext.resume()
   * é˜²æ­¢ iOS WebKit ä¸­ resume() æ°¸è¿œä¸è¿”å›çš„ bug
   * @param ctx - è¦ resume çš„ AudioContext
   * @param timeoutMs - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   */
  const resumeWithTimeout = async (ctx: AudioContext, timeoutMs = 3000): Promise<void> => {
    return Promise.race([
      ctx.resume(),
      new Promise<never>((_, reject) =>
        setTimeout(() => reject(new Error(`AudioContext.resume() è¶…æ—¶ (${timeoutMs}ms)`)), timeoutMs)
      ),
    ]);
  };

  /**
   * åˆ›å»ºæ–°çš„ AudioContext å¹¶ç»‘å®š AudioStreamer
   */
  const createAudioContext = (rate: number, completeCb?: () => void): AudioContext => {
    const ctx = new AudioContext({ sampleRate: rate });
    audioContextRef.current = ctx;
    streamerRef.current = new AudioStreamer(ctx);
    if (completeCb) {
      streamerRef.current.onComplete = completeCb;
    }
    return ctx;
  };

  /**
   * ç¡®ä¿ AudioContext å·²å‡†å¤‡å°±ç»ª
   * å¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨
   *
   * ä¸¤å±‚é˜²æŠ¤ï¼š
   * 1. å…ˆç­‰å¾… iOS åŸç”ŸéŸ³é¢‘ä¼šè¯å°±ç»ªï¼ˆensureAudioSessionReadyï¼‰
   * 2. ä¸º AudioContext.resume() åŠ è¶…æ—¶ï¼Œè¶…æ—¶åé”€æ¯é‡å»º
   */
  const ensureReady = useCallback(async (): Promise<AudioContext> => {
    const startTime = performance.now();
    devLog(`ğŸ”Š [ensureReady] å¼€å§‹ | ç°æœ‰ AudioContext çŠ¶æ€: ${audioContextRef.current?.state ?? 'null'}`);

    // ç¬¬ 1 å±‚é˜²æŠ¤ï¼šç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ª
    // è§£å†³å¯†ç è§£é”åœºæ™¯ä¸‹ CallKit è¿˜å ç”¨éŸ³é¢‘è®¾å¤‡çš„é—®é¢˜
    devLog('ğŸ”Š [ensureReady] ç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ª...');
    await ensureAudioSessionReady();

    // åˆ›å»º AudioContextï¼ˆå¦‚æœéœ€è¦ï¼‰
    if (!audioContextRef.current || audioContextRef.current.state === 'closed') {
      try {
        createAudioContext(sampleRate, onPlaybackComplete);
        devLog(`ğŸ”Š [ensureReady] AudioContext åˆ›å»ºå®Œæˆ, çŠ¶æ€: ${audioContextRef.current!.state}`);
      } catch (createErr) {
        console.error('ğŸ”Š [ensureReady] âŒ AudioContext åˆ›å»ºå¤±è´¥:', createErr);
        throw createErr;
      }
    }

    // ç¬¬ 2 å±‚é˜²æŠ¤ï¼šresume() åŠ è¶…æ—¶ + é”€æ¯é‡å»º
    if (audioContextRef.current!.state === 'suspended') {
      devLog('ğŸ”Š [ensureReady] AudioContext.resume() å¼€å§‹...');
      try {
        await resumeWithTimeout(audioContextRef.current!);
        devLog(`ğŸ”Š [ensureReady] AudioContext.resume() å®Œæˆ, çŠ¶æ€: ${audioContextRef.current!.state}`);
      } catch (resumeErr) {
        // resume() å¤±è´¥æˆ–è¶…æ—¶ â†’ é”€æ¯æ—§çš„ï¼Œé‡å»ºæ–°çš„
        console.warn('ğŸ”Š [ensureReady] âš ï¸ AudioContext.resume() å¤±è´¥/è¶…æ—¶ï¼Œé”€æ¯é‡å»º...', resumeErr);
        try {
          audioContextRef.current!.close();
        } catch { /* å¿½ç•¥å…³é—­é”™è¯¯ */ }

        // å†æ¬¡ç­‰å¾…éŸ³é¢‘ä¼šè¯å°±ç»ªï¼ˆå¯èƒ½ iOS ç«¯è¿˜åœ¨åˆ‡æ¢ä¸­ï¼‰
        await ensureAudioSessionReady();

        // é‡å»º AudioContext
        createAudioContext(sampleRate, onPlaybackComplete);
        devLog(`ğŸ”Š [ensureReady] é‡å»º AudioContext, çŠ¶æ€: ${audioContextRef.current!.state}`);

        // é‡è¯• resume
        if (audioContextRef.current!.state === 'suspended') {
          try {
            await resumeWithTimeout(audioContextRef.current!);
            devLog(`ğŸ”Š [ensureReady] é‡å»ºå resume() æˆåŠŸ, çŠ¶æ€: ${audioContextRef.current!.state}`);
          } catch (retryErr) {
            console.error('ğŸ”Š [ensureReady] âŒ é‡å»ºå resume() ä»ç„¶å¤±è´¥:', retryErr);
            throw retryErr;
          }
        }
      }
    }

    const totalElapsed = performance.now() - startTime;
    devLog(`ğŸ”Š [ensureReady] ç»“æŸ - æ€»è€—æ—¶: ${totalElapsed.toFixed(1)}ms, æœ€ç»ˆçŠ¶æ€: ${audioContextRef.current!.state}`);

    return audioContextRef.current!;
  }, [sampleRate, onPlaybackComplete]);

  /**
   * æ’­æ”¾ base64 ç¼–ç çš„ PCM éŸ³é¢‘
   */
  const playAudio = useCallback((base64Data: string) => {
    if (!streamerRef.current || !audioContextRef.current) {
      devLog('âš ï¸ AudioContext not ready, cannot play audio');
      return;
    }

    if (audioContextRef.current.state === 'closed') {
      devLog('âš ï¸ AudioContext is closed, cannot play audio');
      return;
    }

    setIsSpeaking(true);
    const arrayBuffer = base64ToArrayBuffer(base64Data);
    streamerRef.current.addPCM16(new Uint8Array(arrayBuffer));
  }, []);

  /**
   * åœæ­¢æ’­æ”¾ï¼ˆç”¨äºæ‰“æ–­ï¼‰
   */
  const stop = useCallback(() => {
    streamerRef.current?.stop();
    setIsSpeaking(false);
  }, []);

  /**
   * æ ‡è®°è½®æ¬¡å®Œæˆï¼ˆåªè®¾ç½®çŠ¶æ€ï¼Œä¸åœæ­¢æ’­æ”¾ï¼‰
   * å½“ Gemini å‘é€ turnComplete æ—¶è°ƒç”¨
   */
  const markTurnComplete = useCallback(() => {
    setIsSpeaking(false);
  }, []);

  /**
   * æ¸…ç†èµ„æº
   */
  const cleanup = useCallback(() => {
    // åœæ­¢æ’­æ”¾
    streamerRef.current?.stop();
    streamerRef.current = null;

    // å…³é—­ AudioContext
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
      devLog('ğŸ”Š AudioContext closed');
    }
    audioContextRef.current = null;

    setIsSpeaking(false);
  }, []);

  return {
    // State
    isSpeaking,

    // Actions
    ensureReady,
    playAudio,
    stop,
    markTurnComplete,
    cleanup,

    // Refs
    audioContextRef,
    streamerRef,
  };
}
