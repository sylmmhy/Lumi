/**
 * useVideoInput - ÊëÑÂÉèÂ§¥ÊçïËé∑ÂíåËßÜÈ¢ëÂ∏ßÂèëÈÄÅ
 *
 * ËÅåË¥£Ôºö
 * - ÁÆ°ÁêÜÊëÑÂÉèÂ§¥ÊùÉÈôêÂíåËÆæÂ§á
 * - ÊçïËé∑ËßÜÈ¢ëÂ∏ßÂπ∂ËΩ¨Êç¢‰∏∫ JPEG base64
 * - ÊåâÊåáÂÆöÂ∏ßÁéáÂèëÈÄÅËßÜÈ¢ëÂ∏ß
 *
 * ËÆæËÆ°ÂÜ≥Á≠ñÔºö
 * - ËßÜÈ¢ëÈ¢ÑËßàÁã¨Á´ã‰∫éËøûÊé•Áä∂ÊÄÅÔºàÂèØ‰ª•ÂÖàÈ¢ÑËßàÂÜçËøûÊé•Ôºâ
 * - ËßÜÈ¢ëÂ∏ßÂèëÈÄÅ‰æùËµñ‰∫éËøûÊé•Áä∂ÊÄÅ
 * - ÈÄöËøá onVideoFrame ÂõûË∞ÉËß£ËÄ¶
 */

import { useState, useRef, useCallback, useEffect } from 'react';
import { DEFAULT_CAMERA_FRAME_RATE, DEFAULT_CAMERA_RESOLUTION } from '../../../constants/media';
import { devLog, devWarn } from '../utils';

interface UseVideoInputOptions {
  frameRate?: number;
  resolution?: { width: number; height: number };
  onVideoFrame?: (base64Jpeg: string) => void;
  onError?: (error: string) => void;
}

interface UseVideoInputReturn {
  // State
  isEnabled: boolean;
  videoStream: MediaStream | null;
  error: string | null;

  // Actions
  start: () => Promise<void>;
  stop: () => void;
  toggle: () => Promise<void>;

  // Refs for UI (MutableRefObject to allow external assignment)
  videoRef: React.MutableRefObject<HTMLVideoElement | null>;
  canvasRef: React.MutableRefObject<HTMLCanvasElement | null>;

  // Control
  startFrameCapture: () => void;
  stopFrameCapture: () => void;
}

export function useVideoInput(
  options: UseVideoInputOptions = {}
): UseVideoInputReturn {
  const {
    frameRate = DEFAULT_CAMERA_FRAME_RATE,
    resolution = DEFAULT_CAMERA_RESOLUTION,
    onVideoFrame,
    onError
  } = options;

  // State
  const [isEnabled, setIsEnabled] = useState(false);
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);

  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const captureTimeoutRef = useRef<number>(-1);
  const isCapturingRef = useRef(false);
  const isStartingRef = useRef(false); // Èò≤Ê≠¢Âπ∂ÂèëÂêØÂä®
  const currentStreamRef = useRef<MediaStream | null>(null); // ËøΩË∏™ÂΩìÂâç stream ‰ª•‰æøÊ∏ÖÁêÜ

  /**
   * ÂêØÂä®ÊëÑÂÉèÂ§¥
   * Ê∑ªÂä†ÂπÇÁ≠âÂÆàÂç´ÔºöÂ¶ÇÊûúÂ∑≤ÂêØÁî®ÊàñÊ≠£Âú®ÂêØÂä®‰∏≠ÔºåÁõ¥Êé•ËøîÂõû
   */
  const start = useCallback(async () => {
    // ÂπÇÁ≠âÂÆàÂç´ÔºöÂ∑≤ÁªèÂêØÁî®
    if (isEnabled) {
      devLog('üìπ Camera already enabled, skipping start');
      return;
    }

    // ÂπÇÁ≠âÂÆàÂç´ÔºöÊ≠£Âú®ÂêØÂä®‰∏≠ÔºàÈò≤Ê≠¢Âπ∂ÂèëË∞ÉÁî®Ôºâ
    if (isStartingRef.current) {
      devLog('üìπ Camera start already in progress, skipping');
      return;
    }

    isStartingRef.current = true;

    try {
      // Â¶ÇÊûúÊúâÊóßÁöÑ streamÔºåÂÖàÂÅúÊ≠¢ÂÆÉÔºàÈò≤Ê≠¢ËµÑÊ∫êÊ≥ÑÊºèÔºâ
      if (currentStreamRef.current) {
        currentStreamRef.current.getTracks().forEach((track) => track.stop());
        currentStreamRef.current = null;
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'user',
          width: { ideal: resolution.width },
          height: { ideal: resolution.height },
        },
      });

      currentStreamRef.current = stream;
      setVideoStream(stream);
      setIsEnabled(true);
      setError(null);

      devLog('üìπ Camera started');
    } catch (err) {
      console.error('Camera error:', err);
      const errorMessage = 'Camera access denied. Please allow camera access in Settings.';
      setError(errorMessage);
      onError?.(errorMessage);
    } finally {
      isStartingRef.current = false;
    }
  }, [isEnabled, resolution, onError]);

  /**
   * ÂÅúÊ≠¢ÊëÑÂÉèÂ§¥
   * Ê∏ÖÁêÜÊâÄÊúâËµÑÊ∫ê
   */
  const stop = useCallback(() => {
    // ÂÅúÊ≠¢ÊâÄÊúâ tracks
    if (currentStreamRef.current) {
      currentStreamRef.current.getTracks().forEach((track) => track.stop());
      currentStreamRef.current = null;
    }
    // ‰πüÂÅúÊ≠¢ state ‰∏≠ÁöÑ streamÔºà‰ª•Èò≤‰∏á‰∏Ä‰∏ç‰∏ÄËá¥Ôºâ
    videoStream?.getTracks().forEach((track) => track.stop());
    setVideoStream(null);
    setIsEnabled(false);

    // ÂÅúÊ≠¢Â∏ßÊçïËé∑
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }
    isCapturingRef.current = false;

    devLog('üìπ Camera stopped');
  }, [videoStream]);

  /**
   * ÂàáÊç¢ÊëÑÂÉèÂ§¥Áä∂ÊÄÅ
   */
  const toggle = useCallback(async () => {
    if (isEnabled) {
      stop();
    } else {
      await start();
    }
  }, [isEnabled, start, stop]);

  /**
   * Â∞ùËØïÊí≠ÊîæËßÜÈ¢ëÈ¢ÑËßà
   */
  const ensureVideoPlayback = useCallback(async (videoElement: HTMLVideoElement) => {
    try {
      const playPromise = videoElement.play();
      if (playPromise) {
        await playPromise;
      }
    } catch (err) {
      devWarn('Camera preview playback failed:', err);
      setError('Camera preview blocked. Please tap the camera button to start playback.');
    }
  }, []);

  /**
   * ËÆæÁΩÆËßÜÈ¢ëÈ¢ÑËßàÔºàÁã¨Á´ã‰∫éËøûÊé•Áä∂ÊÄÅÔºâ
   */
  useEffect(() => {
    if (videoRef.current && videoStream) {
      videoRef.current.srcObject = videoStream;
      void ensureVideoPlayback(videoRef.current);
    }
  }, [videoStream, ensureVideoPlayback]);

  /**
   * ÂèëÈÄÅÂçï‰∏™ËßÜÈ¢ëÂ∏ß
   */
  const sendVideoFrame = useCallback(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;

    if (!video || !canvas || !onVideoFrame) {
      return;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // Áº©Â∞èÂ∞∫ÂØ∏‰ª•ÂáèÂ∞ëÂ∏¶ÂÆΩ
    canvas.width = video.videoWidth * 0.25;
    canvas.height = video.videoHeight * 0.25;

    if (canvas.width + canvas.height > 0) {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const base64 = canvas.toDataURL('image/jpeg', 1.0);
      const data = base64.slice(base64.indexOf(',') + 1);
      onVideoFrame(data);
    }

    // ÁªßÁª≠ÊçïËé∑
    if (isCapturingRef.current && isEnabled) {
      captureTimeoutRef.current = window.setTimeout(
        sendVideoFrame,
        1000 / frameRate
      );
    }
  }, [frameRate, isEnabled, onVideoFrame]);

  /**
   * ÂºÄÂßãËßÜÈ¢ëÂ∏ßÊçïËé∑
   */
  const startFrameCapture = useCallback(() => {
    if (!isEnabled || !videoStream || isCapturingRef.current) return;

    isCapturingRef.current = true;
    requestAnimationFrame(sendVideoFrame);

    devLog('üìπ Frame capture started');
  }, [isEnabled, videoStream, sendVideoFrame]);

  /**
   * ÂÅúÊ≠¢ËßÜÈ¢ëÂ∏ßÊçïËé∑
   */
  const stopFrameCapture = useCallback(() => {
    isCapturingRef.current = false;
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }

    devLog('üìπ Frame capture stopped');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (captureTimeoutRef.current !== -1) {
        clearTimeout(captureTimeoutRef.current);
      }
    };
  }, []);

  return {
    // State
    isEnabled,
    videoStream,
    error,

    // Actions
    start,
    stop,
    toggle,

    // Refs
    videoRef,
    canvasRef,

    // Control
    startFrameCapture,
    stopFrameCapture,
  };
}
