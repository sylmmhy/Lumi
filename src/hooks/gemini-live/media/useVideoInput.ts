/**
 * useVideoInput - æ‘„åƒå¤´æ•è·å’Œè§†é¢‘å¸§å‘é€
 *
 * èŒè´£ï¼š
 * - ç®¡ç†æ‘„åƒå¤´æƒé™å’Œè®¾å¤‡
 * - æ•è·è§†é¢‘å¸§å¹¶è½¬æ¢ä¸º JPEG base64
 * - æŒ‰æŒ‡å®šå¸§ç‡å‘é€è§†é¢‘å¸§
 *
 * è®¾è®¡å†³ç­–ï¼š
 * - è§†é¢‘é¢„è§ˆç‹¬ç«‹äºè¿æ¥çŠ¶æ€ï¼ˆå¯ä»¥å…ˆé¢„è§ˆå†è¿æ¥ï¼‰
 * - è§†é¢‘å¸§å‘é€ä¾èµ–äºè¿æ¥çŠ¶æ€
 * - é€šè¿‡ onVideoFrame å›è°ƒè§£è€¦
 */

import { useState, useRef, useCallback, useEffect } from 'react';
import { DEFAULT_CAMERA_FRAME_RATE, DEFAULT_CAMERA_RESOLUTION } from '../../../constants/media';
import { devLog, devWarn } from '../utils';
import { ensureAudioSessionReady } from '../../../lib/native-audio-session';

interface UseVideoInputOptions {
  frameRate?: number;
  resolution?: { width: number; height: number };
  onVideoFrame?: (base64Jpeg: string) => void;
  onError?: (error: string) => void;
}

interface UseVideoInputReturn {
  // State
  isEnabled: boolean;
  videoStream: MediaStream | null;
  error: string | null;

  // Actions
  start: () => Promise<void>;
  stop: () => void;
  toggle: () => Promise<void>;

  // Refs for UI (MutableRefObject to allow external assignment)
  videoRef: React.MutableRefObject<HTMLVideoElement | null>;
  canvasRef: React.MutableRefObject<HTMLCanvasElement | null>;

  // Control
  startFrameCapture: () => void;
  stopFrameCapture: () => void;
}

export function useVideoInput(
  options: UseVideoInputOptions = {}
): UseVideoInputReturn {
  const {
    frameRate = DEFAULT_CAMERA_FRAME_RATE,
    resolution = DEFAULT_CAMERA_RESOLUTION,
    onVideoFrame,
    onError
  } = options;

  // State
  const [isEnabled, setIsEnabled] = useState(false);
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);

  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const captureTimeoutRef = useRef<number>(-1);
  const isCapturingRef = useRef(false);
  const isStartingRef = useRef(false); // é˜²æ­¢å¹¶å‘å¯åŠ¨
  const currentStreamRef = useRef<MediaStream | null>(null); // è¿½è¸ªå½“å‰ stream ä»¥ä¾¿æ¸…ç†

  /**
   * å¯åŠ¨æ‘„åƒå¤´
   * æ·»åŠ å¹‚ç­‰å®ˆå«ï¼šå¦‚æœå·²å¯ç”¨æˆ–æ­£åœ¨å¯åŠ¨ä¸­ï¼Œç›´æ¥è¿”å›
   */
  const start = useCallback(async () => {
    // å¹‚ç­‰å®ˆå«ï¼šå·²ç»å¯ç”¨
    if (isEnabled) {
      devLog('ğŸ“¹ Camera already enabled, skipping start');
      return;
    }

    // å¹‚ç­‰å®ˆå«ï¼šæ­£åœ¨å¯åŠ¨ä¸­ï¼ˆé˜²æ­¢å¹¶å‘è°ƒç”¨ï¼‰
    if (isStartingRef.current) {
      devLog('ğŸ“¹ Camera start already in progress, skipping');
      return;
    }

    isStartingRef.current = true;

    try {
      // åœ¨ iOS Native WebView ä¸­ï¼Œå…ˆç­‰å¾…éŸ³é¢‘ä¼šè¯å°±ç»ª
      // è¿™æ˜¯ä¸ºäº†è§£å†³ CallKit æ¥ç”µæ¥å¬åéŸ³é¢‘ä¼šè¯å†²çªçš„é—®é¢˜
      await ensureAudioSessionReady();

      // å¦‚æœæœ‰æ—§çš„ streamï¼Œå…ˆåœæ­¢å®ƒï¼ˆé˜²æ­¢èµ„æºæ³„æ¼ï¼‰
      if (currentStreamRef.current) {
        currentStreamRef.current.getTracks().forEach((track) => track.stop());
        currentStreamRef.current = null;
      }

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'user',
          width: { ideal: resolution.width },
          height: { ideal: resolution.height },
        },
      });

      currentStreamRef.current = stream;
      setVideoStream(stream);
      setIsEnabled(true);
      setError(null);

      devLog('ğŸ“¹ Camera started');
    } catch (err) {
      console.error('ğŸ“¹ [videoInput.start] âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥:', err);
      const errorMessage = 'Camera access denied. Please allow camera access in Settings.';
      setError(errorMessage);
      onError?.(errorMessage);
    } finally {
      isStartingRef.current = false;
    }
  }, [isEnabled, resolution, onError]);

  /**
   * åœæ­¢æ‘„åƒå¤´
   * æ¸…ç†æ‰€æœ‰èµ„æº
   */
  const stop = useCallback(() => {
    // åœæ­¢æ‰€æœ‰ tracks
    if (currentStreamRef.current) {
      currentStreamRef.current.getTracks().forEach((track) => track.stop());
      currentStreamRef.current = null;
    }
    // ä¹Ÿåœæ­¢ state ä¸­çš„ streamï¼ˆä»¥é˜²ä¸‡ä¸€ä¸ä¸€è‡´ï¼‰
    videoStream?.getTracks().forEach((track) => track.stop());
    setVideoStream(null);
    setIsEnabled(false);

    // åœæ­¢å¸§æ•è·
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }
    isCapturingRef.current = false;

    devLog('ğŸ“¹ Camera stopped');
  }, [videoStream]);

  /**
   * åˆ‡æ¢æ‘„åƒå¤´çŠ¶æ€
   */
  const toggle = useCallback(async () => {
    if (isEnabled) {
      stop();
    } else {
      await start();
    }
  }, [isEnabled, start, stop]);

  /**
   * å°è¯•æ’­æ”¾è§†é¢‘é¢„è§ˆ
   */
  const ensureVideoPlayback = useCallback(async (videoElement: HTMLVideoElement) => {
    try {
      const playPromise = videoElement.play();
      if (playPromise) {
        await playPromise;
      }
    } catch (err) {
      devWarn('Camera preview playback failed:', err);
      setError('Camera preview blocked. Please tap the camera button to start playback.');
    }
  }, []);

  /**
   * è®¾ç½®è§†é¢‘é¢„è§ˆï¼ˆç‹¬ç«‹äºè¿æ¥çŠ¶æ€ï¼‰
   */
  useEffect(() => {
    if (videoRef.current && videoStream) {
      videoRef.current.srcObject = videoStream;
      void ensureVideoPlayback(videoRef.current);
    }
  }, [videoStream, ensureVideoPlayback]);

  /**
   * å‘é€å•ä¸ªè§†é¢‘å¸§
   */
  const sendVideoFrame = useCallback(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;

    if (!video || !canvas || !onVideoFrame) {
      return;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // ç¼©å°å°ºå¯¸ä»¥å‡å°‘å¸¦å®½
    canvas.width = video.videoWidth * 0.25;
    canvas.height = video.videoHeight * 0.25;

    if (canvas.width + canvas.height > 0) {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const base64 = canvas.toDataURL('image/jpeg', 1.0);
      const data = base64.slice(base64.indexOf(',') + 1);
      onVideoFrame(data);
    }

    // ç»§ç»­æ•è·
    if (isCapturingRef.current && isEnabled) {
      captureTimeoutRef.current = window.setTimeout(
        sendVideoFrame,
        1000 / frameRate
      );
    }
  }, [frameRate, isEnabled, onVideoFrame]);

  /**
   * å¼€å§‹è§†é¢‘å¸§æ•è·
   */
  const startFrameCapture = useCallback(() => {
    if (!isEnabled || !videoStream || isCapturingRef.current) return;

    isCapturingRef.current = true;
    requestAnimationFrame(sendVideoFrame);

    devLog('ğŸ“¹ Frame capture started');
  }, [isEnabled, videoStream, sendVideoFrame]);

  /**
   * åœæ­¢è§†é¢‘å¸§æ•è·
   */
  const stopFrameCapture = useCallback(() => {
    isCapturingRef.current = false;
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }

    devLog('ğŸ“¹ Frame capture stopped');
  }, []);

  // P0 ä¿®å¤ï¼šå®Œæ•´æ¸…ç†èµ„æº on unmount
  // é˜²æ­¢æ‘„åƒå¤´èµ„æºæ³„æ¼ï¼Œç¡®ä¿æµè§ˆå™¨é‡Šæ”¾è®¾å¤‡
  useEffect(() => {
    const videoElement = videoRef.current;
    return () => {
      // 1. æ¸…ç†å¸§æ•è·å®šæ—¶å™¨
      if (captureTimeoutRef.current !== -1) {
        clearTimeout(captureTimeoutRef.current);
        captureTimeoutRef.current = -1;
      }
      isCapturingRef.current = false;

      // 2. åœæ­¢å¹¶æ¸…ç† stream tracks
      if (currentStreamRef.current) {
        currentStreamRef.current.getTracks().forEach((track) => {
          track.stop();
          devLog('ğŸ“¹ Cleanup: stopped track', track.kind);
        });
        currentStreamRef.current = null;
      }

      // 3. æ¸…ç©º video å…ƒç´ çš„ srcObjectï¼ˆå…³é”®ï¼šé˜²æ­¢æµè§ˆå™¨ç»§ç»­å ç”¨æ‘„åƒå¤´ï¼‰
      if (videoElement) {
        videoElement.srcObject = null;
        devLog('ğŸ“¹ Cleanup: cleared videoRef.srcObject');
      }

      devLog('ğŸ“¹ useVideoInput unmounted, all resources cleaned up');
    };
  }, []);

  return {
    // State
    isEnabled,
    videoStream,
    error,

    // Actions
    start,
    stop,
    toggle,

    // Refs
    videoRef,
    canvasRef,

    // Control
    startFrameCapture,
    stopFrameCapture,
  };
}
