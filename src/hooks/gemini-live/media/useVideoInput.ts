/**
 * useVideoInput - æ‘„åƒå¤´æ•èŽ·å’Œè§†é¢‘å¸§å‘é€
 *
 * èŒè´£ï¼š
 * - ç®¡ç†æ‘„åƒå¤´æƒé™å’Œè®¾å¤‡
 * - æ•èŽ·è§†é¢‘å¸§å¹¶è½¬æ¢ä¸º JPEG base64
 * - æŒ‰æŒ‡å®šå¸§çŽ‡å‘é€è§†é¢‘å¸§
 *
 * è®¾è®¡å†³ç­–ï¼š
 * - è§†é¢‘é¢„è§ˆç‹¬ç«‹äºŽè¿žæŽ¥çŠ¶æ€ï¼ˆå¯ä»¥å…ˆé¢„è§ˆå†è¿žæŽ¥ï¼‰
 * - è§†é¢‘å¸§å‘é€ä¾èµ–äºŽè¿žæŽ¥çŠ¶æ€
 * - é€šè¿‡ onVideoFrame å›žè°ƒè§£è€¦
 */

import { useState, useRef, useCallback, useEffect } from 'react';
import { DEFAULT_CAMERA_FRAME_RATE, DEFAULT_CAMERA_RESOLUTION } from '../../../constants/media';
import { devLog, devWarn } from '../utils';

interface UseVideoInputOptions {
  frameRate?: number;
  resolution?: { width: number; height: number };
  onVideoFrame?: (base64Jpeg: string) => void;
  onError?: (error: string) => void;
}

interface UseVideoInputReturn {
  // State
  isEnabled: boolean;
  videoStream: MediaStream | null;
  error: string | null;

  // Actions
  start: () => Promise<void>;
  stop: () => void;
  toggle: () => Promise<void>;

  // Refs for UI (MutableRefObject to allow external assignment)
  videoRef: React.MutableRefObject<HTMLVideoElement | null>;
  canvasRef: React.MutableRefObject<HTMLCanvasElement | null>;

  // Control
  startFrameCapture: () => void;
  stopFrameCapture: () => void;
}

export function useVideoInput(
  options: UseVideoInputOptions = {}
): UseVideoInputReturn {
  const {
    frameRate = DEFAULT_CAMERA_FRAME_RATE,
    resolution = DEFAULT_CAMERA_RESOLUTION,
    onVideoFrame,
    onError
  } = options;

  // State
  const [isEnabled, setIsEnabled] = useState(false);
  const [videoStream, setVideoStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);

  // Refs
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const captureTimeoutRef = useRef<number>(-1);
  const isCapturingRef = useRef(false);

  /**
   * å¯åŠ¨æ‘„åƒå¤´
   */
  const start = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          facingMode: 'user',
          width: { ideal: resolution.width },
          height: { ideal: resolution.height },
        },
      });

      setVideoStream(stream);
      setIsEnabled(true);
      setError(null);

      devLog('ðŸ“¹ Camera started');
    } catch (err) {
      console.error('Camera error:', err);
      const errorMessage = 'Camera access denied. Please allow camera access in Settings.';
      setError(errorMessage);
      onError?.(errorMessage);
    }
  }, [resolution, onError]);

  /**
   * åœæ­¢æ‘„åƒå¤´
   */
  const stop = useCallback(() => {
    videoStream?.getTracks().forEach((track) => track.stop());
    setVideoStream(null);
    setIsEnabled(false);

    // åœæ­¢å¸§æ•èŽ·
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }
    isCapturingRef.current = false;

    devLog('ðŸ“¹ Camera stopped');
  }, [videoStream]);

  /**
   * åˆ‡æ¢æ‘„åƒå¤´çŠ¶æ€
   */
  const toggle = useCallback(async () => {
    if (isEnabled) {
      stop();
    } else {
      await start();
    }
  }, [isEnabled, start, stop]);

  /**
   * å°è¯•æ’­æ”¾è§†é¢‘é¢„è§ˆ
   */
  const ensureVideoPlayback = useCallback(async (videoElement: HTMLVideoElement) => {
    try {
      const playPromise = videoElement.play();
      if (playPromise) {
        await playPromise;
      }
    } catch (err) {
      devWarn('Camera preview playback failed:', err);
      setError('Camera preview blocked. Please tap the camera button to start playback.');
    }
  }, []);

  /**
   * è®¾ç½®è§†é¢‘é¢„è§ˆï¼ˆç‹¬ç«‹äºŽè¿žæŽ¥çŠ¶æ€ï¼‰
   */
  useEffect(() => {
    if (videoRef.current && videoStream) {
      videoRef.current.srcObject = videoStream;
      void ensureVideoPlayback(videoRef.current);
    }
  }, [videoStream, ensureVideoPlayback]);

  /**
   * å‘é€å•ä¸ªè§†é¢‘å¸§
   */
  const sendVideoFrame = useCallback(() => {
    const video = videoRef.current;
    const canvas = canvasRef.current;

    if (!video || !canvas || !onVideoFrame) {
      return;
    }

    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // ç¼©å°å°ºå¯¸ä»¥å‡å°‘å¸¦å®½
    canvas.width = video.videoWidth * 0.25;
    canvas.height = video.videoHeight * 0.25;

    if (canvas.width + canvas.height > 0) {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const base64 = canvas.toDataURL('image/jpeg', 1.0);
      const data = base64.slice(base64.indexOf(',') + 1);
      onVideoFrame(data);
    }

    // ç»§ç»­æ•èŽ·
    if (isCapturingRef.current && isEnabled) {
      captureTimeoutRef.current = window.setTimeout(
        sendVideoFrame,
        1000 / frameRate
      );
    }
  }, [frameRate, isEnabled, onVideoFrame]);

  /**
   * å¼€å§‹è§†é¢‘å¸§æ•èŽ·
   */
  const startFrameCapture = useCallback(() => {
    if (!isEnabled || !videoStream || isCapturingRef.current) return;

    isCapturingRef.current = true;
    requestAnimationFrame(sendVideoFrame);

    devLog('ðŸ“¹ Frame capture started');
  }, [isEnabled, videoStream, sendVideoFrame]);

  /**
   * åœæ­¢è§†é¢‘å¸§æ•èŽ·
   */
  const stopFrameCapture = useCallback(() => {
    isCapturingRef.current = false;
    if (captureTimeoutRef.current !== -1) {
      clearTimeout(captureTimeoutRef.current);
      captureTimeoutRef.current = -1;
    }

    devLog('ðŸ“¹ Frame capture stopped');
  }, []);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (captureTimeoutRef.current !== -1) {
        clearTimeout(captureTimeoutRef.current);
      }
    };
  }, []);

  return {
    // State
    isEnabled,
    videoStream,
    error,

    // Actions
    start,
    stop,
    toggle,

    // Refs
    videoRef,
    canvasRef,

    // Control
    startFrameCapture,
    stopFrameCapture,
  };
}
