/**
 * useGeminiLive - Gemini Live å¤šæ¨¡æ€å¯¹è¯ Hookï¼ˆç»„åˆå™¨ï¼‰
 *
 * è¿™æ˜¯ä¸»å…¥å£ hookï¼Œç»„åˆæ‰€æœ‰å­æ¨¡å—ï¼š
 * - useGeminiSession: WebSocket è¿æ¥ç®¡ç†
 * - useAudioInput: éº¦å…‹é£å½•åˆ¶
 * - useVideoInput: æ‘„åƒå¤´æ•è·
 * - useAudioOutput: éŸ³é¢‘æ’­æ”¾
 * - useTranscript: è½¬å½•ç®¡ç†
 * - useSessionAnalytics: åŸ‹ç‚¹è¿½è¸ª
 *
 * ä¿æŒåŸæœ‰ API å…¼å®¹ï¼Œè°ƒç”¨æ–¹æ— éœ€ä¿®æ”¹
 */

import { useCallback, useEffect, useRef } from 'react';
import type { LiveServerMessage, FunctionDeclaration } from '@google/genai';

// Core
import { useGeminiSession, fetchGeminiToken } from './core/useGeminiSession';
import { handleServerContent } from './core/messageHandlers';

// Media
import { useAudioInput } from './media/useAudioInput';
import { useVideoInput } from './media/useVideoInput';
import { useAudioOutput } from './media/useAudioOutput';

// Features
import { useTranscript } from './features/useTranscript';
import { useSessionAnalytics } from './features/useSessionAnalytics';

// Types
import type { ToolCall, ToolCallEvent, TranscriptEntry } from './types';
import { devLog } from './utils';

// ============================================================================
// Types
// ============================================================================

export type GeminiLiveStatus = 'disconnected' | 'connecting' | 'connected' | 'error';

interface UseGeminiLiveOptions {
  systemInstruction?: string;
  tools?: FunctionDeclaration[];
  onTranscriptUpdate?: (transcript: TranscriptEntry[]) => void;
  onMessage?: (message: LiveServerMessage) => void;
  onTurnComplete?: () => void;
  onToolCall?: (toolCall: ToolCallEvent) => void;
  enableCamera?: boolean;
  enableMicrophone?: boolean;
}

// ============================================================================
// Main Hook
// ============================================================================

export function useGeminiLive(options: UseGeminiLiveOptions = {}) {
  const {
    systemInstruction,
    tools,
    onTranscriptUpdate,
    onMessage,
    onTurnComplete,
    onToolCall,
    enableCamera = false,
    enableMicrophone = false,
  } = options;

  // ============================================================================
  // Sub-hooks
  // ============================================================================

  // Analytics (must be first to track initial state)
  const analytics = useSessionAnalytics();

  // Audio output (for playing AI responses)
  const audioOutput = useAudioOutput({
    onPlaybackComplete: () => {
      // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ’­æ”¾å®Œæˆçš„é€»è¾‘
    },
  });

  // Transcript management
  const transcriptManager = useTranscript({
    onUpdate: onTranscriptUpdate,
  });

  // Refs for callbacks (é¿å…é—­åŒ…é—®é¢˜)
  const onTurnCompleteRef = useRef<(() => void) | null>(onTurnComplete ?? null);
  const onToolCallRef = useRef<((toolCall: ToolCallEvent) => void) | null>(onToolCall ?? null);

  useEffect(() => {
    onTurnCompleteRef.current = onTurnComplete ?? null;
  }, [onTurnComplete]);

  useEffect(() => {
    onToolCallRef.current = onToolCall ?? null;
  }, [onToolCall]);

  // Session management (core)
  const session = useGeminiSession({
    onMessage: (message: LiveServerMessage) => {
      // è°ƒç”¨å¤–éƒ¨æ¶ˆæ¯å¤„ç†å™¨
      onMessage?.(message);

      // ä½¿ç”¨æ¶ˆæ¯å¤„ç†å™¨å¤„ç†æœåŠ¡å™¨å†…å®¹
      if (message.serverContent) {
        handleServerContent(message, {
          onInterrupt: () => {
            audioOutput.stop();
          },
          onTurnComplete: () => {
            audioOutput.markTurnComplete();  // é‡ç½® isSpeaking çŠ¶æ€
            onTurnCompleteRef.current?.();
          },
          onInputTranscription: (text: string) => {
            transcriptManager.addUserEntry(text);
          },
          onOutputTranscription: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          onToolCall: (toolCall: ToolCall) => {
            devLog('ğŸ”§ Tool call received:', toolCall);

            if (toolCall?.functionCalls && toolCall.functionCalls.length > 0) {
              const functionCall = toolCall.functionCalls[0];
              const functionName = functionCall.name;
              const args = functionCall.args;

              devLog('ğŸ“ Function called:', functionName, args);

              if (onToolCallRef.current) {
                onToolCallRef.current({ functionName, args });
              }

              // Send function response back to AI
              session.sendToolResponse({
                functionResponses: [
                  {
                    id: functionCall.id,
                    name: functionName,
                    response: { success: true },
                  },
                ],
              });
            }
          },
          onAudioData: async (data: string) => {
            await audioOutput.ensureReady();
            audioOutput.playAudio(data);
          },
          onTextContent: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          session: session.sessionRef.current,
        });
      }
    },
    onConnected: () => {
      analytics.trackConnect();
    },
    onDisconnected: () => {
      // Cleanup handled in disconnect
    },
    onError: (error: string) => {
      devLog('Session error:', error);
    },
  });

  // Audio input (microphone)
  const audioInput = useAudioInput({
    onAudioData: (base64Audio: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'audio/pcm;rate=16000',
          data: base64Audio,
        },
      });
    },
    onError: (error: string) => {
      devLog('Audio input error:', error);
    },
  });

  // Video input (camera)
  const videoInput = useVideoInput({
    onVideoFrame: (base64Jpeg: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'image/jpeg',
          data: base64Jpeg,
        },
      });
    },
    onError: (error: string) => {
      devLog('Video input error:', error);
    },
  });

  // ============================================================================
  // Composed Actions
  // ============================================================================

  /**
   * è¿æ¥ Gemini Live
   */
  const connect = useCallback(async (
    customSystemInstruction?: string,
    customTools?: FunctionDeclaration[],
    prefetchedToken?: string
  ) => {
    // é‡ç½®ç»Ÿè®¡
    analytics.resetStats();

    // é¢„åˆå§‹åŒ– AudioContextï¼ˆå¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­ï¼‰
    devLog('ğŸ”Š Pre-initializing AudioContext...');
    await audioOutput.ensureReady();
    devLog('âœ… AudioContext ready');

    // å»ºç«‹è¿æ¥
    await session.connect(
      {
        systemInstruction: customSystemInstruction || systemInstruction,
        tools: customTools || tools,
      },
      prefetchedToken
    );
  }, [systemInstruction, tools, session, audioOutput, analytics]);

  /**
   * æ–­å¼€è¿æ¥å¹¶æ¸…ç†æ‰€æœ‰èµ„æº
   */
  const disconnect = useCallback(() => {
    devLog('ğŸ”Œ Disconnecting Gemini Live...');

    // åŸ‹ç‚¹
    analytics.trackDisconnect();

    // å…³é—­ session
    session.disconnect();

    // åœæ­¢éº¦å…‹é£
    audioInput.stop();

    // åœæ­¢æ‘„åƒå¤´
    videoInput.stop();

    // æ¸…ç†éŸ³é¢‘è¾“å‡º
    audioOutput.cleanup();

    devLog('âœ… Gemini Live disconnected and cleaned up');
  }, [session, audioInput, videoInput, audioOutput, analytics]);

  /**
   * åˆ‡æ¢éº¦å…‹é£
   */
  const toggleMicrophone = useCallback(async () => {
    if (audioInput.isRecording) {
      audioInput.stop();
      analytics.trackMicToggle(false);
    } else {
      // ç¡®ä¿ AudioContext å·²å‡†å¤‡
      await audioOutput.ensureReady();
      await audioInput.start();
      analytics.trackMicToggle(true);
    }
  }, [audioInput, audioOutput, analytics]);

  /**
   * åˆ‡æ¢æ‘„åƒå¤´
   */
  const toggleCamera = useCallback(async () => {
    if (videoInput.isEnabled) {
      videoInput.stop();
      analytics.trackCameraToggle(false);
    } else {
      await audioOutput.ensureReady();
      await videoInput.start();
      analytics.trackCameraToggle(true);
    }
  }, [videoInput, audioOutput, analytics]);

  /**
   * å‘é€æ–‡æœ¬æ¶ˆæ¯
   */
  const sendTextMessage = useCallback((text: string) => {
    if (session.isConnected) {
      session.sendRealtimeInput({ text });
    }
  }, [session]);

  /**
   * è®¾ç½® onTurnComplete å›è°ƒ
   */
  const setOnTurnComplete = useCallback((handler: (() => void) | null | undefined) => {
    onTurnCompleteRef.current = handler ?? null;
  }, []);

  // ============================================================================
  // Auto-enable Effects
  // ============================================================================

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨æ‘„åƒå¤´
  useEffect(() => {
    if (session.isConnected && enableCamera && !videoInput.isEnabled) {
      queueMicrotask(() => {
        toggleCamera();
      });
    }
  }, [session.isConnected, enableCamera, videoInput.isEnabled, toggleCamera]);

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨éº¦å…‹é£
  useEffect(() => {
    if (session.isConnected && enableMicrophone && !audioInput.isRecording) {
      queueMicrotask(() => {
        toggleMicrophone();
      });
    }
  }, [session.isConnected, enableMicrophone, audioInput.isRecording, toggleMicrophone]);

  // è¿æ¥åå¼€å§‹è§†é¢‘å¸§æ•è·
  useEffect(() => {
    if (session.isConnected && videoInput.isEnabled) {
      videoInput.startFrameCapture();
    } else {
      videoInput.stopFrameCapture();
    }
  }, [session.isConnected, videoInput.isEnabled, videoInput]);

  // ============================================================================
  // Return (ä¿æŒåŸæœ‰ API å…¼å®¹)
  // ============================================================================

  return {
    // State
    isConnected: session.isConnected,
    isRecording: audioInput.isRecording,
    isSpeaking: audioOutput.isSpeaking,
    error: session.error || audioInput.error || videoInput.error,
    transcript: transcriptManager.transcript,
    cameraEnabled: videoInput.isEnabled,
    videoStream: videoInput.videoStream,
    audioStream: audioInput.audioStream,

    // Actions
    connect,
    disconnect,
    toggleMicrophone,
    toggleCamera,
    sendTextMessage,
    setOnTurnComplete,

    // Refs for UI
    videoRef: videoInput.videoRef,
    canvasRef: videoInput.canvasRef,
  };
}

// Re-export for convenience
export { fetchGeminiToken };
export type { TranscriptEntry, ToolCallEvent };
