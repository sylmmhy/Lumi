/**
 * useGeminiLive - Gemini Live å¤šæ¨¡æ€å¯¹è¯ Hookï¼ˆç»„åˆå™¨ï¼‰
 *
 * è¿™æ˜¯ä¸»å…¥å£ hookï¼Œç»„åˆæ‰€æœ‰å­æ¨¡å—ï¼š
 * - useGeminiSession: WebSocket è¿æ¥ç®¡ç†
 * - useAudioInput: éº¦å…‹é£å½•åˆ¶
 * - useVideoInput: æ‘„åƒå¤´æ•è·
 * - useAudioOutput: éŸ³é¢‘æ’­æ”¾
 * - useTranscript: è½¬å½•ç®¡ç†
 * - useSessionAnalytics: åŸ‹ç‚¹è¿½è¸ª
 *
 * ä¿æŒåŸæœ‰ API å…¼å®¹ï¼Œè°ƒç”¨æ–¹æ— éœ€ä¿®æ”¹
 */

import { useCallback, useEffect, useRef } from 'react';
import type { LiveServerMessage, FunctionDeclaration } from '@google/genai';

// Core
import { useGeminiSession, fetchGeminiToken } from './core/useGeminiSession';
import { handleServerContent } from './core/messageHandlers';

// Media
import { useAudioInput } from './media/useAudioInput';
import { useVideoInput } from './media/useVideoInput';
import { useAudioOutput } from './media/useAudioOutput';
import { useVideoFrameBuffer } from './media/useVideoFrameBuffer';

// Features
import { useTranscript } from './features/useTranscript';
import { useSessionAnalytics } from './features/useSessionAnalytics';

// Types
import type { ToolCall, ToolCallEvent, TranscriptEntry } from './types';
import { devLog } from './utils';

// ============================================================================
// Types
// ============================================================================

export type GeminiLiveStatus = 'disconnected' | 'connecting' | 'connected' | 'error';

interface UseGeminiLiveOptions {
  systemInstruction?: string;
  tools?: FunctionDeclaration[];
  onTranscriptUpdate?: (transcript: TranscriptEntry[]) => void;
  onMessage?: (message: LiveServerMessage) => void;
  onTurnComplete?: () => void;
  onToolCall?: (toolCall: ToolCallEvent) => void;
  enableCamera?: boolean;
  enableMicrophone?: boolean;
}

// ============================================================================
// Main Hook
// ============================================================================

export function useGeminiLive(options: UseGeminiLiveOptions = {}) {
  const {
    systemInstruction,
    tools,
    onTranscriptUpdate,
    onMessage,
    onTurnComplete,
    onToolCall,
    enableCamera = false,
    enableMicrophone = false,
  } = options;

  // ============================================================================
  // Sub-hooks
  // ============================================================================

  // Analytics (must be first to track initial state)
  const analytics = useSessionAnalytics();

  // Audio output (for playing AI responses)
  const audioOutput = useAudioOutput({
    onPlaybackComplete: () => {
      // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ’­æ”¾å®Œæˆçš„é€»è¾‘
    },
  });

  // Transcript management
  const transcriptManager = useTranscript({
    onUpdate: onTranscriptUpdate,
  });

  // Refs for callbacks (é¿å…é—­åŒ…é—®é¢˜)
  const onTurnCompleteRef = useRef<(() => void) | null>(onTurnComplete ?? null);
  const onToolCallRef = useRef<((toolCall: ToolCallEvent) => void) | null>(onToolCall ?? null);

  useEffect(() => {
    onTurnCompleteRef.current = onTurnComplete ?? null;
  }, [onTurnComplete]);

  useEffect(() => {
    onToolCallRef.current = onToolCall ?? null;
  }, [onToolCall]);

  // è¿½è¸ªæœ€åä¸€æ¬¡ turnComplete çš„æ—¶é—´ï¼Œç”¨äºåˆ¤æ–­å®‰å…¨æ³¨å…¥çª—å£
  // å¿…é¡»åœ¨ useGeminiSession ä¹‹å‰å®šä¹‰ï¼Œå› ä¸º onTurnComplete å›è°ƒéœ€è¦è®¿é—®è¿™äº› refs
  const lastTurnCompleteTimeRef = useRef<number>(0);
  // è¿½è¸ª AI æ˜¯å¦æ­£åœ¨è¯´è¯ï¼ˆåŒæ­¥ç‰ˆï¼Œç”¨äºå®‰å…¨çª—å£åˆ¤æ–­ï¼‰
  const isSpeakingRef = useRef<boolean>(false);

  // Session management (core)
  const session = useGeminiSession({
    onMessage: (message: LiveServerMessage) => {
      // è°ƒç”¨å¤–éƒ¨æ¶ˆæ¯å¤„ç†å™¨
      onMessage?.(message);

      // ä½¿ç”¨æ¶ˆæ¯å¤„ç†å™¨å¤„ç†æœåŠ¡å™¨å†…å®¹
      if (message.serverContent) {
        handleServerContent(message, {
          onInterrupt: () => {
            audioOutput.stop();
          },
          onTurnComplete: () => {
            audioOutput.markTurnComplete();  // é‡ç½® isSpeaking çŠ¶æ€ï¼ˆå¼‚æ­¥ï¼‰
            isSpeakingRef.current = false;  // ç«‹å³åŒæ­¥æ›´æ–° refï¼Œç¡®ä¿å®‰å…¨çª—å£åˆ¤æ–­æ­£ç¡®
            lastTurnCompleteTimeRef.current = Date.now();  // è®°å½• turnComplete æ—¶é—´ï¼Œç”¨äºå®‰å…¨æ³¨å…¥çª—å£
            onTurnCompleteRef.current?.();
          },
          onInputTranscription: (text: string) => {
            transcriptManager.addUserEntry(text);
          },
          onOutputTranscription: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          onToolCall: (toolCall: ToolCall) => {
            devLog('ğŸ”§ Tool call received:', toolCall);

            if (toolCall?.functionCalls && toolCall.functionCalls.length > 0) {
              const functionCall = toolCall.functionCalls[0];
              const functionName = functionCall.name;
              const args = functionCall.args;

              devLog('ğŸ“ Function called:', functionName, args);

              if (onToolCallRef.current) {
                onToolCallRef.current({ functionName, args });
              }

              // Send function response back to AI
              session.sendToolResponse({
                functionResponses: [
                  {
                    id: functionCall.id,
                    name: functionName,
                    response: { success: true },
                  },
                ],
              });
            }
          },
          onAudioData: async (data: string) => {
            try {
              await audioOutput.ensureReady();
              audioOutput.playAudio(data);
            } catch (err) {
              devLog('âš ï¸ Audio playback error:', err);
            }
          },
          onTextContent: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          session: session.sessionRef.current,
        });
      }
    },
    onConnected: () => {
      analytics.trackConnect();
    },
    onDisconnected: () => {
      // Cleanup handled in disconnect
    },
    onError: (error: string) => {
      devLog('Session error:', error);
    },
  });

  // Audio input (microphone)
  // è§£æ„å‡ºç¨³å®šçš„å­—æ®µï¼Œé¿å…ä¾èµ–æ•´ä¸ªå¯¹è±¡å¯¼è‡´ useCallback/useEffect é‡å¤è§¦å‘
  const audioInput = useAudioInput({
    onAudioData: (base64Audio: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'audio/pcm;rate=16000',
          data: base64Audio,
        },
      });
    },
    onError: (error: string) => {
      devLog('Audio input error:', error);
    },
  });
  const {
    isRecording: audioIsRecording,
    start: audioStart,
    stop: audioStop,
    error: audioError,
    audioStream,
  } = audioInput;

  // Video frame buffer (ç¯å½¢ç¼“å†²åŒºï¼Œä¿å­˜æœ€è¿‘ 10 å¸§ç”¨äºä»»åŠ¡éªŒè¯)
  const frameBuffer = useVideoFrameBuffer({ maxFrames: 10 });

  // Video input (camera)
  // è§£æ„å‡ºç¨³å®šçš„å­—æ®µï¼Œé¿å…ä¾èµ–æ•´ä¸ªå¯¹è±¡å¯¼è‡´ useCallback/useEffect é‡å¤è§¦å‘
  const videoInput = useVideoInput({
    onVideoFrame: (base64Jpeg: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'image/jpeg',
          data: base64Jpeg,
        },
      });
      // åŒæ—¶å­˜å…¥å¸§ç¼“å†²åŒºï¼Œä¾›ä»»åŠ¡å®Œæˆæ—¶è§†è§‰éªŒè¯ä½¿ç”¨
      frameBuffer.addFrame(base64Jpeg);
    },
    onError: (error: string) => {
      devLog('Video input error:', error);
    },
  });
  const {
    isEnabled: videoIsEnabled,
    start: videoStart,
    stop: videoStop,
    error: videoError,
    videoStream,
    videoRef,
    canvasRef,
    startFrameCapture,
    stopFrameCapture,
  } = videoInput;

  // ============================================================================
  // Composed Actions
  // ============================================================================

  /**
   * è¿æ¥ Gemini Live
   * @param customSystemInstruction - è‡ªå®šä¹‰ç³»ç»ŸæŒ‡ä»¤
   * @param customTools - è‡ªå®šä¹‰å·¥å…·åˆ—è¡¨
   * @param prefetchedToken - é¢„è·å–çš„ Gemini token
   * @param voiceName - AI å£°éŸ³åç§°ï¼ˆå¦‚ 'Puck', 'Kore'ï¼‰
   */
  const connect = useCallback(async (
    customSystemInstruction?: string,
    customTools?: FunctionDeclaration[],
    prefetchedToken?: string,
    voiceName?: string
  ) => {
    // é‡ç½®ç»Ÿè®¡
    analytics.resetStats();

    // é¢„åˆå§‹åŒ– AudioContextï¼ˆå¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­ï¼‰
    devLog('ğŸ”Š Pre-initializing AudioContext...');
    await audioOutput.ensureReady();
    devLog('âœ… AudioContext ready');

    // å»ºç«‹è¿æ¥
    await session.connect(
      {
        systemInstruction: customSystemInstruction || systemInstruction,
        tools: customTools || tools,
        voiceName,
      },
      prefetchedToken
    );
  }, [systemInstruction, tools, session, audioOutput, analytics]);

  /**
   * ç«‹å³åœæ­¢éŸ³é¢‘æ’­æ”¾ï¼ˆä¸æ–­å¼€è¿æ¥ï¼‰
   * ç”¨äºå¿«é€Ÿå“åº”ç”¨æˆ·æŒ‚æ–­æ“ä½œï¼Œç«‹å³é™éŸ³ AI
   */
  const stopAudio = useCallback(() => {
    devLog('ğŸ”‡ Stopping audio playback immediately...');
    audioOutput.stop();
  }, [audioOutput]);

  /**
   * æ–­å¼€è¿æ¥å¹¶æ¸…ç†æ‰€æœ‰èµ„æº
   */
  const disconnect = useCallback(() => {
    devLog('ğŸ”Œ Disconnecting Gemini Live...');

    // åŸ‹ç‚¹
    analytics.trackDisconnect();

    // å…³é—­ session
    session.disconnect();

    // åœæ­¢éº¦å…‹é£
    audioStop();

    // åœæ­¢æ‘„åƒå¤´
    videoStop();

    // æ¸…ç†éŸ³é¢‘è¾“å‡º
    audioOutput.cleanup();

    devLog('âœ… Gemini Live disconnected and cleaned up');
  }, [session, audioStop, videoStop, audioOutput, analytics]);

  /**
   * åˆ‡æ¢éº¦å…‹é£
   * ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½é‡å»ºå‡½æ•°
   */
  const toggleMicrophone = useCallback(async () => {
    if (audioIsRecording) {
      audioStop();
      analytics.trackMicToggle(false);
    } else {
      // ç¡®ä¿ AudioContext å·²å‡†å¤‡ï¼ˆä¼šç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ªï¼‰
      await audioOutput.ensureReady();
      await audioStart();
      analytics.trackMicToggle(true);
    }
  }, [audioIsRecording, audioStart, audioStop, audioOutput, analytics]);

  /**
   * åˆ‡æ¢æ‘„åƒå¤´
   * ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½é‡å»ºå‡½æ•°
   */
  const toggleCamera = useCallback(async () => {
    if (videoIsEnabled) {
      videoStop();
      analytics.trackCameraToggle(false);
    } else {
      // ç¡®ä¿ AudioContext å·²å‡†å¤‡ï¼ˆä¼šç­‰å¾… iOS éŸ³é¢‘ä¼šè¯å°±ç»ªï¼‰
      await audioOutput.ensureReady();
      await videoStart();
      analytics.trackCameraToggle(true);
    }
  }, [videoIsEnabled, videoStart, videoStop, audioOutput, analytics]);

  // è§£æ„å‡ºéœ€è¦çš„ session å­—æ®µï¼Œé¿å…åœ¨ Hook deps ä¸­ä¾èµ–æ•´ä¸ª session å¯¹è±¡
  const sessionIsConnected = session.isConnected;
  const sendRealtimeInput = session.sendRealtimeInput;
  const sendClientContent = session.sendClientContent;

  /**
   * å‘é€æ–‡æœ¬æ¶ˆæ¯
   * æ³¨æ„ï¼šä½¿ç”¨ session.isConnected å’Œ session.sendRealtimeInput ä½œä¸ºä¾èµ–
   * è€Œä¸æ˜¯æ•´ä¸ª session å¯¹è±¡ï¼Œé¿å…å› å¯¹è±¡å¼•ç”¨å˜åŒ–å¯¼è‡´å‡½æ•°é¢‘ç¹é‡å»º
   */
  const sendTextMessage = useCallback((text: string) => {
    if (sessionIsConnected) {
      sendRealtimeInput({ text });
      if (import.meta.env.DEV) {
        console.log('ğŸ“¤ [GeminiLive] å‘é€æ–‡æœ¬:', text.substring(0, 60) + (text.length > 60 ? '...' : ''));
      }
    } else if (import.meta.env.DEV) {
      console.warn('âš ï¸ [GeminiLive] å‘é€å¤±è´¥: è¿æ¥å·²æ–­å¼€');
    }
  }, [sessionIsConnected, sendRealtimeInput]);

  // åŒæ­¥ isSpeaking çŠ¶æ€åˆ° refï¼ˆå½“ AI å¼€å§‹è¯´è¯æ—¶æ›´æ–°ï¼‰
  useEffect(() => {
    if (audioOutput.isSpeaking) {
      isSpeakingRef.current = true;
    }
    // æ³¨æ„ï¼šisSpeaking = false çš„æƒ…å†µåœ¨ onTurnComplete å›è°ƒä¸­ç«‹å³å¤„ç†ï¼Œä¸ä¾èµ–è¿™ä¸ª effect
  }, [audioOutput.isSpeaking]);

  /**
   * é™é»˜æ³¨å…¥ä¸Šä¸‹æ–‡åˆ°å¯¹è¯ä¸­ï¼ˆä¸è§¦å‘ AI å“åº”ï¼‰
   *
   * è¿™æ˜¯æ–¹æ¡ˆ A çš„æ ¸å¿ƒå®ç°ï¼š
   * - ä½¿ç”¨ sendClientContent + turn_complete=false é™é»˜æ³¨å…¥
   * - åªåœ¨å®‰å…¨çª—å£æœŸï¼ˆAI è¯´å®Œè¯åã€ç”¨æˆ·å¼€å§‹è¯´è¯å‰ï¼‰æ³¨å…¥
   * - æ³¨å…¥çš„å†…å®¹ä¼šè¢« AI è®°ä½ï¼Œåœ¨ä¸‹æ¬¡å›å¤æ—¶è‡ªç„¶å¼•ç”¨
   *
   * @param content - è¦æ³¨å…¥çš„ä¸Šä¸‹æ–‡å†…å®¹ï¼ˆå¦‚ [CONTEXT] æ¶ˆæ¯ï¼‰
   * @param options - é…ç½®é€‰é¡¹
   * @returns boolean - æ˜¯å¦æˆåŠŸæ³¨å…¥
   */
  const injectContextSilently = useCallback((
    content: string,
    options: {
      /** æ˜¯å¦å¼ºåˆ¶æ³¨å…¥ï¼ˆå¿½ç•¥å®‰å…¨çª—å£æ£€æŸ¥ï¼‰ */
      force?: boolean;
      /** å®‰å…¨çª—å£æœŸï¼ˆæ¯«ç§’ï¼‰ï¼ŒAI è¯´å®Œè¯åå¤šä¹…å†…å¯ä»¥æ³¨å…¥ï¼Œé»˜è®¤ 5000ms */
      safeWindowMs?: number;
    } = {}
  ): boolean => {
    const { force = false, safeWindowMs = 5000 } = options;

    if (!sessionIsConnected) {
      if (import.meta.env.DEV) {
        console.warn('âš ï¸ [GeminiLive] é™é»˜æ³¨å…¥å¤±è´¥: è¿æ¥å·²æ–­å¼€');
      }
      return false;
    }

    // æ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨çª—å£æœŸ
    if (!force) {
      const now = Date.now();
      const timeSinceTurnComplete = now - lastTurnCompleteTimeRef.current;

      // å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œä¸æ³¨å…¥
      if (isSpeakingRef.current) {
        if (import.meta.env.DEV) {
          console.log('â¸ï¸ [GeminiLive] é™é»˜æ³¨å…¥å»¶è¿Ÿ: AI æ­£åœ¨è¯´è¯');
        }
        return false;
      }

      // å¦‚æœè·ç¦»ä¸Šæ¬¡ turnComplete å¤ªä¹…ï¼Œå¯èƒ½ç”¨æˆ·å·²ç»åœ¨è¯´è¯äº†ï¼Œä¸æ³¨å…¥
      if (lastTurnCompleteTimeRef.current > 0 && timeSinceTurnComplete > safeWindowMs) {
        if (import.meta.env.DEV) {
          console.log(`â¸ï¸ [GeminiLive] é™é»˜æ³¨å…¥å»¶è¿Ÿ: è¶…å‡ºå®‰å…¨çª—å£ (${timeSinceTurnComplete}ms > ${safeWindowMs}ms)`);
        }
        return false;
      }
    }

    // æ‰§è¡Œé™é»˜æ³¨å…¥ï¼ˆsendClientContent è¿”å› voidï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨ try-catch å¤„ç†é”™è¯¯ï¼‰
    try {
      sendClientContent(content, false);
    } catch (error) {
      if (import.meta.env.DEV) {
        console.warn('âš ï¸ [GeminiLive] é™é»˜æ³¨å…¥å¤±è´¥:', error);
      }
      return false;
    }

    if (import.meta.env.DEV) {
      console.log('ğŸ”‡ [GeminiLive] é™é»˜æ³¨å…¥ä¸Šä¸‹æ–‡:', content.substring(0, 80) + (content.length > 80 ? '...' : ''));
    }

    return true;
  }, [sessionIsConnected, sendClientContent]);

  /**
   * è®¾ç½® onTurnComplete å›è°ƒ
   */
  const setOnTurnComplete = useCallback((handler: (() => void) | null | undefined) => {
    onTurnCompleteRef.current = handler ?? null;
  }, []);

  // ============================================================================
  // Auto-enable Effects
  // ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½è§¦å‘ effect
  // ============================================================================

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨æ‘„åƒå¤´
  useEffect(() => {
    if (session.isConnected && enableCamera && !videoIsEnabled) {
      queueMicrotask(() => {
        toggleCamera();
      });
    }
  }, [session.isConnected, enableCamera, videoIsEnabled, toggleCamera]);

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨éº¦å…‹é£
  useEffect(() => {
    if (session.isConnected && enableMicrophone && !audioIsRecording) {
      queueMicrotask(() => {
        toggleMicrophone();
      });
    }
  }, [session.isConnected, enableMicrophone, audioIsRecording, toggleMicrophone]);

  // è¿æ¥åå¼€å§‹è§†é¢‘å¸§æ•è·
  useEffect(() => {
    if (session.isConnected && videoIsEnabled) {
      startFrameCapture();
    } else {
      stopFrameCapture();
    }
  }, [session.isConnected, videoIsEnabled, startFrameCapture, stopFrameCapture]);

  // ============================================================================
  // Return (ä¿æŒåŸæœ‰ API å…¼å®¹)
  // ============================================================================

  return {
    // State
    isConnected: session.isConnected,
    isRecording: audioIsRecording,
    isSpeaking: audioOutput.isSpeaking,
    // åˆå¹¶æ‰€æœ‰é”™è¯¯ï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
    error: [session.error, audioError, videoError].filter(Boolean).join('; ') || null,
    transcript: transcriptManager.transcript,
    cameraEnabled: videoIsEnabled,
    videoStream,
    audioStream,

    // Actions
    connect,
    disconnect,
    stopAudio,
    toggleMicrophone,
    toggleCamera,
    sendTextMessage,
    setOnTurnComplete,

    // Context injection (æ–¹æ¡ˆ A: turnComplete åé™é»˜æ³¨å…¥)
    injectContextSilently,
    sendClientContent: session.sendClientContent,

    // Frame buffer (ä»»åŠ¡å®Œæˆæ—¶æŠ“å–æœ€è¿‘å¸§ç”¨äºè§†è§‰éªŒè¯)
    getRecentFrames: frameBuffer.getRecentFrames,

    // Refs for UI
    videoRef,
    canvasRef,
  };
}

// Re-export for convenience
export { fetchGeminiToken };
export type { TranscriptEntry, ToolCallEvent };
