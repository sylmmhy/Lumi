/**
 * useGeminiLive - Gemini Live å¤šæ¨¡æ€å¯¹è¯ Hookï¼ˆç»„åˆå™¨ï¼‰
 *
 * è¿™æ˜¯ä¸»å…¥å£ hookï¼Œç»„åˆæ‰€æœ‰å­æ¨¡å—ï¼š
 * - useGeminiSession: WebSocket è¿æ¥ç®¡ç†
 * - useAudioInput: éº¦å…‹é£å½•åˆ¶
 * - useVideoInput: æ‘„åƒå¤´æ•è·
 * - useAudioOutput: éŸ³é¢‘æ’­æ”¾
 * - useTranscript: è½¬å½•ç®¡ç†
 * - useSessionAnalytics: åŸ‹ç‚¹è¿½è¸ª
 *
 * ä¿æŒåŸæœ‰ API å…¼å®¹ï¼Œè°ƒç”¨æ–¹æ— éœ€ä¿®æ”¹
 */

import { useCallback, useEffect, useRef } from 'react';
import type { LiveServerMessage, FunctionDeclaration } from '@google/genai';

// Core
import { useGeminiSession, fetchGeminiToken } from './core/useGeminiSession';
import { handleServerContent } from './core/messageHandlers';

// Media
import { useAudioInput } from './media/useAudioInput';
import { useVideoInput } from './media/useVideoInput';
import { useAudioOutput } from './media/useAudioOutput';

// Features
import { useTranscript } from './features/useTranscript';
import { useSessionAnalytics } from './features/useSessionAnalytics';

// Types
import type { ToolCall, ToolCallEvent, TranscriptEntry } from './types';
import { devLog } from './utils';

// ============================================================================
// Types
// ============================================================================

export type GeminiLiveStatus = 'disconnected' | 'connecting' | 'connected' | 'error';

interface UseGeminiLiveOptions {
  systemInstruction?: string;
  tools?: FunctionDeclaration[];
  onTranscriptUpdate?: (transcript: TranscriptEntry[]) => void;
  onMessage?: (message: LiveServerMessage) => void;
  onTurnComplete?: () => void;
  onToolCall?: (toolCall: ToolCallEvent) => void;
  enableCamera?: boolean;
  enableMicrophone?: boolean;
}

// ============================================================================
// Main Hook
// ============================================================================

export function useGeminiLive(options: UseGeminiLiveOptions = {}) {
  const {
    systemInstruction,
    tools,
    onTranscriptUpdate,
    onMessage,
    onTurnComplete,
    onToolCall,
    enableCamera = false,
    enableMicrophone = false,
  } = options;

  // ============================================================================
  // Sub-hooks
  // ============================================================================

  // Analytics (must be first to track initial state)
  const analytics = useSessionAnalytics();

  // Audio output (for playing AI responses)
  const audioOutput = useAudioOutput({
    onPlaybackComplete: () => {
      // å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ’­æ”¾å®Œæˆçš„é€»è¾‘
    },
  });

  // Transcript management
  const transcriptManager = useTranscript({
    onUpdate: onTranscriptUpdate,
  });

  // Refs for callbacks (é¿å…é—­åŒ…é—®é¢˜)
  const onTurnCompleteRef = useRef<(() => void) | null>(onTurnComplete ?? null);
  const onToolCallRef = useRef<((toolCall: ToolCallEvent) => void) | null>(onToolCall ?? null);

  useEffect(() => {
    onTurnCompleteRef.current = onTurnComplete ?? null;
  }, [onTurnComplete]);

  useEffect(() => {
    onToolCallRef.current = onToolCall ?? null;
  }, [onToolCall]);

  // Session management (core)
  const session = useGeminiSession({
    onMessage: (message: LiveServerMessage) => {
      // è°ƒç”¨å¤–éƒ¨æ¶ˆæ¯å¤„ç†å™¨
      onMessage?.(message);

      // ä½¿ç”¨æ¶ˆæ¯å¤„ç†å™¨å¤„ç†æœåŠ¡å™¨å†…å®¹
      if (message.serverContent) {
        handleServerContent(message, {
          onInterrupt: () => {
            audioOutput.stop();
          },
          onTurnComplete: () => {
            audioOutput.markTurnComplete();  // é‡ç½® isSpeaking çŠ¶æ€
            onTurnCompleteRef.current?.();
          },
          onInputTranscription: (text: string) => {
            transcriptManager.addUserEntry(text);
          },
          onOutputTranscription: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          onToolCall: (toolCall: ToolCall) => {
            devLog('ğŸ”§ Tool call received:', toolCall);

            if (toolCall?.functionCalls && toolCall.functionCalls.length > 0) {
              const functionCall = toolCall.functionCalls[0];
              const functionName = functionCall.name;
              const args = functionCall.args;

              devLog('ğŸ“ Function called:', functionName, args);

              if (onToolCallRef.current) {
                onToolCallRef.current({ functionName, args });
              }

              // Send function response back to AI
              session.sendToolResponse({
                functionResponses: [
                  {
                    id: functionCall.id,
                    name: functionName,
                    response: { success: true },
                  },
                ],
              });
            }
          },
          onAudioData: async (data: string) => {
            try {
              await audioOutput.ensureReady();
              audioOutput.playAudio(data);
            } catch (err) {
              devLog('âš ï¸ Audio playback error:', err);
            }
          },
          onTextContent: (text: string) => {
            transcriptManager.addAssistantEntry(text);
          },
          session: session.sessionRef.current,
        });
      }
    },
    onConnected: () => {
      analytics.trackConnect();
    },
    onDisconnected: () => {
      // Cleanup handled in disconnect
    },
    onError: (error: string) => {
      devLog('Session error:', error);
    },
  });

  // Audio input (microphone)
  // è§£æ„å‡ºç¨³å®šçš„å­—æ®µï¼Œé¿å…ä¾èµ–æ•´ä¸ªå¯¹è±¡å¯¼è‡´ useCallback/useEffect é‡å¤è§¦å‘
  const audioInput = useAudioInput({
    onAudioData: (base64Audio: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'audio/pcm;rate=16000',
          data: base64Audio,
        },
      });
    },
    onError: (error: string) => {
      devLog('Audio input error:', error);
    },
  });
  const {
    isRecording: audioIsRecording,
    start: audioStart,
    stop: audioStop,
    error: audioError,
    audioStream,
  } = audioInput;

  // Video input (camera)
  // è§£æ„å‡ºç¨³å®šçš„å­—æ®µï¼Œé¿å…ä¾èµ–æ•´ä¸ªå¯¹è±¡å¯¼è‡´ useCallback/useEffect é‡å¤è§¦å‘
  const videoInput = useVideoInput({
    onVideoFrame: (base64Jpeg: string) => {
      session.sendRealtimeInput({
        media: {
          mimeType: 'image/jpeg',
          data: base64Jpeg,
        },
      });
    },
    onError: (error: string) => {
      devLog('Video input error:', error);
    },
  });
  const {
    isEnabled: videoIsEnabled,
    start: videoStart,
    stop: videoStop,
    error: videoError,
    videoStream,
    videoRef,
    canvasRef,
    startFrameCapture,
    stopFrameCapture,
  } = videoInput;

  // ============================================================================
  // Composed Actions
  // ============================================================================

  /**
   * è¿æ¥ Gemini Live
   */
  const connect = useCallback(async (
    customSystemInstruction?: string,
    customTools?: FunctionDeclaration[],
    prefetchedToken?: string
  ) => {
    // é‡ç½®ç»Ÿè®¡
    analytics.resetStats();

    // é¢„åˆå§‹åŒ– AudioContextï¼ˆå¿…é¡»åœ¨ç”¨æˆ·äº¤äº’ä¸Šä¸‹æ–‡ä¸­ï¼‰
    devLog('ğŸ”Š Pre-initializing AudioContext...');
    await audioOutput.ensureReady();
    devLog('âœ… AudioContext ready');

    // å»ºç«‹è¿æ¥
    await session.connect(
      {
        systemInstruction: customSystemInstruction || systemInstruction,
        tools: customTools || tools,
      },
      prefetchedToken
    );
  }, [systemInstruction, tools, session, audioOutput, analytics]);

  /**
   * æ–­å¼€è¿æ¥å¹¶æ¸…ç†æ‰€æœ‰èµ„æº
   */
  const disconnect = useCallback(() => {
    devLog('ğŸ”Œ Disconnecting Gemini Live...');

    // åŸ‹ç‚¹
    analytics.trackDisconnect();

    // å…³é—­ session
    session.disconnect();

    // åœæ­¢éº¦å…‹é£
    audioStop();

    // åœæ­¢æ‘„åƒå¤´
    videoStop();

    // æ¸…ç†éŸ³é¢‘è¾“å‡º
    audioOutput.cleanup();

    devLog('âœ… Gemini Live disconnected and cleaned up');
  }, [session, audioStop, videoStop, audioOutput, analytics]);

  /**
   * åˆ‡æ¢éº¦å…‹é£
   * ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½é‡å»ºå‡½æ•°
   */
  const toggleMicrophone = useCallback(async () => {
    if (audioIsRecording) {
      audioStop();
      analytics.trackMicToggle(false);
    } else {
      // ç¡®ä¿ AudioContext å·²å‡†å¤‡
      await audioOutput.ensureReady();
      await audioStart();
      analytics.trackMicToggle(true);
    }
  }, [audioIsRecording, audioStart, audioStop, audioOutput, analytics]);

  /**
   * åˆ‡æ¢æ‘„åƒå¤´
   * ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½é‡å»ºå‡½æ•°
   */
  const toggleCamera = useCallback(async () => {
    if (videoIsEnabled) {
      videoStop();
      analytics.trackCameraToggle(false);
    } else {
      await audioOutput.ensureReady();
      await videoStart();
      analytics.trackCameraToggle(true);
    }
  }, [videoIsEnabled, videoStart, videoStop, audioOutput, analytics]);

  /**
   * å‘é€æ–‡æœ¬æ¶ˆæ¯
   * ğŸ”§ åŒæ—¶æ£€æŸ¥ sessionRefï¼ˆç”¨äºè¿æ¥åˆšå»ºç«‹æ—¶ï¼‰å’Œ isConnectedï¼ˆç”¨äºè¿æ¥æ–­å¼€æ—¶ï¼‰
   */
  const sendTextMessage = useCallback((text: string) => {
    // ğŸ”§ ä¸¤ä¸ªæ¡ä»¶éƒ½æ£€æŸ¥ï¼š
    // - sessionRef.current !== null: ç¡®ä¿ session å¯¹è±¡å­˜åœ¨ï¼ˆè§£å†³è¿æ¥åˆšå»ºç«‹æ—¶ state å»¶è¿Ÿé—®é¢˜ï¼‰
    // - session.isConnected: ç¡®ä¿ WebSocket æ²¡æœ‰æ–­å¼€
    const hasActiveSession = session.sessionRef.current !== null || session.isConnected;
    
    if (hasActiveSession) {
      session.sendRealtimeInput({ text });
      if (import.meta.env.DEV) {
        console.log('ğŸ“¤ [GeminiLive] å‘é€æ–‡æœ¬:', text.substring(0, 60) + (text.length > 60 ? '...' : ''));
      }
    } else if (import.meta.env.DEV) {
      console.warn('âš ï¸ [GeminiLive] å‘é€å¤±è´¥: è¿æ¥å·²æ–­å¼€');
    }
  }, [session.sessionRef, session.sendRealtimeInput, session.isConnected]);

  /**
   * è®¾ç½® onTurnComplete å›è°ƒ
   */
  const setOnTurnComplete = useCallback((handler: (() => void) | null | undefined) => {
    onTurnCompleteRef.current = handler ?? null;
  }, []);

  /**
   * ä¸­é€”æ›´æ–° System Instruction
   * 
   * ç”¨äºåœ¨ä¼šè¯è¿‡ç¨‹ä¸­åŠ¨æ€åˆ‡æ¢ AI çš„è¡Œä¸ºæ¨¡å¼ï¼Œä¾‹å¦‚ï¼š
   * - å½“ç”¨æˆ·æŒç»­æŠµæŠ—æ—¶ï¼Œåˆ‡æ¢åˆ°ä¸¥å‰è¯­æ°”
   * - å½“ç”¨æˆ·æƒ…ç»ªä½è½æ—¶ï¼Œåˆ‡æ¢åˆ°æ¸©å’Œè¯­æ°”
   * 
   * æ­¤æ–¹æ³•ä½¿ç”¨ Gemini Live API å®˜æ–¹æ”¯æŒçš„ system role æ¶ˆæ¯ï¼Œ
   * ä¸ä¼šå ç”¨å¯¹è¯ tokenï¼Œå¯¹å‰©ä½™æ•´ä¸ªä¼šè¯æŒä¹…ç”Ÿæ•ˆã€‚
   * 
   * @param instruction - æ–°çš„ç³»ç»ŸæŒ‡ä»¤å†…å®¹
   * 
   * @example
   * // åˆ‡æ¢åˆ°ä¸¥å‰æ¨¡å¼
   * updateSystemInstruction('ç”¨æˆ·æŒç»­æŠµæŠ—ã€‚ä»ç°åœ¨å¼€å§‹ä½¿ç”¨ä¸¥å‰ç›´æ¥çš„è¯­æ°”ï¼Œå¦‚ï¼š"å¥½äº†ï¼Œå€Ÿå£å¤Ÿå¤šäº†ã€‚3ã€2ã€1ï¼Œç«™èµ·æ¥ã€‚"');
   * 
   * @see https://docs.cloud.google.com/vertex-ai/generative-ai/docs/live-api/start-manage-session
   */
  const updateSystemInstruction = useCallback((instruction: string) => {
    if (!session.isConnected) {
      if (import.meta.env.DEV) {
        console.warn('âš ï¸ [GeminiLive] updateSystemInstruction å¤±è´¥: è¿æ¥å·²æ–­å¼€');
      }
      return;
    }

    session.sendClientContent({
      turns: {
        role: 'system',
        parts: [{ text: instruction }]
      },
      turnComplete: true
    });

    if (import.meta.env.DEV) {
      console.log('ğŸ­ [GeminiLive] System Instruction å·²æ›´æ–°:', instruction.substring(0, 80) + (instruction.length > 80 ? '...' : ''));
    }
  }, [session.isConnected, session.sendClientContent]);

  // ============================================================================
  // Auto-enable Effects
  // ä½¿ç”¨è§£æ„çš„ç¨³å®šå­—æ®µä½œä¸ºä¾èµ–ï¼Œé¿å…æ¯æ¬¡æ¸²æŸ“éƒ½è§¦å‘ effect
  // ============================================================================

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨æ‘„åƒå¤´
  useEffect(() => {
    if (session.isConnected && enableCamera && !videoIsEnabled) {
      queueMicrotask(() => {
        toggleCamera();
      });
    }
  }, [session.isConnected, enableCamera, videoIsEnabled, toggleCamera]);

  // è¿æ¥åè‡ªåŠ¨å¯ç”¨éº¦å…‹é£
  useEffect(() => {
    if (session.isConnected && enableMicrophone && !audioIsRecording) {
      queueMicrotask(() => {
        toggleMicrophone();
      });
    }
  }, [session.isConnected, enableMicrophone, audioIsRecording, toggleMicrophone]);

  // è¿æ¥åå¼€å§‹è§†é¢‘å¸§æ•è·
  useEffect(() => {
    if (session.isConnected && videoIsEnabled) {
      startFrameCapture();
    } else {
      stopFrameCapture();
    }
  }, [session.isConnected, videoIsEnabled, startFrameCapture, stopFrameCapture]);

  // ============================================================================
  // Return (ä¿æŒåŸæœ‰ API å…¼å®¹)
  // ============================================================================

  return {
    // State
    isConnected: session.isConnected,
    isRecording: audioIsRecording,
    isSpeaking: audioOutput.isSpeaking,
    // åˆå¹¶æ‰€æœ‰é”™è¯¯ï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
    error: [session.error, audioError, videoError].filter(Boolean).join('; ') || null,
    transcript: transcriptManager.transcript,
    cameraEnabled: videoIsEnabled,
    videoStream,
    audioStream,

    // Actions
    connect,
    disconnect,
    toggleMicrophone,
    toggleCamera,
    sendTextMessage,
    setOnTurnComplete,
    updateSystemInstruction,

    // Refs for UI
    videoRef,
    canvasRef,
  };
}

// Re-export for convenience
export { fetchGeminiToken };
export type { TranscriptEntry, ToolCallEvent };
