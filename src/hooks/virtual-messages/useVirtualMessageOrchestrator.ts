/**
 * # è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨ Hook
 *
 * æ ¸å¿ƒè°ƒåº¦å™¨ï¼Œæ•´åˆæ‰€æœ‰è™šæ‹Ÿæ¶ˆæ¯ç³»ç»Ÿç»„ä»¶ï¼š
 * - ConversationContextTracker: è¿½è¸ªå¯¹è¯ä¸Šä¸‹æ–‡
 * - TopicDetector: æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªå˜åŒ–
 * - AsyncMemoryPipeline: å¼‚æ­¥æ£€ç´¢ç›¸å…³è®°å¿†
 * - VirtualMessageQueue: æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†
 *
 * ## æ–¹æ¡ˆ A å®ç°ï¼šturnComplete åé™é»˜æ³¨å…¥
 *
 * æ ¸å¿ƒæµç¨‹ï¼š
 * 1. è¯é¢˜æ£€æµ‹ â†’ å¼‚æ­¥æ£€ç´¢è®°å¿†ï¼ˆä¸é˜»å¡ï¼‰
 * 2. ç›‘å¬ turnComplete äº‹ä»¶ï¼ˆAI è¯´å®Œè¯ï¼‰
 * 3. åœ¨å®‰å…¨çª—å£æœŸè°ƒç”¨ injectContextSilently
 * 4. è®°å¿†è¢«é™é»˜åŠ å…¥ä¸Šä¸‹æ–‡ï¼Œç­‰å¾…ä¸‹æ¬¡ AI è‡ªç„¶å¼•ç”¨
 *
 * ## ä½¿ç”¨ç¤ºä¾‹
 *
 * ```typescript
 * const orchestrator = useVirtualMessageOrchestrator({
 *   userId,
 *   taskDescription: 'å®Œæˆä»»åŠ¡',
 *   initialDuration: 300,
 *   taskStartTime: Date.now(),
 *   injectContextSilently: geminiLive.injectContextSilently,
 *   isSpeaking: geminiLive.isSpeaking,
 * })
 *
 * // å½“ç”¨æˆ·è¯´è¯æ—¶
 * orchestrator.onUserSpeech(text)
 *
 * // å½“ AI è¯´è¯æ—¶
 * orchestrator.onAISpeech(text)
 *
 * // å½“ AI è¯´å®Œè¯æ—¶ï¼ˆturnCompleteï¼‰
 * orchestrator.onTurnComplete()
 * ```
 *
 * @see docs/in-progress/20260127-dynamic-virtual-messages.md
 */

import { useCallback, useRef, useEffect } from 'react'
import { useConversationContextTracker } from './useConversationContextTracker'
import { useTopicDetector } from './useTopicDetector'
import { useAsyncMemoryPipeline, generateContextMessage } from './useAsyncMemoryPipeline'
import { useVirtualMessageQueue } from './useVirtualMessageQueue'
import type {
  VirtualMessageOrchestratorOptions,
  VirtualMessageType,
  TopicInfo,
  EmotionalState,
} from './types'
import { EMOTION_RESPONSE_THRESHOLD } from './constants'
import type { SuggestedAction } from '../useToneManager'

/**
 * è°ƒåº¦å™¨é…ç½®ï¼ˆæ‰©å±•åŸºç¡€é…ç½®ï¼‰
 */
interface UseVirtualMessageOrchestratorOptions extends VirtualMessageOrchestratorOptions {
  /**
   * é™é»˜æ³¨å…¥ä¸Šä¸‹æ–‡çš„å›è°ƒ
   * æ¥è‡ª useGeminiLive.injectContextSilently
   */
  injectContextSilently: (content: string, options?: { force?: boolean }) => boolean
  /**
   * AI æ˜¯å¦æ­£åœ¨è¯´è¯
   * æ¥è‡ª useGeminiLive.isSpeaking
   */
  isSpeaking: boolean
  /**
   * æ˜¯å¦å¯ç”¨è°ƒåº¦å™¨
   */
  enabled?: boolean
  /**
   * é¦–é€‰è¯­è¨€ï¼ˆç”¨äºç”Ÿæˆæ¶ˆæ¯æ—¶æºå¸¦è¯­è¨€ä¿¡æ¯ï¼‰
   */
  preferredLanguage?: string
}

/**
 * è¯é¢˜æ£€æµ‹ç»“æœï¼ˆç”¨äºæŠ—æ‹’åˆ†æï¼‰
 */
export interface TopicResultForResistance {
  topic: { id: string; name: string } | null
  emotion?: 'happy' | 'sad' | 'anxious' | 'frustrated' | 'tired' | 'neutral'
  emotionIntensity?: number
  confidence?: number
}

/**
 * è°ƒåº¦å™¨è¿”å›å€¼
 */
interface VirtualMessageOrchestratorResult {
  /** å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶ï¼ˆå¼‚æ­¥ï¼Œè°ƒç”¨ Semantic Router APIï¼‰ï¼Œè¿”å›è¯é¢˜æ£€æµ‹ç»“æœ */
  onUserSpeech: (text: string) => Promise<TopicResultForResistance | null>
  /** å¤„ç† AI è¯´è¯äº‹ä»¶ */
  onAISpeech: (text: string) => void
  /** å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰ */
  onTurnComplete: () => void
  /** æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰ */
  triggerMemoryRetrieval: (topic: string, keywords?: string[]) => Promise<void>
  /** è·å–å½“å‰é˜Ÿåˆ—å¤§å° */
  getQueueSize: () => number
  /** è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ */
  getContext: () => ReturnType<ReturnType<typeof useConversationContextTracker>['getContext']>
  /** é‡ç½®è°ƒåº¦å™¨çŠ¶æ€ */
  reset: () => void
  /** è¯é¢˜æ£€æµ‹å™¨æ˜¯å¦æ­£åœ¨åŠ è½½ */
  isDetecting: boolean
  /**
   * æ ¹æ®æŠ—æ‹’åˆ†æç»“æœå‘é€å¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   * @param suggestedAction - æ¥è‡ª analyzeResistance çš„å»ºè®®åŠ¨ä½œ
   * @returns æ˜¯å¦æˆåŠŸå…¥é˜Ÿ
   */
  sendMessageForAction: (suggestedAction: SuggestedAction) => boolean
  /**
   * å‘é€æ¸©æŸ”å¼•å¯¼æ¶ˆæ¯ï¼ˆç”¨äºæƒ…ç»ªç¨³å®šåå¼•å¯¼å›ä»»åŠ¡ï¼‰
   */
  sendGentleRedirect: () => boolean
}

/**
 * è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨
 */
export function useVirtualMessageOrchestrator(
  options: UseVirtualMessageOrchestratorOptions
): VirtualMessageOrchestratorResult {
  const {
    userId,
    taskDescription,
    initialDuration,
    taskStartTime,
    injectContextSilently,
    isSpeaking,
    enabled = true,
    enableMemoryRetrieval = true,
    cooldownMs = 5000,
    preferredLanguage = 'en-US',
  } = options

  // =====================================================
  // å­ Hooks
  // =====================================================

  // å¯¹è¯ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
  const contextTracker = useConversationContextTracker({
    taskDescription,
    initialDuration,
    taskStartTime,
  })

  // è¯é¢˜æ£€æµ‹å™¨
  const topicDetector = useTopicDetector()

  // å¼‚æ­¥è®°å¿†ç®¡é“
  const memoryPipeline = useAsyncMemoryPipeline(userId)

  // æ¶ˆæ¯é˜Ÿåˆ—
  const messageQueue = useVirtualMessageQueue({
    onSendMessage: (message) => injectContextSilently(message),
    cooldownMs,
    enabled,
  })

  // =====================================================
  // Refs
  // =====================================================

  // è¿½è¸ªä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯é¢˜
  const lastTopicRef = useRef<TopicInfo | null>(null)
  // è¿½è¸ªæ˜¯å¦æœ‰å¾…å‘é€çš„è®°å¿†æ¶ˆæ¯
  const pendingMemoryRef = useRef<boolean>(false)
  // è¿½è¸ª AI è¯´è¯çŠ¶æ€
  const isSpeakingRef = useRef<boolean>(isSpeaking)

  useEffect(() => {
    isSpeakingRef.current = isSpeaking
  }, [isSpeaking])

  // =====================================================
  // æ ¸å¿ƒæ–¹æ³•
  // =====================================================

  /**
   * ç”Ÿæˆæƒ…ç»ªå“åº”æ¶ˆæ¯ [EMPATHY]
   */
  const generateEmpathyMessage = useCallback((
    emotion: EmotionalState['primary'],
    intensity: number,
    trigger?: string
  ): string => {
    const currentTime = new Date().toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: false,
    })

    const context = contextTracker.getVirtualMessageContext()

    return `[EMPATHY] emotion=${emotion} intensity=${intensity.toFixed(1)}${trigger ? ` trigger="${trigger}"` : ''} current_time=${currentTime} language=${preferredLanguage}
conversation_context: ç”¨æˆ·æ­£åœ¨è®¨è®º"${context.currentTopic || 'æœªçŸ¥è¯é¢˜'}"ï¼Œåˆšä»"${context.topicFlow[context.topicFlow.length - 2] || 'æ— '}"è¯é¢˜è½¬è¿‡æ¥
last_ai_said: "${context.recentAISpeech?.substring(0, 50) || '(æ— )'}"
action: ä¼˜å…ˆå€¾å¬å’Œå®‰æ…°ï¼Œç­‰æƒ…ç»ªç¨³å®šåå†è½»æŸ”åœ°å¼•å¯¼å›ä»»åŠ¡ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * ç”Ÿæˆå€¾å¬æ¨¡å¼æ¶ˆæ¯ [LISTEN_FIRST]
   * ç”¨äºæƒ…æ„Ÿè¯é¢˜ï¼ŒAI åº”è¯¥è¿›å…¥å€¾å¬æ¨¡å¼ï¼Œæš‚æ—¶ä¸æ¨ä»»åŠ¡
   */
  const generateListenFirstMessage = useCallback((): string => {
    const context = contextTracker.getVirtualMessageContext()

    return `[LISTEN_FIRST] language=${preferredLanguage}
user_context: "${context.recentUserSpeech?.substring(0, 100) || '(æ— )'}"
topic: ${context.currentTopic || 'æœªçŸ¥'}
action: è¿›å…¥å€¾å¬æ¨¡å¼ã€‚ç”¨æˆ·åœ¨åˆ†äº«æƒ…æ„Ÿå†…å®¹ï¼Œæš‚åœä»»åŠ¡ç›¸å…³è¯é¢˜ã€‚ç”¨å¼€æ”¾å¼é—®é¢˜å¼•å¯¼ä»–ä»¬å€¾è¯‰ï¼Œä¸è¦æä»»åŠ¡ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * ç”Ÿæˆæ¸©æŸ”å¼•å¯¼æ¶ˆæ¯ [GENTLE_REDIRECT]
   * ç”¨äºæƒ…ç»ªç¨³å®šåï¼Œè½»æŸ”å¼•å¯¼å›ä»»åŠ¡
   */
  const generateGentleRedirectMessage = useCallback((): string => {
    const elapsedMinutes = Math.floor((Date.now() - taskStartTime) / 60000)

    return `[GENTLE_REDIRECT] elapsed=${elapsedMinutes}m language=${preferredLanguage}
action: ç”¨æˆ·æƒ…ç»ªçœ‹èµ·æ¥ç¨³å®šäº†ã€‚è½»æŸ”åœ°é—®ä»–ä»¬æ˜¯å¦æƒ³åšç‚¹ä»€ä¹ˆè½¬ç§»æ³¨æ„åŠ›ï¼ŒæŠŠä»»åŠ¡ä½œä¸º"å°äº‹"æå‡ºï¼Œå‹åŠ›è¦å°ã€‚`
  }, [taskStartTime, preferredLanguage])

  /**
   * ç”Ÿæˆæ¥å—åœæ­¢æ¶ˆæ¯ [ACCEPT_STOP]
   * ç”¨äºç”¨æˆ·æ˜ç¡®è¡¨ç¤ºä¸æƒ³åšæ—¶ï¼Œä¼˜é›…æ¥å—
   */
  const generateAcceptStopMessage = useCallback((): string => {
    return `[ACCEPT_STOP] language=${preferredLanguage}
action: ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºä¸æƒ³ç»§ç»­ã€‚ä¼˜é›…æ¥å—ä»–ä»¬çš„é€‰æ‹©ï¼Œä¸è¦è¯•å›¾è¯´æœæˆ–æä¾›æ›¿ä»£æ–¹æ¡ˆã€‚è®©ä»–ä»¬çŸ¥é“ä½ éšæ—¶åœ¨è¿™é‡Œã€‚`
  }, [preferredLanguage])

  /**
   * ç”Ÿæˆæ¨è¿›å°æ­¥éª¤æ¶ˆæ¯ [PUSH_TINY_STEP]
   * ç”¨äºæ™®é€šä»»åŠ¡æŠ—æ‹’ï¼ˆéæƒ…æ„Ÿï¼‰ï¼Œæ¨è¿›æ›´å°çš„æ­¥éª¤
   */
  const generatePushTinyStepMessage = useCallback((): string => {
    const context = contextTracker.getVirtualMessageContext()

    return `[PUSH_TINY_STEP] language=${preferredLanguage}
user_said: "${context.recentUserSpeech?.substring(0, 80) || '(æ— )'}"
task: ${taskDescription}
action: ç”¨æˆ·åœ¨æ‰¾å€Ÿå£ï¼ˆä¸æ˜¯æƒ…æ„Ÿå›°æ‰°ï¼‰ã€‚ç®€çŸ­æ‰¿è®¤ä»–ä»¬çš„å€Ÿå£ï¼Œç„¶åæä¾›ä¸€ä¸ªæ›´å°çš„æ­¥éª¤ã€‚ä¿æŒè½»æ¾çš„åšæŒã€‚`
  }, [contextTracker, taskDescription, preferredLanguage])

  /**
   * æ ¹æ®å»ºè®®åŠ¨ä½œç”Ÿæˆå¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   *
   * @param suggestedAction - æ¥è‡ª analyzeResistance çš„å»ºè®®åŠ¨ä½œ
   * @returns æ¶ˆæ¯å†…å®¹å’Œç±»å‹
   */
  const generateMessageForAction = useCallback((
    suggestedAction: SuggestedAction
  ): { content: string; type: VirtualMessageType } | null => {
    switch (suggestedAction) {
      case 'empathy':
        // é«˜å¼ºåº¦æƒ…æ„Ÿ â†’ EMPATHY æ¶ˆæ¯ï¼ˆå·²æœ‰é€»è¾‘å¤„ç†ï¼‰
        return null // ç”±ç°æœ‰ EMPATHY é€»è¾‘å¤„ç†

      case 'listen':
        return {
          content: generateListenFirstMessage(),
          type: 'LISTEN_FIRST',
        }

      case 'accept_stop':
        return {
          content: generateAcceptStopMessage(),
          type: 'ACCEPT_STOP',
        }

      case 'tiny_step':
        return {
          content: generatePushTinyStepMessage(),
          type: 'PUSH_TINY_STEP',
        }

      case 'tone_shift':
        // TONE_SHIFT ç”± ToneManager ç›´æ¥å¤„ç†
        return null

      default:
        return null
    }
  }, [generateListenFirstMessage, generateAcceptStopMessage, generatePushTinyStepMessage])

  /**
   * å¤„ç†è¯é¢˜å˜åŒ–ï¼Œè§¦å‘è®°å¿†æ£€ç´¢
   *
   * @param topic - æ£€æµ‹åˆ°çš„è¯é¢˜
   * @param emotionalState - æ£€æµ‹åˆ°çš„æƒ…ç»ª
   * @param memoryQuestions - Semantic Router è¿”å›çš„è®°å¿†æ£€ç´¢é—®é¢˜ï¼ˆå¯é€‰ï¼‰
   */
  const handleTopicChange = useCallback(async (
    topic: TopicInfo,
    emotionalState: EmotionalState,
    memoryQuestions?: string[]
  ) => {
    if (!enableMemoryRetrieval || !userId) {
      return
    }

    // æ ‡è®°æœ‰å¾…å¤„ç†çš„è®°å¿†
    pendingMemoryRef.current = true

    // ä½¿ç”¨ Semantic Router è¿”å›çš„è®°å¿†æ£€ç´¢é—®é¢˜ä½œä¸ºç§å­
    const seedQuestions = memoryQuestions || []

    // å¼‚æ­¥æ£€ç´¢è®°å¿†
    const memories = await memoryPipeline.fetchMemoriesForTopic(
      topic.name,
      topic.keywords,
      contextTracker.getContext().summary,
      seedQuestions
    )

    if (memories.length > 0) {
      // ç”Ÿæˆ [CONTEXT] æ¶ˆæ¯
      const contextMessage = generateContextMessage(
        memories,
        topic.name,
        emotionalState.primary,
        emotionalState.intensity
      )

      // å…¥é˜Ÿæ¶ˆæ¯
      messageQueue.enqueue({
        type: 'CONTEXT',
        priority: 'normal',
        content: contextMessage,
        relatedTopic: topic.name,
      })

      if (import.meta.env.DEV) {
        console.log(`ğŸ§  [Orchestrator] è®°å¿†æ£€ç´¢å®Œæˆï¼Œå·²å…¥é˜Ÿ CONTEXT æ¶ˆæ¯`, {
          topic: topic.name,
          memoriesCount: memories.length,
          queueSize: messageQueue.size(),
        })
      }
    }

    pendingMemoryRef.current = false
  }, [
    enableMemoryRetrieval,
    userId,
    memoryPipeline,
    contextTracker,
    messageQueue,
  ])

  /**
   * å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶ï¼ˆä½¿ç”¨ Semantic Router å¼‚æ­¥æ£€æµ‹ï¼‰
   * è¿”å›è¯é¢˜æ£€æµ‹ç»“æœï¼Œä¾›æŠ—æ‹’åˆ†æä½¿ç”¨
   */
  const onUserSpeech = useCallback(async (text: string): Promise<TopicResultForResistance | null> => {
    if (!enabled) return null

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addUserMessage(text)

    // å¼‚æ­¥æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªï¼ˆè°ƒç”¨ Semantic Router APIï¼‰
    const result = await topicDetector.detectFromMessageAsync(text)

    // æ›´æ–°æƒ…ç»ªçŠ¶æ€
    if (result.emotionalState.primary !== 'neutral') {
      contextTracker.updateEmotionalState(result.emotionalState)
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æƒ…ç»ªå“åº”
    if (
      result.emotionalState.intensity >= EMOTION_RESPONSE_THRESHOLD &&
      result.emotionalState.primary !== 'neutral'
    ) {
      // ç”Ÿæˆ [EMPATHY] æ¶ˆæ¯å¹¶å…¥é˜Ÿï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
      const empathyMessage = generateEmpathyMessage(
        result.emotionalState.primary,
        result.emotionalState.intensity,
        result.emotionalState.trigger
      )

      messageQueue.enqueue({
        type: 'EMPATHY',
        priority: 'urgent',
        content: empathyMessage,
      })

      if (import.meta.env.DEV) {
        console.log(`ğŸ’— [Orchestrator] æ£€æµ‹åˆ°å¼ºçƒˆæƒ…ç»ªï¼Œå·²å…¥é˜Ÿ EMPATHY æ¶ˆæ¯`, {
          emotion: result.emotionalState.primary,
          intensity: result.emotionalState.intensity,
        })
      }
    }

    // å¤„ç†è¯é¢˜å˜åŒ–
    if (result.topic) {
      contextTracker.updateTopic(result.topic)

      if (result.isTopicChanged) {
        lastTopicRef.current = result.topic

        if (import.meta.env.DEV) {
          console.log(`ğŸ·ï¸ [Orchestrator] è¯é¢˜å˜åŒ–: ${result.topic.name}`, {
            confidence: result.confidence ? `${(result.confidence * 100).toFixed(1)}%` : 'N/A',
            shouldRetrieveMemory: result.shouldRetrieveMemory,
          })
        }

        // å¦‚æœ Semantic Router å»ºè®®æ£€ç´¢è®°å¿†ï¼Œè§¦å‘å¼‚æ­¥è®°å¿†æ£€ç´¢
        if (result.shouldRetrieveMemory) {
          handleTopicChange(result.topic, result.emotionalState, result.memoryQuestions)
        }
      }
    }

    // è¿”å›è¯é¢˜æ£€æµ‹ç»“æœï¼ˆç”¨äºæŠ—æ‹’åˆ†æï¼‰
    return {
      topic: result.topic ? { id: result.topic.id, name: result.topic.name } : null,
      emotion: result.emotionalState.primary,
      emotionIntensity: result.emotionalState.intensity,
      confidence: result.confidence,
    }
  }, [
    enabled,
    contextTracker,
    topicDetector,
    messageQueue,
    generateEmpathyMessage,
    handleTopicChange,
  ])

  /**
   * å¤„ç† AI è¯´è¯äº‹ä»¶
   */
  const onAISpeech = useCallback((text: string) => {
    if (!enabled) return

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addAIMessage(text)
  }, [enabled, contextTracker])

  /**
   * å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰
   *
   * è¿™æ˜¯æ–¹æ¡ˆ A çš„æ ¸å¿ƒï¼šåœ¨å®‰å…¨çª—å£æœŸå°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
   */
  const onTurnComplete = useCallback(() => {
    if (!enabled) return

    if (import.meta.env.DEV) {
      console.log(`âœ… [Orchestrator] turnComplete - å°è¯•å‘é€é˜Ÿåˆ—æ¶ˆæ¯`, {
        queueSize: messageQueue.size(),
        isInCooldown: messageQueue.isInCooldown(),
      })
    }

    // å°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
    // injectContextSilently ä¼šæ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨çª—å£æœŸ
    const sent = messageQueue.tryFlush()

    if (sent && import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] æˆåŠŸå‘é€é˜Ÿåˆ—æ¶ˆæ¯`)
    }
  }, [enabled, messageQueue])

  /**
   * æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰
   */
  const triggerMemoryRetrieval = useCallback(async (
    topic: string,
    keywords: string[] = []
  ) => {
    if (!userId) return

    const memories = await memoryPipeline.fetchMemoriesForTopic(topic, keywords)

    if (memories.length > 0) {
      const contextMessage = generateContextMessage(
        memories,
        topic,
        'neutral',
        0.5
      )

      messageQueue.enqueue({
        type: 'CONTEXT',
        priority: 'normal',
        content: contextMessage,
        relatedTopic: topic,
      })
    }
  }, [userId, memoryPipeline, messageQueue])

  /**
   * è·å–é˜Ÿåˆ—å¤§å°
   */
  const getQueueSize = useCallback(() => {
    return messageQueue.size()
  }, [messageQueue])

  /**
   * è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
   */
  const getContext = useCallback(() => {
    return contextTracker.getContext()
  }, [contextTracker])

  /**
   * é‡ç½®è°ƒåº¦å™¨çŠ¶æ€
   */
  const reset = useCallback(() => {
    contextTracker.resetContext()
    messageQueue.clear()
    lastTopicRef.current = null
    pendingMemoryRef.current = false

    if (import.meta.env.DEV) {
      console.log(`ğŸ”„ [Orchestrator] çŠ¶æ€å·²é‡ç½®`)
    }
  }, [contextTracker, messageQueue])

  /**
   * æ ¹æ®æŠ—æ‹’åˆ†æç»“æœå‘é€å¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   *
   * @param suggestedAction - æ¥è‡ª analyzeResistance çš„å»ºè®®åŠ¨ä½œ
   * @returns æ˜¯å¦æˆåŠŸå…¥é˜Ÿ
   */
  const sendMessageForAction = useCallback((suggestedAction: SuggestedAction): boolean => {
    const messageData = generateMessageForAction(suggestedAction)

    if (!messageData) {
      // empathy å’Œ tone_shift ç”±å…¶ä»–é€»è¾‘å¤„ç†
      return false
    }

    // æ ¹æ®æ¶ˆæ¯ç±»å‹è®¾ç½®ä¼˜å…ˆçº§
    const priority = messageData.type === 'LISTEN_FIRST' ? 'urgent' as const
      : messageData.type === 'ACCEPT_STOP' ? 'high' as const
      : 'high' as const

    messageQueue.enqueue({
      type: messageData.type,
      priority,
      content: messageData.content,
    })

    if (import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] å…¥é˜Ÿ ${messageData.type} æ¶ˆæ¯ (action: ${suggestedAction})`)
    }

    return true
  }, [generateMessageForAction, messageQueue])

  /**
   * å‘é€æ¸©æŸ”å¼•å¯¼æ¶ˆæ¯
   * ç”¨äºæƒ…ç»ªç¨³å®šåå¼•å¯¼å›ä»»åŠ¡
   */
  const sendGentleRedirect = useCallback((): boolean => {
    const content = generateGentleRedirectMessage()

    messageQueue.enqueue({
      type: 'GENTLE_REDIRECT',
      priority: 'normal',
      content,
    })

    if (import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] å…¥é˜Ÿ GENTLE_REDIRECT æ¶ˆæ¯`)
    }

    return true
  }, [generateGentleRedirectMessage, messageQueue])

  return {
    onUserSpeech,
    onAISpeech,
    onTurnComplete,
    triggerMemoryRetrieval,
    getQueueSize,
    getContext,
    reset,
    isDetecting: topicDetector.isLoading,
    sendMessageForAction,
    sendGentleRedirect,
  }
}

export type { VirtualMessageOrchestratorResult }
