/**
 * # è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨ Hook
 *
 * æ ¸å¿ƒè°ƒåº¦å™¨ï¼Œæ•´åˆæ‰€æœ‰è™šæ‹Ÿæ¶ˆæ¯ç³»ç»Ÿç»„ä»¶ï¼š
 * - ConversationContextTracker: è¿½è¸ªå¯¹è¯ä¸Šä¸‹æ–‡
 * - TopicDetector: æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªå˜åŒ–ï¼ˆå‘é‡åŒ¹é…ï¼‰
 * - AsyncMemoryPipeline: å¼‚æ­¥æ£€ç´¢ç›¸å…³è®°å¿†
 *
 * ## æ–¹æ¡ˆ B å®ç°ï¼šåŒæ­¥ç­‰å¾…è®°å¿† + é™é»˜æ³¨å…¥
 *
 * æ ¸å¿ƒæµç¨‹ï¼š
 * 1. ç”¨æˆ·è¯´è¯ â†’ åŒæ­¥ç­‰å¾…è®°å¿†æ£€ç´¢ï¼ˆæœ€å¤š1ç§’ï¼‰
 * 2. è®°å¿† + ç”¨æˆ·çš„è¯é™é»˜æ³¨å…¥ï¼ˆturnComplete=falseï¼‰
 * 3. AI å¸¦ç€è®°å¿†è‡ªç„¶å›å¤
 *
 * @see docs/in-progress/20260127-dynamic-virtual-messages.md
 */

import { useCallback, useRef, useEffect } from 'react'
import { useConversationContextTracker } from './useConversationContextTracker'
import { useTopicDetector } from './useTopicDetector'
import { useAsyncMemoryPipeline, generateContextMessage } from './useAsyncMemoryPipeline'
import type {
  VirtualMessageOrchestratorOptions,
  VirtualMessageType,
  TopicInfo,
  EmotionalState,
} from './types'
import { EMOTION_RESPONSE_THRESHOLD } from './constants'
import type { SuggestedAction } from '../useToneManager'

/**
 * è°ƒåº¦å™¨é…ç½®ï¼ˆæ‰©å±•åŸºç¡€é…ç½®ï¼‰
 */
interface UseVirtualMessageOrchestratorOptions extends Omit<VirtualMessageOrchestratorOptions, 'onSendMessage' | 'cooldownMs'> {
  /**
   * å‘é€å®¢æˆ·ç«¯å†…å®¹çš„å›è°ƒï¼ˆç«‹å³æ³¨å…¥ï¼‰
   * æ¥è‡ª useGeminiLive.sendClientContent
   * @param content - è¦å‘é€çš„å†…å®¹
   * @param turnComplete - true=è§¦å‘AIå“åº”, false=é™é»˜ï¼ˆä½†ä¼šé˜»å¡åç»­è¾“å…¥ï¼Œä¸æ¨èï¼‰
   * @param role - 'user' æˆ– 'system'ï¼Œç”¨ 'system' æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡
   */
  sendClientContent: (content: string, turnComplete?: boolean, role?: 'user' | 'system') => void
  /**
   * AI æ˜¯å¦æ­£åœ¨è¯´è¯
   * æ¥è‡ª useGeminiLive.isSpeaking
   */
  isSpeaking: boolean
  /**
   * æ˜¯å¦å¯ç”¨è°ƒåº¦å™¨
   */
  enabled?: boolean
  /**
   * é¦–é€‰è¯­è¨€ï¼ˆç”¨äºç”Ÿæˆæ¶ˆæ¯æ—¶æºå¸¦è¯­è¨€ä¿¡æ¯ï¼‰
   */
  preferredLanguage?: string
}

/**
 * è¯é¢˜æ£€æµ‹ç»“æœï¼ˆç”¨äºæŠ—æ‹’åˆ†æï¼‰
 */
export interface TopicResultForResistance {
  topic: { id: string; name: string } | null
  emotion?: 'happy' | 'sad' | 'anxious' | 'frustrated' | 'tired' | 'neutral'
  emotionIntensity?: number
  confidence?: number
}

/**
 * è°ƒåº¦å™¨è¿”å›å€¼
 */
interface VirtualMessageOrchestratorResult {
  /** å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶ï¼ˆå¼‚æ­¥ï¼‰ï¼Œè¿”å›è¯é¢˜æ£€æµ‹ç»“æœ */
  onUserSpeech: (text: string) => Promise<TopicResultForResistance | null>
  /** å¤„ç† AI è¯´è¯äº‹ä»¶ */
  onAISpeech: (text: string) => void
  /** å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰- æ–¹æ¡ˆ 2 ä¸­ä»…ç”¨äºæ›´æ–°çŠ¶æ€ */
  onTurnComplete: () => void
  /** æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰ */
  triggerMemoryRetrieval: (topic: string, keywords?: string[]) => Promise<void>
  /** è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ */
  getContext: () => ReturnType<ReturnType<typeof useConversationContextTracker>['getContext']>
  /** é‡ç½®è°ƒåº¦å™¨çŠ¶æ€ */
  reset: () => void
  /** è¯é¢˜æ£€æµ‹å™¨æ˜¯å¦æ­£åœ¨æ£€æµ‹ */
  isDetecting: boolean
  /**
   * æ ¹æ®æŠ—æ‹’åˆ†æç»“æœå‘é€å¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   * @param suggestedAction - æ¥è‡ª analyzeResistance çš„å»ºè®®åŠ¨ä½œ
   * @returns æ˜¯å¦æˆåŠŸå‘é€
   */
  sendMessageForAction: (suggestedAction: SuggestedAction) => boolean
  /**
   * å‘é€æ¸©æŸ”å¼•å¯¼æ¶ˆæ¯ï¼ˆç”¨äºæƒ…ç»ªç¨³å®šåå¼•å¯¼å›ä»»åŠ¡ï¼‰
   */
  sendGentleRedirect: () => boolean
}

/**
 * è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨ï¼ˆæ–¹æ¡ˆ Bï¼šåŒæ­¥ç­‰å¾…è®°å¿†ï¼‰
 */
export function useVirtualMessageOrchestrator(
  options: UseVirtualMessageOrchestratorOptions
): VirtualMessageOrchestratorResult {
  const {
    userId,
    taskDescription,
    initialDuration,
    taskStartTime,
    sendClientContent,
    isSpeaking,
    enabled = true,
    enableMemoryRetrieval = true,
    preferredLanguage = 'en-US',
  } = options

  // =====================================================
  // å­ Hooks
  // =====================================================

  // å¯¹è¯ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
  const contextTracker = useConversationContextTracker({
    taskDescription,
    initialDuration,
    taskStartTime,
  })

  // è¯é¢˜æ£€æµ‹å™¨ï¼ˆå‘é‡ç‰ˆï¼‰
  const topicDetector = useTopicDetector()

  // å¼‚æ­¥è®°å¿†ç®¡é“
  const memoryPipeline = useAsyncMemoryPipeline(userId)

  // =====================================================
  // Refs
  // =====================================================

  // è¿½è¸ªä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯é¢˜
  const lastTopicRef = useRef<TopicInfo | null>(null)
  // è¿½è¸ª AI è¯´è¯çŠ¶æ€
  const isSpeakingRef = useRef<boolean>(isSpeaking)

  useEffect(() => {
    isSpeakingRef.current = isSpeaking
  }, [isSpeaking])

  // =====================================================
  // æ ¸å¿ƒæ–¹æ³•ï¼šç«‹å³æ³¨å…¥
  // =====================================================

  /**
   * ç«‹å³æ³¨å…¥è™šæ‹Ÿæ¶ˆæ¯
   * ä½¿ç”¨ sendClientContent + turnComplete=true + role='user'
   * æ³¨æ„ï¼šGemini Live API åªæ”¯æŒ role='user'ï¼Œä¸æ”¯æŒ 'system'
   * AI ä¼šç”¨è¿‡æ¸¡è¯å“åº”ï¼Œç„¶åå¼•ç”¨æ³¨å…¥çš„ä¸Šä¸‹æ–‡
   */
  const injectMessageImmediately = useCallback((content: string, type: VirtualMessageType) => {
    const timestamp = new Date().toLocaleTimeString()
    console.log(`\nğŸ’‰ [${timestamp}] ========== ç«‹å³æ³¨å…¥ ${type} ==========`)
    console.log(`ğŸ’‰ [Orchestrator] å†…å®¹é¢„è§ˆ: ${content.substring(0, 100)}...`)

    // Gemini Live API åªæ”¯æŒ role='user'ï¼Œæ‰€ä»¥ç”¨ [CONTEXT] æ ‡ç­¾è®© AI è¯†åˆ«è¿™æ˜¯ç³»ç»ŸæŒ‡ä»¤
    // turnComplete=true è§¦å‘ AI å“åº”ï¼ˆAI ä¼šç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼‰
    sendClientContent(content, true, 'user')

    console.log(`ğŸ’‰ [Orchestrator] âœ… å·²æ³¨å…¥ï¼Œç­‰å¾… AI å“åº”`)
  }, [sendClientContent])

  // =====================================================
  // æ¶ˆæ¯ç”Ÿæˆæ–¹æ³•
  // =====================================================

  /**
   * ç”Ÿæˆæƒ…ç»ªå“åº”æ¶ˆæ¯ [EMPATHY]
   */
  const generateEmpathyMessage = useCallback((
    emotion: EmotionalState['primary'],
    intensity: number,
    trigger?: string
  ): string => {
    const currentTime = new Date().toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: false,
    })

    const context = contextTracker.getVirtualMessageContext()

    return `[EMPATHY] emotion=${emotion} intensity=${intensity.toFixed(1)}${trigger ? ` trigger="${trigger}"` : ''} current_time=${currentTime} language=${preferredLanguage}
conversation_context: ç”¨æˆ·æ­£åœ¨è®¨è®º"${context.currentTopic || 'æœªçŸ¥è¯é¢˜'}"
last_user_said: "${context.recentUserSpeech?.substring(0, 50) || '(æ— )'}"
action: ç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼ˆå¦‚ "I hear you..." æˆ– "That sounds tough..."ï¼‰ï¼Œç„¶åå€¾å¬å’Œå®‰æ…°ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * ç”Ÿæˆå€¾å¬æ¨¡å¼æ¶ˆæ¯ [LISTEN_FIRST]
   */
  const generateListenFirstMessage = useCallback((): string => {
    const context = contextTracker.getVirtualMessageContext()

    return `[LISTEN_FIRST] language=${preferredLanguage}
user_context: "${context.recentUserSpeech?.substring(0, 100) || '(æ— )'}"
topic: ${context.currentTopic || 'æœªçŸ¥'}
action: ç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼Œç„¶åè¿›å…¥å€¾å¬æ¨¡å¼ã€‚ç”¨æˆ·åœ¨åˆ†äº«æƒ…æ„Ÿå†…å®¹ï¼Œæš‚åœä»»åŠ¡ç›¸å…³è¯é¢˜ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * ç”Ÿæˆæ¸©æŸ”å¼•å¯¼æ¶ˆæ¯ [GENTLE_REDIRECT]
   */
  const generateGentleRedirectMessage = useCallback((): string => {
    const elapsedMinutes = Math.floor((Date.now() - taskStartTime) / 60000)

    return `[GENTLE_REDIRECT] elapsed=${elapsedMinutes}m language=${preferredLanguage}
action: ç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼Œç„¶åè½»æŸ”åœ°é—®ç”¨æˆ·æ˜¯å¦æƒ³åšç‚¹ä»€ä¹ˆè½¬ç§»æ³¨æ„åŠ›ã€‚`
  }, [taskStartTime, preferredLanguage])

  /**
   * ç”Ÿæˆæ¥å—åœæ­¢æ¶ˆæ¯ [ACCEPT_STOP]
   */
  const generateAcceptStopMessage = useCallback((): string => {
    return `[ACCEPT_STOP] language=${preferredLanguage}
action: ç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼ˆå¦‚ "I get it..."ï¼‰ï¼Œç„¶åä¼˜é›…æ¥å—ç”¨æˆ·çš„é€‰æ‹©ï¼Œä¸è¦è¯•å›¾è¯´æœã€‚`
  }, [preferredLanguage])

  /**
   * ç”Ÿæˆæ¨è¿›å°æ­¥éª¤æ¶ˆæ¯ [PUSH_TINY_STEP]
   */
  const generatePushTinyStepMessage = useCallback((): string => {
    const context = contextTracker.getVirtualMessageContext()

    return `[PUSH_TINY_STEP] language=${preferredLanguage}
user_said: "${context.recentUserSpeech?.substring(0, 80) || '(æ— )'}"
task: ${taskDescription}
action: ç”¨è¿‡æ¸¡è¯å¼€å¤´ï¼Œç®€çŸ­æ‰¿è®¤ç”¨æˆ·çš„å€Ÿå£ï¼Œç„¶åæä¾›ä¸€ä¸ªæ›´å°çš„æ­¥éª¤ã€‚`
  }, [contextTracker, taskDescription, preferredLanguage])

  /**
   * æ ¹æ®å»ºè®®åŠ¨ä½œç”Ÿæˆå¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   */
  const generateMessageForAction = useCallback((
    suggestedAction: SuggestedAction
  ): { content: string; type: VirtualMessageType } | null => {
    switch (suggestedAction) {
      case 'empathy':
        return null // ç”± EMPATHY é€»è¾‘å¤„ç†

      case 'listen':
        return {
          content: generateListenFirstMessage(),
          type: 'LISTEN_FIRST',
        }

      case 'accept_stop':
        return {
          content: generateAcceptStopMessage(),
          type: 'ACCEPT_STOP',
        }

      case 'tiny_step':
        return {
          content: generatePushTinyStepMessage(),
          type: 'PUSH_TINY_STEP',
        }

      case 'tone_shift':
        return null // ç”± ToneManager å¤„ç†

      default:
        return null
    }
  }, [generateListenFirstMessage, generateAcceptStopMessage, generatePushTinyStepMessage])

  // =====================================================
  // äº‹ä»¶å¤„ç†
  // =====================================================

  /**
   * å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶
   */
  const onUserSpeech = useCallback(async (text: string): Promise<TopicResultForResistance | null> => {
    if (!enabled) return null

    const timestamp = new Date().toLocaleTimeString()
    console.log(`\nğŸ¤ [${timestamp}] ========== ç”¨æˆ·è¯´è¯ ==========`)
    console.log(`ğŸ¤ [Orchestrator] å†…å®¹: "${text.substring(0, 50)}..."`)

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addUserMessage(text)

    // å¼‚æ­¥æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªï¼ˆå‘é‡åŒ¹é…ï¼‰
    console.log(`ğŸ” [Orchestrator] å¼€å§‹è¯é¢˜æ£€æµ‹...`)
    const result = await topicDetector.detectFromMessage(text)

    console.log(`ğŸ” [Orchestrator] è¯é¢˜æ£€æµ‹å®Œæˆ:`, {
      topic: result.topic?.name || 'æ— ',
      confidence: result.confidence ? `${(result.confidence * 100).toFixed(1)}%` : 'N/A',
      emotion: result.emotionalState.primary,
      isTopicChanged: result.isTopicChanged,
    })

    // æ›´æ–°æƒ…ç»ªçŠ¶æ€
    if (result.emotionalState.primary !== 'neutral') {
      contextTracker.updateEmotionalState(result.emotionalState)
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æƒ…ç»ªå“åº”
    if (
      result.emotionalState.intensity >= EMOTION_RESPONSE_THRESHOLD &&
      result.emotionalState.primary !== 'neutral'
    ) {
      console.log(`\nğŸ’— [${timestamp}] ========== è§¦å‘æƒ…ç»ªå“åº” ==========`)

      const empathyMessage = generateEmpathyMessage(
        result.emotionalState.primary,
        result.emotionalState.intensity,
        result.emotionalState.trigger
      )

      // ğŸ†• æ–¹æ¡ˆ 2ï¼šé™é»˜æ³¨å…¥
      sendClientContent(empathyMessage, false, 'user')
      console.log(`âœ… [Orchestrator] EMPATHY å·²é™é»˜æ³¨å…¥`) 
    }

    // å¤„ç†è¯é¢˜å˜åŒ–ï¼ˆç”¨äºä¸Šä¸‹æ–‡è¿½è¸ªï¼‰
    if (result.topic) {
      contextTracker.updateTopic(result.topic)

      if (result.isTopicChanged) {
        console.log(`\nğŸ·ï¸ [${timestamp}] ========== è¯é¢˜å˜åŒ– ==========`)
        console.log(`ğŸ·ï¸ [Orchestrator] æ–°è¯é¢˜: "${result.topic.name}"`)
        lastTopicRef.current = result.topic
      }
    }

    // ğŸ”§ æ–¹æ¡ˆ Bï¼šåŒæ­¥ç­‰å¾…è®°å¿†æ£€ç´¢ï¼Œç«‹å³é™é»˜æ³¨å…¥
    if (enableMemoryRetrieval && userId && text.length > 5) {
      console.log(`\nğŸ” [${timestamp}] ========== åŒæ­¥æ£€ç´¢è®°å¿† ==========`)
      console.log(`ğŸ” [Orchestrator] æœç´¢è¯: "${text.substring(0, 30)}..."`)

      // åŒæ­¥ç­‰å¾…è®°å¿†æ£€ç´¢å®Œæˆ
      const memories = await memoryPipeline.fetchMemoriesForTopic(
        text,
        [],
        contextTracker.getContext().summary
      )

      if (memories.length > 0) {
        console.log(`ğŸ” [Orchestrator] æ‰¾åˆ° ${memories.length} æ¡è®°å¿†ï¼Œç«‹å³é™é»˜æ³¨å…¥`)
        memories.forEach((m, i) => {
          console.log(`   ${i + 1}. [${m.tag}] ${m.content}`)
        })

        const contextMessage = generateContextMessage(
          memories,
          result.topic?.name || 'å¯¹è¯',
          result.emotionalState.primary,
          result.emotionalState.intensity
        )

        // âœ… é™é»˜æ³¨å…¥ï¼ˆturnComplete=falseï¼‰ï¼ŒAI å›å¤æ—¶ä¼šè‡ªç„¶å¼•ç”¨
        sendClientContent(contextMessage, false, 'user')
        console.log(`âœ… [Orchestrator] è®°å¿†å·²æ³¨å…¥ï¼ŒAI å°†å¸¦ç€è®°å¿†å›å¤`)
      } else {
        console.log(`ğŸ” [Orchestrator] æœªæ‰¾åˆ°ç›¸å…³è®°å¿†`)
      }
    }

    // è¿”å›è¯é¢˜æ£€æµ‹ç»“æœï¼ˆç”¨äºæŠ—æ‹’åˆ†æï¼‰
    return {
      topic: result.topic ? { id: result.topic.id, name: result.topic.name } : null,
      emotion: result.emotionalState.primary,
      emotionIntensity: result.emotionalState.intensity,
      confidence: result.confidence,
    }
  }, [
    enabled,
    enableMemoryRetrieval,
    userId,
    contextTracker,
    topicDetector,
    memoryPipeline,
    generateEmpathyMessage,
    sendClientContent,
  ])

  /**
   * å¤„ç† AI è¯´è¯äº‹ä»¶
   */
  const onAISpeech = useCallback((text: string) => {
    if (!enabled) return
    contextTracker.addAIMessage(text)
  }, [enabled, contextTracker])

  /**
   * å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰
   */
  const onTurnComplete = useCallback(() => {
    if (!enabled) return

    const timestamp = new Date().toLocaleTimeString()

    if (import.meta.env.DEV) {
      console.log(`\nâœ… [${timestamp}] ========== AI è¯´å®Œè¯ (turnComplete) ==========`)
    }
  }, [enabled])

  /**
   * æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰
   */
  const triggerMemoryRetrieval = useCallback(async (
    topic: string,
    keywords: string[] = []
  ) => {
    if (!userId) return

    const memories = await memoryPipeline.fetchMemoriesForTopic(topic, keywords)

    if (memories.length > 0) {
      const contextMessage = generateContextMessage(
        memories,
        topic,
        'neutral',
        0.5
      )

      injectMessageImmediately(contextMessage, 'CONTEXT')
    }
  }, [userId, memoryPipeline, injectMessageImmediately])

  /**
   * è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
   */
  const getContext = useCallback(() => {
    return contextTracker.getContext()
  }, [contextTracker])

  /**
   * é‡ç½®è°ƒåº¦å™¨çŠ¶æ€
   */
  const reset = useCallback(() => {
    contextTracker.resetContext()
    topicDetector.reset()
    lastTopicRef.current = null

    if (import.meta.env.DEV) {
      console.log(`ğŸ”„ [Orchestrator] çŠ¶æ€å·²é‡ç½®`)
    }
  }, [contextTracker, topicDetector])

  /**
   * æ ¹æ®æŠ—æ‹’åˆ†æç»“æœå‘é€å¯¹åº”çš„è™šæ‹Ÿæ¶ˆæ¯
   */
  const sendMessageForAction = useCallback((suggestedAction: SuggestedAction): boolean => {
    const messageData = generateMessageForAction(suggestedAction)

    if (!messageData) {
      return false
    }

    // ğŸ†• æ–¹æ¡ˆ 2ï¼šç«‹å³æ³¨å…¥
    injectMessageImmediately(messageData.content, messageData.type)

    if (import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] å·²å‘é€ ${messageData.type} æ¶ˆæ¯ (action: ${suggestedAction})`)
    }

    return true
  }, [generateMessageForAction, injectMessageImmediately])

  /**
   * å‘é€æ¸©æŸ”å¼•å¯¼æ¶ˆæ¯
   */
  const sendGentleRedirect = useCallback((): boolean => {
    const content = generateGentleRedirectMessage()

    injectMessageImmediately(content, 'GENTLE_REDIRECT')

    if (import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] å·²å‘é€ GENTLE_REDIRECT æ¶ˆæ¯`)
    }

    return true
  }, [generateGentleRedirectMessage, injectMessageImmediately])

  return {
    onUserSpeech,
    onAISpeech,
    onTurnComplete,
    triggerMemoryRetrieval,
    getContext,
    reset,
    isDetecting: topicDetector.isDetecting,
    sendMessageForAction,
    sendGentleRedirect,
  }
}

export type { VirtualMessageOrchestratorResult }
