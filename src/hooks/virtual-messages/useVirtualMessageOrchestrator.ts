/**
 * # è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨ Hook
 *
 * æ ¸å¿ƒè°ƒåº¦å™¨ï¼Œæ•´åˆæ‰€æœ‰è™šæ‹Ÿæ¶ˆæ¯ç³»ç»Ÿç»„ä»¶ï¼š
 * - ConversationContextTracker: è¿½è¸ªå¯¹è¯ä¸Šä¸‹æ–‡
 * - TopicDetector: æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªå˜åŒ–
 * - AsyncMemoryPipeline: å¼‚æ­¥æ£€ç´¢ç›¸å…³è®°å¿†
 * - VirtualMessageQueue: æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†
 *
 * ## æ–¹æ¡ˆ A å®ç°ï¼šturnComplete åé™é»˜æ³¨å…¥
 *
 * æ ¸å¿ƒæµç¨‹ï¼š
 * 1. è¯é¢˜æ£€æµ‹ â†’ å¼‚æ­¥æ£€ç´¢è®°å¿†ï¼ˆä¸é˜»å¡ï¼‰
 * 2. ç›‘å¬ turnComplete äº‹ä»¶ï¼ˆAI è¯´å®Œè¯ï¼‰
 * 3. åœ¨å®‰å…¨çª—å£æœŸè°ƒç”¨ injectContextSilently
 * 4. è®°å¿†è¢«é™é»˜åŠ å…¥ä¸Šä¸‹æ–‡ï¼Œç­‰å¾…ä¸‹æ¬¡ AI è‡ªç„¶å¼•ç”¨
 *
 * ## ä½¿ç”¨ç¤ºä¾‹
 *
 * ```typescript
 * const orchestrator = useVirtualMessageOrchestrator({
 *   userId,
 *   taskDescription: 'å®Œæˆä»»åŠ¡',
 *   initialDuration: 300,
 *   taskStartTime: Date.now(),
 *   injectContextSilently: geminiLive.injectContextSilently,
 *   isSpeaking: geminiLive.isSpeaking,
 * })
 *
 * // å½“ç”¨æˆ·è¯´è¯æ—¶
 * orchestrator.onUserSpeech(text)
 *
 * // å½“ AI è¯´è¯æ—¶
 * orchestrator.onAISpeech(text)
 *
 * // å½“ AI è¯´å®Œè¯æ—¶ï¼ˆturnCompleteï¼‰
 * orchestrator.onTurnComplete()
 * ```
 *
 * @see docs/in-progress/20260127-dynamic-virtual-messages.md
 */

import { useCallback, useRef, useEffect } from 'react'
import { useConversationContextTracker } from './useConversationContextTracker'
import { useTopicDetector } from './useTopicDetector'
import { useAsyncMemoryPipeline, generateContextMessage } from './useAsyncMemoryPipeline'
import { useVirtualMessageQueue } from './useVirtualMessageQueue'
import type {
  VirtualMessageOrchestratorOptions,
  TopicInfo,
  EmotionalState,
} from './types'
import { EMOTION_RESPONSE_THRESHOLD } from './constants'

/**
 * è°ƒåº¦å™¨é…ç½®ï¼ˆæ‰©å±•åŸºç¡€é…ç½®ï¼‰
 */
interface UseVirtualMessageOrchestratorOptions extends VirtualMessageOrchestratorOptions {
  /**
   * é™é»˜æ³¨å…¥ä¸Šä¸‹æ–‡çš„å›è°ƒ
   * æ¥è‡ª useGeminiLive.injectContextSilently
   */
  injectContextSilently: (content: string, options?: { force?: boolean }) => boolean
  /**
   * AI æ˜¯å¦æ­£åœ¨è¯´è¯
   * æ¥è‡ª useGeminiLive.isSpeaking
   */
  isSpeaking: boolean
  /**
   * æ˜¯å¦å¯ç”¨è°ƒåº¦å™¨
   */
  enabled?: boolean
  /**
   * é¦–é€‰è¯­è¨€ï¼ˆç”¨äºç”Ÿæˆæ¶ˆæ¯æ—¶æºå¸¦è¯­è¨€ä¿¡æ¯ï¼‰
   */
  preferredLanguage?: string
}

/**
 * è°ƒåº¦å™¨è¿”å›å€¼
 */
interface VirtualMessageOrchestratorResult {
  /** å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶ */
  onUserSpeech: (text: string) => void
  /** å¤„ç† AI è¯´è¯äº‹ä»¶ */
  onAISpeech: (text: string) => void
  /** å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰ */
  onTurnComplete: () => void
  /** æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰ */
  triggerMemoryRetrieval: (topic: string, keywords?: string[]) => Promise<void>
  /** è·å–å½“å‰é˜Ÿåˆ—å¤§å° */
  getQueueSize: () => number
  /** è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ */
  getContext: () => ReturnType<ReturnType<typeof useConversationContextTracker>['getContext']>
  /** é‡ç½®è°ƒåº¦å™¨çŠ¶æ€ */
  reset: () => void
}

/**
 * è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨
 */
export function useVirtualMessageOrchestrator(
  options: UseVirtualMessageOrchestratorOptions
): VirtualMessageOrchestratorResult {
  const {
    userId,
    taskDescription,
    initialDuration,
    taskStartTime,
    injectContextSilently,
    isSpeaking,
    enabled = true,
    enableMemoryRetrieval = true,
    cooldownMs = 5000,
    preferredLanguage = 'en-US',
  } = options

  // =====================================================
  // å­ Hooks
  // =====================================================

  // å¯¹è¯ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
  const contextTracker = useConversationContextTracker({
    taskDescription,
    initialDuration,
    taskStartTime,
  })

  // è¯é¢˜æ£€æµ‹å™¨
  const topicDetector = useTopicDetector()

  // å¼‚æ­¥è®°å¿†ç®¡é“
  const memoryPipeline = useAsyncMemoryPipeline(userId)

  // æ¶ˆæ¯é˜Ÿåˆ—
  const messageQueue = useVirtualMessageQueue({
    onSendMessage: (message) => injectContextSilently(message),
    cooldownMs,
    enabled,
  })

  // =====================================================
  // Refs
  // =====================================================

  // è¿½è¸ªä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯é¢˜
  const lastTopicRef = useRef<TopicInfo | null>(null)
  // è¿½è¸ªæ˜¯å¦æœ‰å¾…å‘é€çš„è®°å¿†æ¶ˆæ¯
  const pendingMemoryRef = useRef<boolean>(false)
  // è¿½è¸ª AI è¯´è¯çŠ¶æ€
  const isSpeakingRef = useRef<boolean>(isSpeaking)

  useEffect(() => {
    isSpeakingRef.current = isSpeaking
  }, [isSpeaking])

  // =====================================================
  // æ ¸å¿ƒæ–¹æ³•
  // =====================================================

  /**
   * ç”Ÿæˆæƒ…ç»ªå“åº”æ¶ˆæ¯ [EMPATHY]
   */
  const generateEmpathyMessage = useCallback((
    emotion: EmotionalState['primary'],
    intensity: number,
    trigger?: string
  ): string => {
    const currentTime = new Date().toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: false,
    })

    const context = contextTracker.getVirtualMessageContext()

    return `[EMPATHY] emotion=${emotion} intensity=${intensity.toFixed(1)}${trigger ? ` trigger="${trigger}"` : ''} current_time=${currentTime} language=${preferredLanguage}
conversation_context: ç”¨æˆ·æ­£åœ¨è®¨è®º"${context.currentTopic || 'æœªçŸ¥è¯é¢˜'}"ï¼Œåˆšä»"${context.topicFlow[context.topicFlow.length - 2] || 'æ— '}"è¯é¢˜è½¬è¿‡æ¥
last_ai_said: "${context.recentAISpeech?.substring(0, 50) || '(æ— )'}"
action: ä¼˜å…ˆå€¾å¬å’Œå®‰æ…°ï¼Œç­‰æƒ…ç»ªç¨³å®šåå†è½»æŸ”åœ°å¼•å¯¼å›ä»»åŠ¡ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * å¤„ç†è¯é¢˜å˜åŒ–ï¼Œè§¦å‘è®°å¿†æ£€ç´¢
   */
  const handleTopicChange = useCallback(async (
    topic: TopicInfo,
    emotionalState: EmotionalState
  ) => {
    if (!enableMemoryRetrieval || !userId) {
      return
    }

    // æ ‡è®°æœ‰å¾…å¤„ç†çš„è®°å¿†
    pendingMemoryRef.current = true

    // è·å–è¯é¢˜ç›¸å…³çš„è®°å¿†æ£€ç´¢é—®é¢˜
    const seedQuestions = topicDetector.getMemoryQuestionsForTopic(topic.id)

    // å¼‚æ­¥æ£€ç´¢è®°å¿†
    const memories = await memoryPipeline.fetchMemoriesForTopic(
      topic.name,
      topic.keywords,
      contextTracker.getContext().summary,
      seedQuestions
    )

    if (memories.length > 0) {
      // ç”Ÿæˆ [CONTEXT] æ¶ˆæ¯
      const contextMessage = generateContextMessage(
        memories,
        topic.name,
        emotionalState.primary,
        emotionalState.intensity
      )

      // å…¥é˜Ÿæ¶ˆæ¯
      messageQueue.enqueue({
        type: 'CONTEXT',
        priority: 'normal',
        content: contextMessage,
        relatedTopic: topic.name,
      })

      if (import.meta.env.DEV) {
        console.log(`ğŸ§  [Orchestrator] è®°å¿†æ£€ç´¢å®Œæˆï¼Œå·²å…¥é˜Ÿ CONTEXT æ¶ˆæ¯`, {
          topic: topic.name,
          memoriesCount: memories.length,
          queueSize: messageQueue.size(),
        })
      }
    }

    pendingMemoryRef.current = false
  }, [
    enableMemoryRetrieval,
    userId,
    topicDetector,
    memoryPipeline,
    contextTracker,
    messageQueue,
  ])

  /**
   * å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶
   */
  const onUserSpeech = useCallback((text: string) => {
    if (!enabled) return

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addUserMessage(text)

    // æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªï¼ˆå‡½æ•°å†…éƒ¨å·²è¿½è¸ªè¯é¢˜å˜åŒ–ï¼‰
    const result = topicDetector.detectFromMessage(text)

    // æ›´æ–°æƒ…ç»ªçŠ¶æ€
    if (result.emotionalState.primary !== 'neutral') {
      contextTracker.updateEmotionalState(result.emotionalState)
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æƒ…ç»ªå“åº”
    if (
      result.emotionalState.intensity >= EMOTION_RESPONSE_THRESHOLD &&
      result.emotionalState.primary !== 'neutral'
    ) {
      // ç”Ÿæˆ [EMPATHY] æ¶ˆæ¯å¹¶å…¥é˜Ÿï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
      const empathyMessage = generateEmpathyMessage(
        result.emotionalState.primary,
        result.emotionalState.intensity,
        result.emotionalState.trigger
      )

      messageQueue.enqueue({
        type: 'EMPATHY',
        priority: 'urgent',
        content: empathyMessage,
      })

      if (import.meta.env.DEV) {
        console.log(`ğŸ’— [Orchestrator] æ£€æµ‹åˆ°å¼ºçƒˆæƒ…ç»ªï¼Œå·²å…¥é˜Ÿ EMPATHY æ¶ˆæ¯`, {
          emotion: result.emotionalState.primary,
          intensity: result.emotionalState.intensity,
        })
      }
    }

    // å¤„ç†è¯é¢˜å˜åŒ–
    if (result.topic) {
      contextTracker.updateTopic(result.topic)

      if (result.isTopicChanged) {
        lastTopicRef.current = result.topic

        if (import.meta.env.DEV) {
          console.log(`ğŸ·ï¸ [Orchestrator] è¯é¢˜å˜åŒ–: ${result.topic.name}`, {
            keywords: result.matchedKeywords,
          })
        }

        // è§¦å‘å¼‚æ­¥è®°å¿†æ£€ç´¢
        handleTopicChange(result.topic, result.emotionalState)
      }
    }
  }, [
    enabled,
    contextTracker,
    topicDetector,
    messageQueue,
    generateEmpathyMessage,
    handleTopicChange,
  ])

  /**
   * å¤„ç† AI è¯´è¯äº‹ä»¶
   */
  const onAISpeech = useCallback((text: string) => {
    if (!enabled) return

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addAIMessage(text)
  }, [enabled, contextTracker])

  /**
   * å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰
   *
   * è¿™æ˜¯æ–¹æ¡ˆ A çš„æ ¸å¿ƒï¼šåœ¨å®‰å…¨çª—å£æœŸå°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
   */
  const onTurnComplete = useCallback(() => {
    if (!enabled) return

    if (import.meta.env.DEV) {
      console.log(`âœ… [Orchestrator] turnComplete - å°è¯•å‘é€é˜Ÿåˆ—æ¶ˆæ¯`, {
        queueSize: messageQueue.size(),
        isInCooldown: messageQueue.isInCooldown(),
      })
    }

    // å°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
    // injectContextSilently ä¼šæ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨çª—å£æœŸ
    const sent = messageQueue.tryFlush()

    if (sent && import.meta.env.DEV) {
      console.log(`ğŸ“¤ [Orchestrator] æˆåŠŸå‘é€é˜Ÿåˆ—æ¶ˆæ¯`)
    }
  }, [enabled, messageQueue])

  /**
   * æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰
   */
  const triggerMemoryRetrieval = useCallback(async (
    topic: string,
    keywords: string[] = []
  ) => {
    if (!userId) return

    const memories = await memoryPipeline.fetchMemoriesForTopic(topic, keywords)

    if (memories.length > 0) {
      const contextMessage = generateContextMessage(
        memories,
        topic,
        'neutral',
        0.5
      )

      messageQueue.enqueue({
        type: 'CONTEXT',
        priority: 'normal',
        content: contextMessage,
        relatedTopic: topic,
      })
    }
  }, [userId, memoryPipeline, messageQueue])

  /**
   * è·å–é˜Ÿåˆ—å¤§å°
   */
  const getQueueSize = useCallback(() => {
    return messageQueue.size()
  }, [messageQueue])

  /**
   * è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
   */
  const getContext = useCallback(() => {
    return contextTracker.getContext()
  }, [contextTracker])

  /**
   * é‡ç½®è°ƒåº¦å™¨çŠ¶æ€
   */
  const reset = useCallback(() => {
    contextTracker.resetContext()
    messageQueue.clear()
    lastTopicRef.current = null
    pendingMemoryRef.current = false

    if (import.meta.env.DEV) {
      console.log(`ğŸ”„ [Orchestrator] çŠ¶æ€å·²é‡ç½®`)
    }
  }, [contextTracker, messageQueue])

  return {
    onUserSpeech,
    onAISpeech,
    onTurnComplete,
    triggerMemoryRetrieval,
    getQueueSize,
    getContext,
    reset,
  }
}

export type { VirtualMessageOrchestratorResult }
