/**
 * # è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨ Hook
 *
 * æ ¸å¿ƒè°ƒåº¦å™¨ï¼Œæ•´åˆæ‰€æœ‰è™šæ‹Ÿæ¶ˆæ¯ç³»ç»Ÿç»„ä»¶ï¼š
 * - ConversationContextTracker: è¿½è¸ªå¯¹è¯ä¸Šä¸‹æ–‡
 * - TopicDetector: æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªå˜åŒ–ï¼ˆå‘é‡åŒ¹é…ç‰ˆï¼‰
 * - AsyncMemoryPipeline: å¼‚æ­¥æ£€ç´¢ç›¸å…³è®°å¿†
 * - VirtualMessageQueue: æ¶ˆæ¯é˜Ÿåˆ—ç®¡ç†
 *
 * ## æ–¹æ¡ˆ 1 å®ç°ï¼šAI è¯´è¯æ—¶ç«‹å³æ‰“æ–­å¹¶æ³¨å…¥è®°å¿†
 *
 * æ ¸å¿ƒæµç¨‹ï¼š
 * 1. ç”¨æˆ·è¯´è¯ â†’ è¯é¢˜æ£€æµ‹ï¼ˆå‘é‡åŒ¹é…ï¼‰â†’ å¼‚æ­¥æ£€ç´¢è®°å¿†
 * 2. å¦‚æœæ£€ç´¢åˆ°è®°å¿†ä¸” AI æ­£åœ¨è¯´è¯ï¼š
 *    - ä½¿ç”¨ sendClientContent(content, true) æ‰“æ–­ AI å¹¶æ³¨å…¥è®°å¿†
 *    - AI ä¼šé‡æ–°å“åº”ï¼Œè¿™æ¬¡ä¼šç”¨ä¸Šè®°å¿†ä¸­çš„ä¿¡æ¯
 * 3. å¦‚æœ AI æ²¡åœ¨è¯´è¯ï¼š
 *    - å…¥é˜Ÿç­‰å¾… turnComplete åé™é»˜æ³¨å…¥
 *
 * ## ä½¿ç”¨ç¤ºä¾‹
 *
 * ```typescript
 * const orchestrator = useVirtualMessageOrchestrator({
 *   userId,
 *   taskDescription: 'å®Œæˆä»»åŠ¡',
 *   initialDuration: 300,
 *   taskStartTime: Date.now(),
 *   injectContextSilently: geminiLive.injectContextSilently,
 *   sendClientContent: geminiLive.sendClientContent, // æ–¹æ¡ˆ 1 å¿…éœ€
 *   isSpeaking: geminiLive.isSpeaking,
 * })
 *
 * // å½“ç”¨æˆ·è¯´è¯æ—¶
 * orchestrator.onUserSpeech(text)
 *
 * // å½“ AI è¯´è¯æ—¶
 * orchestrator.onAISpeech(text)
 *
 * // å½“ AI è¯´å®Œè¯æ—¶ï¼ˆturnCompleteï¼‰
 * orchestrator.onTurnComplete()
 * ```
 *
 * @see docs/in-progress/20260127-dynamic-virtual-messages.md
 */

import { useCallback, useRef, useEffect, useState } from 'react'
import { useConversationContextTracker } from './useConversationContextTracker'
import { useTopicDetector, type TopicDetectionResultExtended } from './useTopicDetector'
import { useAsyncMemoryPipeline, generateContextMessage } from './useAsyncMemoryPipeline'
import { useVirtualMessageQueue } from './useVirtualMessageQueue'
import type {
  VirtualMessageOrchestratorOptions,
  TopicInfo,
  EmotionalState,
} from './types'
import { EMOTION_RESPONSE_THRESHOLD } from './constants'

/**
 * è°ƒåº¦å™¨é…ç½®ï¼ˆæ‰©å±•åŸºç¡€é…ç½®ï¼‰
 */
interface UseVirtualMessageOrchestratorOptions extends VirtualMessageOrchestratorOptions {
  /**
   * é™é»˜æ³¨å…¥ä¸Šä¸‹æ–‡çš„å›è°ƒ
   * æ¥è‡ª useGeminiLive.injectContextSilently
   */
  injectContextSilently: (content: string, options?: { force?: boolean }) => boolean
  /**
   * å‘é€å®¢æˆ·ç«¯å†…å®¹çš„å›è°ƒï¼ˆæ”¯æŒæ‰“æ–­ AIï¼‰
   * æ¥è‡ª useGeminiLive.sendClientContent
   * @param content - è¦å‘é€çš„å†…å®¹
   * @param turnComplete - true=æ‰“æ–­AIå¹¶è§¦å‘æ–°å“åº”, false=é™é»˜æ³¨å…¥
   * @param role - 'user' æˆ– 'system'ï¼Œç”¨ 'system' æ³¨å…¥è®°å¿†ä¸Šä¸‹æ–‡
   */
  sendClientContent: (content: string, turnComplete?: boolean, role?: 'user' | 'system') => void
  /**
   * AI æ˜¯å¦æ­£åœ¨è¯´è¯
   * æ¥è‡ª useGeminiLive.isSpeaking
   */
  isSpeaking: boolean
  /**
   * æ˜¯å¦å¯ç”¨è°ƒåº¦å™¨
   */
  enabled?: boolean
  /**
   * é¦–é€‰è¯­è¨€ï¼ˆç”¨äºç”Ÿæˆæ¶ˆæ¯æ—¶æºå¸¦è¯­è¨€ä¿¡æ¯ï¼‰
   */
  preferredLanguage?: string
}

/**
 * è°ƒåº¦å™¨è¿”å›å€¼
 */
interface VirtualMessageOrchestratorResult {
  /** å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶ */
  onUserSpeech: (text: string) => void
  /** å¤„ç† AI è¯´è¯äº‹ä»¶ */
  onAISpeech: (text: string) => void
  /** å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰ */
  onTurnComplete: () => void
  /** æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰ */
  triggerMemoryRetrieval: (topic: string, keywords?: string[]) => Promise<void>
  /** è·å–å½“å‰é˜Ÿåˆ—å¤§å° */
  getQueueSize: () => number
  /** è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡ */
  getContext: () => ReturnType<ReturnType<typeof useConversationContextTracker>['getContext']>
  /** é‡ç½®è°ƒåº¦å™¨çŠ¶æ€ */
  reset: () => void
  /** æ˜¯å¦æ­£åœ¨æ£€æµ‹è¯é¢˜ */
  isDetectingTopic: boolean
  /** å¾…å¤„ç†çš„è®°å¿†ï¼ˆè°ƒè¯•ç”¨ï¼‰ */
  pendingMemory: { topic: string; count: number } | null
}

/**
 * è™šæ‹Ÿæ¶ˆæ¯è°ƒåº¦å™¨
 */
export function useVirtualMessageOrchestrator(
  options: UseVirtualMessageOrchestratorOptions
): VirtualMessageOrchestratorResult {
  const {
    userId,
    taskDescription,
    initialDuration,
    taskStartTime,
    injectContextSilently,
    sendClientContent,
    isSpeaking,
    enabled = true,
    enableMemoryRetrieval = true,
    cooldownMs = 5000,
    preferredLanguage = 'en-US',
  } = options

  // =====================================================
  // å­ Hooks
  // =====================================================

  // å¯¹è¯ä¸Šä¸‹æ–‡è¿½è¸ªå™¨
  const contextTracker = useConversationContextTracker({
    taskDescription,
    initialDuration,
    taskStartTime,
  })

  // è¯é¢˜æ£€æµ‹å™¨ï¼ˆå‘é‡ç‰ˆï¼‰
  const topicDetector = useTopicDetector()

  // å¼‚æ­¥è®°å¿†ç®¡é“
  const memoryPipeline = useAsyncMemoryPipeline(userId)

  // æ¶ˆæ¯é˜Ÿåˆ—
  const messageQueue = useVirtualMessageQueue({
    onSendMessage: (message) => injectContextSilently(message),
    cooldownMs,
    enabled,
  })

  // =====================================================
  // State & Refs
  // =====================================================

  // è¿½è¸ªä¸Šä¸€æ¬¡æ£€æµ‹åˆ°çš„è¯é¢˜
  const lastTopicRef = useRef<TopicInfo | null>(null)
  // è¿½è¸ª AI è¯´è¯çŠ¶æ€
  const isSpeakingRef = useRef<boolean>(isSpeaking)
  // å¾…å¤„ç†çš„è®°å¿†ï¼ˆè°ƒè¯•ç”¨ï¼‰
  const [pendingMemory, setPendingMemory] = useState<{ topic: string; count: number } | null>(null)

  useEffect(() => {
    isSpeakingRef.current = isSpeaking
  }, [isSpeaking])

  // =====================================================
  // æ ¸å¿ƒæ–¹æ³•
  // =====================================================

  /**
   * ç”Ÿæˆæƒ…ç»ªå“åº”æ¶ˆæ¯ [EMPATHY]
   */
  const generateEmpathyMessage = useCallback((
    emotion: EmotionalState['primary'],
    intensity: number,
    trigger?: string
  ): string => {
    const currentTime = new Date().toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit',
      hour12: false,
    })

    const context = contextTracker.getVirtualMessageContext()

    return `[EMPATHY] emotion=${emotion} intensity=${intensity.toFixed(1)}${trigger ? ` trigger="${trigger}"` : ''} current_time=${currentTime} language=${preferredLanguage}
conversation_context: ç”¨æˆ·æ­£åœ¨è®¨è®º"${context.currentTopic || 'æœªçŸ¥è¯é¢˜'}"ï¼Œåˆšä»"${context.topicFlow[context.topicFlow.length - 2] || 'æ— '}"è¯é¢˜è½¬è¿‡æ¥
last_ai_said: "${context.recentAISpeech?.substring(0, 50) || '(æ— )'}"
action: ä¼˜å…ˆå€¾å¬å’Œå®‰æ…°ï¼Œç­‰æƒ…ç»ªç¨³å®šåå†è½»æŸ”åœ°å¼•å¯¼å›ä»»åŠ¡ã€‚`
  }, [contextTracker, preferredLanguage])

  /**
   * å¤„ç†è¯é¢˜æ£€æµ‹ç»“æœï¼Œè§¦å‘è®°å¿†æ£€ç´¢
   */
  const handleTopicDetectionResult = useCallback(async (
    result: TopicDetectionResultExtended,
    userText: string
  ) => {
    const timestamp = new Date().toLocaleTimeString()

    // æ›´æ–°æƒ…ç»ªçŠ¶æ€
    if (result.emotionalState.primary !== 'neutral') {
      console.log(`ğŸ’­ [Orchestrator] æ›´æ–°æƒ…ç»ªçŠ¶æ€: ${result.emotionalState.primary} (å¼ºåº¦: ${result.emotionalState.intensity.toFixed(2)})`)
      contextTracker.updateEmotionalState(result.emotionalState)
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æƒ…ç»ªå“åº”
    if (
      result.emotionalState.intensity >= EMOTION_RESPONSE_THRESHOLD &&
      result.emotionalState.primary !== 'neutral'
    ) {
      console.log(`\nğŸ’— [${timestamp}] ========== è§¦å‘æƒ…ç»ªå“åº” ==========`)
      console.log(`ğŸ’— [Orchestrator] æƒ…ç»ªå¼ºåº¦ ${result.emotionalState.intensity.toFixed(2)} >= é˜ˆå€¼ ${EMOTION_RESPONSE_THRESHOLD}`)
      
      // ç”Ÿæˆ [EMPATHY] æ¶ˆæ¯å¹¶å…¥é˜Ÿï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
      const empathyMessage = generateEmpathyMessage(
        result.emotionalState.primary,
        result.emotionalState.intensity,
        result.emotionalState.trigger
      )

      messageQueue.enqueue({
        type: 'EMPATHY',
        priority: 'urgent',
        content: empathyMessage,
      })

      console.log(`ğŸ’— [Orchestrator] å·²å…¥é˜Ÿ [EMPATHY] æ¶ˆæ¯`, {
        emotion: result.emotionalState.primary,
        intensity: result.emotionalState.intensity,
        queueSize: messageQueue.size(),
      })
    }

    // å¤„ç†è¯é¢˜å˜åŒ–
    if (result.topic) {
      contextTracker.updateTopic(result.topic)

      if (result.isTopicChanged) {
        console.log(`\nğŸ·ï¸ [${timestamp}] ========== è¯é¢˜å˜åŒ– ==========`)
        console.log(`ğŸ·ï¸ [Orchestrator] æ–°è¯é¢˜: "${result.topic.name}" (ç½®ä¿¡åº¦: ${(result.confidence * 100).toFixed(1)}%)`)
        console.log(`ğŸ·ï¸ [Orchestrator] è®°å¿†æ£€ç´¢é—®é¢˜:`, result.memoryQuestions)
        
        lastTopicRef.current = result.topic

        // è§¦å‘å¼‚æ­¥è®°å¿†æ£€ç´¢
        if (enableMemoryRetrieval && userId) {
          console.log(`\nğŸ§  [${timestamp}] ========== å¼€å§‹è®°å¿†æ£€ç´¢ ==========`)
          console.log(`ğŸ§  [Orchestrator] ç”¨æˆ·ID: ${userId}`)
          console.log(`ğŸ§  [Orchestrator] è¯é¢˜: ${result.topic.name}`)
          
          setPendingMemory({ topic: result.topic.name, count: 0 })

          // ä½¿ç”¨ API è¿”å›çš„ memoryQuestions ä½œä¸ºç§å­é—®é¢˜
          const memories = await memoryPipeline.fetchMemoriesForTopic(
            result.topic.name,
            [], // å‘é‡åŒ¹é…ä¸éœ€è¦å…³é”®è¯
            contextTracker.getContext().summary,
            result.memoryQuestions
          )

          console.log(`ğŸ§  [Orchestrator] è®°å¿†æ£€ç´¢ç»“æœ: ${memories.length} æ¡`)
          if (memories.length > 0) {
            console.log(`ğŸ§  [Orchestrator] è®°å¿†å†…å®¹:`, memories.map(m => ({ tag: m.tag, content: m.content.substring(0, 30) + '...' })))
            
            // ç”Ÿæˆ [CONTEXT] æ¶ˆæ¯
            const contextMessage = generateContextMessage(
              memories,
              result.topic.name,
              result.emotionalState.primary,
              result.emotionalState.intensity
            )

            setPendingMemory({ topic: result.topic.name, count: memories.length })

            // ğŸ’¡ æ–¹æ¡ˆ 1ï¼šå¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œç«‹å³æ‰“æ–­å¹¶æ³¨å…¥è®°å¿†
            // æ ¹æ® Google å®˜æ–¹æ–‡æ¡£ï¼Œä½¿ç”¨ role='system' æ¥æ³¨å…¥ä¸Šä¸‹æ–‡/è®°å¿†
            if (isSpeakingRef.current) {
              console.log(`\nğŸš¨ [æ–¹æ¡ˆ 1 + system role] ========== AI æ­£åœ¨è¯´è¯ï¼Œç«‹å³æ‰“æ–­å¹¶æ³¨å…¥è®°å¿† ==========`)
              console.log(`ğŸš¨ [Orchestrator] è¯é¢˜: ${result.topic.name}`)
              console.log(`ğŸš¨ [Orchestrator] è®°å¿†æ•°: ${memories.length}`)
              console.log(`ğŸš¨ [Orchestrator] æ¶ˆæ¯é¢„è§ˆ: ${contextMessage.substring(0, 100)}...`)
              
              // ä½¿ç”¨ sendClientContent + turnComplete=true + role='system' æ‰“æ–­ AI å¹¶æ³¨å…¥è®°å¿†
              // role='system' ç¡®ä¿ AI æŠŠè¿™äº›å†…å®¹å½“ä½œä¸Šä¸‹æ–‡è€Œä¸æ˜¯ç”¨æˆ·é—®é¢˜
              sendClientContent(contextMessage, true, 'system')
              
              console.log(`ğŸš¨ [Orchestrator] âœ… è®°å¿†å·²æ³¨å…¥ (role=system)ï¼ŒAI å°†é‡æ–°å“åº”`)
            } else {
              // AI æ²¡åœ¨è¯´è¯ï¼Œå…¥é˜Ÿç­‰å¾…
              messageQueue.enqueue({
                type: 'CONTEXT',
                priority: 'normal',
                content: contextMessage,
                relatedTopic: result.topic.name,
              })

              console.log(`\nğŸ“¥ [${timestamp}] ========== å…¥é˜Ÿ CONTEXT æ¶ˆæ¯ ==========`)
              console.log(`ğŸ“¥ [Orchestrator] è¯é¢˜: ${result.topic.name}`)
              console.log(`ğŸ“¥ [Orchestrator] è®°å¿†æ•°: ${memories.length}`)
              console.log(`ğŸ“¥ [Orchestrator] é˜Ÿåˆ—å¤§å°: ${messageQueue.size()}`)
              console.log(`ğŸ“¥ [Orchestrator] æ¶ˆæ¯é¢„è§ˆ: ${contextMessage.substring(0, 100)}...`)
            }
          } else {
            console.log(`ğŸ§  [Orchestrator] æœªæ‰¾åˆ°ç›¸å…³è®°å¿†`)
            setPendingMemory(null)
          }
        } else {
          console.log(`ğŸ§  [Orchestrator] è·³è¿‡è®°å¿†æ£€ç´¢ (enableMemoryRetrieval=${enableMemoryRetrieval}, userId=${userId})`)
        }
      }
    }
  }, [
    enableMemoryRetrieval,
    userId,
    memoryPipeline,
    contextTracker,
    messageQueue,
    generateEmpathyMessage,
    sendClientContent,
  ])

  /**
   * å¤„ç†ç”¨æˆ·è¯´è¯äº‹ä»¶
   */
  const onUserSpeech = useCallback((text: string) => {
    if (!enabled) return

    const timestamp = new Date().toLocaleTimeString()
    console.log(`\nğŸ¤ [${timestamp}] ========== ç”¨æˆ·è¯´è¯ ==========`)
    console.log(`ğŸ¤ [Orchestrator] å†…å®¹: "${text.substring(0, 50)}..."`)

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addUserMessage(text)

    // å¼‚æ­¥æ£€æµ‹è¯é¢˜å’Œæƒ…ç»ªï¼ˆå‘é‡åŒ¹é…ï¼‰
    console.log(`ğŸ” [Orchestrator] å¼€å§‹è¯é¢˜æ£€æµ‹ (å‘é‡åŒ¹é…)...`)
    topicDetector.detectFromMessage(text).then((result) => {
      console.log(`ğŸ” [Orchestrator] è¯é¢˜æ£€æµ‹å®Œæˆ:`, {
        topic: result.topic?.name || 'æ— ',
        confidence: result.confidence ? `${(result.confidence * 100).toFixed(1)}%` : 'N/A',
        emotion: result.emotionalState.primary,
        isTopicChanged: result.isTopicChanged,
      })
      handleTopicDetectionResult(result, text)
    }).catch((err) => {
      console.error('ğŸ·ï¸ [Orchestrator] è¯é¢˜æ£€æµ‹å¤±è´¥:', err)
      
      // å¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°æƒ…ç»ªæ£€æµ‹ä½œä¸º fallback
      const localEmotion = topicDetector.detectEmotionLocally(text)
      if (localEmotion.primary !== 'neutral') {
        contextTracker.updateEmotionalState(localEmotion)
      }
    })
  }, [
    enabled,
    contextTracker,
    topicDetector,
    handleTopicDetectionResult,
  ])

  /**
   * å¤„ç† AI è¯´è¯äº‹ä»¶
   */
  const onAISpeech = useCallback((text: string) => {
    if (!enabled) return

    // æ›´æ–°ä¸Šä¸‹æ–‡
    contextTracker.addAIMessage(text)
  }, [enabled, contextTracker])

  /**
   * å¤„ç† AI è¯´å®Œè¯äº‹ä»¶ï¼ˆturnCompleteï¼‰
   *
   * è¿™æ˜¯æ–¹æ¡ˆ A çš„æ ¸å¿ƒï¼šåœ¨å®‰å…¨çª—å£æœŸå°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
   */
  const onTurnComplete = useCallback(() => {
    if (!enabled) return

    const timestamp = new Date().toLocaleTimeString()
    console.log(`\nâœ… [${timestamp}] ========== AI è¯´å®Œè¯ (turnComplete) ==========`)
    console.log(`âœ… [Orchestrator] é˜Ÿåˆ—å¤§å°: ${messageQueue.size()}`)
    console.log(`âœ… [Orchestrator] å†·å´ä¸­: ${messageQueue.isInCooldown()}`)

    // å°è¯•å‘é€é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
    // injectContextSilently ä¼šæ£€æŸ¥æ˜¯å¦åœ¨å®‰å…¨çª—å£æœŸ
    const sent = messageQueue.tryFlush()

    if (sent) {
      console.log(`ğŸ“¤ [${timestamp}] ========== å‘é€è™šæ‹Ÿæ¶ˆæ¯æˆåŠŸ ==========`)
      console.log(`ğŸ“¤ [Orchestrator] æ¶ˆæ¯å·²æ³¨å…¥åˆ° AI ä¸Šä¸‹æ–‡`)
    } else if (messageQueue.size() > 0) {
      console.log(`â³ [Orchestrator] é˜Ÿåˆ—æœ‰æ¶ˆæ¯ä½†æœªå‘é€ (å¯èƒ½åœ¨å†·å´ä¸­)`)
    }
  }, [enabled, messageQueue])

  /**
   * æ‰‹åŠ¨è§¦å‘è®°å¿†æ£€ç´¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰
   */
  const triggerMemoryRetrieval = useCallback(async (
    topic: string,
    keywords: string[] = []
  ) => {
    if (!userId) return

    const memories = await memoryPipeline.fetchMemoriesForTopic(topic, keywords)

    if (memories.length > 0) {
      const contextMessage = generateContextMessage(
        memories,
        topic,
        'neutral',
        0.5
      )

      messageQueue.enqueue({
        type: 'CONTEXT',
        priority: 'normal',
        content: contextMessage,
        relatedTopic: topic,
      })
    }
  }, [userId, memoryPipeline, messageQueue])

  /**
   * è·å–é˜Ÿåˆ—å¤§å°
   */
  const getQueueSize = useCallback(() => {
    return messageQueue.size()
  }, [messageQueue])

  /**
   * è·å–å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
   */
  const getContext = useCallback(() => {
    return contextTracker.getContext()
  }, [contextTracker])

  /**
   * é‡ç½®è°ƒåº¦å™¨çŠ¶æ€
   */
  const reset = useCallback(() => {
    contextTracker.resetContext()
    topicDetector.reset()
    messageQueue.clear()
    lastTopicRef.current = null
    setPendingMemory(null)

    if (import.meta.env.DEV) {
      console.log(`ğŸ”„ [Orchestrator] çŠ¶æ€å·²é‡ç½®`)
    }
  }, [contextTracker, topicDetector, messageQueue])

  return {
    onUserSpeech,
    onAISpeech,
    onTurnComplete,
    triggerMemoryRetrieval,
    getQueueSize,
    getContext,
    reset,
    isDetectingTopic: topicDetector.isDetecting,
    pendingMemory,
  }
}

export type { VirtualMessageOrchestratorResult }
