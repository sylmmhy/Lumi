/**
 * # è®°å¿†æ£€ç´¢å…±äº«æ¨¡å— (Tolan çº§åˆ« Multi-Query RAG)
 *
 * æœ¬æ¨¡å—æä¾›è®°å¿†æ£€ç´¢çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œè¢«ä»¥ä¸‹ Edge Functions ä½¿ç”¨ï¼š
 * - get-system-instruction: å¯åŠ¨æ—¶æ³¨å…¥ system prompt
 * - retrieve-memories: è™šæ‹Ÿæ¶ˆæ¯ç³»ç»Ÿå®æ—¶æ£€ç´¢
 *
 * ## æ ¸å¿ƒåŠŸèƒ½
 * - Question Synthesis: LLM ç”Ÿæˆæ£€ç´¢é—®é¢˜
 * - Batch Embedding: æ‰¹é‡å‘é‡ç”Ÿæˆ
 * - Tiered Search: åˆ†å±‚æ£€ç´¢ï¼ˆçƒ­/æ¸©/å†·ï¼‰
 * - MRR Fusion: å¤šæŸ¥è¯¢ç»“æœèåˆæ’åº
 *
 * @see docs/architecture/tolan-memory-system-upgrade.md
 * @see docs/in-progress/20260127-dynamic-virtual-messages.md
 */

import type { SupabaseClient } from 'https://esm.sh/@supabase/supabase-js@2'

// =====================================================
// é…ç½®å¸¸é‡
// =====================================================

/** è®°å¿†å‘é‡ç›¸ä¼¼åº¦é˜ˆå€¼ */
export const MEMORY_SIMILARITY_THRESHOLD = 0.6

/** æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„æœ€å¤§è®°å¿†æ•° */
export const MEMORY_LIMIT_PER_QUERY = 5

/** æœ€ç»ˆè¿”å›çš„æœ€å¤§è®°å¿†æ•° */
export const MAX_FINAL_MEMORIES = 10

/** çƒ­å±‚ï¼šæœ€è¿‘ N å¤©è®¿é—®è¿‡çš„è®°å¿† */
export const HOT_TIER_DAYS = 7

/** æ¸©å±‚ï¼šN-M å¤©æœªè®¿é—®çš„è®°å¿† */
export const WARM_TIER_DAYS = 30

/** çƒ­å±‚è‡³å°‘éœ€è¦å¤šå°‘æ¡ç»“æœæ‰ç®—"å¤Ÿç”¨" */
export const MIN_HOT_RESULTS = 3

/** å¦‚æœæœ‰ä¸€æ¡ç›¸ä¼¼åº¦ >= æ­¤å€¼ï¼Œä¹Ÿç®—"å¤Ÿç”¨" */
export const MIN_SIMILARITY_FOR_ENOUGH = 0.7

/** è‡³å°‘å¤šå°‘ç§ä¸åŒæ ‡ç­¾æ‰ç®—"å¤Ÿç”¨" */
export const MIN_TAG_DIVERSITY = 2

// =====================================================
// ç±»å‹å®šä¹‰
// =====================================================

/**
 * åˆ†å±‚æ£€ç´¢ç»“æœ
 */
export interface TieredSearchResult {
  memory_id: string
  content: string
  tag: string
  confidence: number
  importance_score: number
  similarity: number
  last_accessed_at: string | null
}

/**
 * Multi-Query RAG æœç´¢ç»“æœ
 */
export interface MultiQueryResult {
  query_index: number
  memory_id: string
  content: string
  tag: string
  confidence: number
  importance_score: number
  similarity: number
  rank: number
}

/**
 * MRR èåˆåçš„è®°å¿†ç»“æœ
 */
export interface MergedMemoryResult {
  memory_id: string
  content: string
  tag: string
  mrrScore: number
  importance: number
}

/**
 * è®°å¿†æ£€ç´¢é…ç½®
 */
export interface MemoryRetrievalConfig {
  /** Azure AI Endpoint */
  azureEndpoint: string
  /** Azure AI API Key */
  azureApiKey: string
  /** Embedding Endpointï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ azureEndpointï¼‰ */
  embeddingEndpoint?: string
  /** Embedding API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨ azureApiKeyï¼‰ */
  embeddingApiKey?: string
  /** Question Synthesis æ¨¡å‹åç§° */
  modelName?: string
  /** Embedding æ¨¡å‹åç§° */
  embeddingModel?: string
}

/**
 * æ ‡ç­¾ä¸Šä¸‹æ–‡æ˜ å°„ï¼ˆç”¨äºæ ¼å¼åŒ–è¾“å‡ºï¼‰
 */
export const TAG_CONTEXT: Record<string, string> = {
  'PREF': '(AI äº¤äº’åå¥½)',
  'PROC': '(æ‹–å»¶æ¨¡å¼)',
  'SOMA': '(èº«å¿ƒååº”)',
  'EMO': '(æƒ…ç»ªæ¨¡å¼)',
  'SAB': '(è‡ªæˆ‘å¦¨ç¢)',
  'EFFECTIVE': '(æœ‰æ•ˆæ¿€åŠ±æ–¹å¼)',
  'CONTEXT': '(ç”Ÿæ´»èƒŒæ™¯)',
}

// =====================================================
// æ ¸å¿ƒå‡½æ•°
// =====================================================

/**
 * Question Synthesis: ä½¿ç”¨ LLM ä¸ºç»™å®šçš„ä¸Šä¸‹æ–‡ç”Ÿæˆå¤šä¸ªæ£€ç´¢é—®é¢˜
 *
 * @param context - ä»»åŠ¡æè¿°æˆ–è¯é¢˜ä¸Šä¸‹æ–‡
 * @param config - API é…ç½®
 * @param seedQuestions - å¯é€‰çš„ç§å­é—®é¢˜ï¼ˆå¦‚è¯é¢˜è§„åˆ™ä¸­é¢„å®šä¹‰çš„é—®é¢˜ï¼‰
 * @returns ç”Ÿæˆçš„æ£€ç´¢é—®é¢˜æ•°ç»„
 *
 * @example
 * const questions = await synthesizeQuestions('ç”¨æˆ·æƒ³å»æ—…è¡Œ', config, [
 *   'ç”¨æˆ·ä¹‹å‰å»è¿‡å“ªäº›åœ°æ–¹æ—…è¡Œï¼Ÿ',
 *   'ç”¨æˆ·å–œæ¬¢ä»€ä¹ˆç±»å‹çš„æ—…è¡Œæ´»åŠ¨ï¼Ÿ',
 * ])
 */
export async function synthesizeQuestions(
  context: string,
  config: MemoryRetrievalConfig,
  seedQuestions?: string[]
): Promise<string[]> {
  if (!config.azureApiKey) {
    console.warn('âš ï¸ AZURE_API_KEY æœªè®¾ç½®ï¼Œè·³è¿‡ Question Synthesis')
    return seedQuestions?.length ? seedQuestions : [context]
  }

  // å¦‚æœæœ‰ç§å­é—®é¢˜ä¸”æ•°é‡è¶³å¤Ÿï¼Œç›´æ¥ä½¿ç”¨
  if (seedQuestions && seedQuestions.length >= 3) {
    console.log(`ğŸ” ä½¿ç”¨é¢„å®šä¹‰çš„ ${seedQuestions.length} ä¸ªæ£€ç´¢é—®é¢˜`)
    return seedQuestions.slice(0, 5)
  }

  const modelName = config.modelName || 'gpt-5.1-chat'

  const prompt = `Based on the user's current context, generate 3-5 search queries to retrieve relevant memories from their history.

Current context: "${context}"
${seedQuestions?.length ? `\nExisting questions (expand on these):\n${seedQuestions.join('\n')}` : ''}

Generate queries that would help find:
1. Past experiences with similar situations
2. User's preferences and habits related to this context
3. Emotional patterns or triggers
4. What motivation techniques worked before
5. Any relevant life context or circumstances

Output ONLY a JSON array of strings, no explanation:
["query1", "query2", "query3"]`

  try {
    const apiUrl = `${config.azureEndpoint}/openai/v1/chat/completions`

    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${config.azureApiKey}`,
      },
      body: JSON.stringify({
        model: modelName,
        messages: [
          { role: 'system', content: 'You are a search query generator. Output only valid JSON arrays.' },
          { role: 'user', content: prompt }
        ],
        max_completion_tokens: 300,
        temperature: 0.3,
      }),
    })

    if (!response.ok) {
      console.error('Question Synthesis API error:', response.status)
      return seedQuestions?.length ? seedQuestions : [context]
    }

    const result = await response.json()
    const content = result.choices?.[0]?.message?.content?.trim()

    if (!content) {
      return seedQuestions?.length ? seedQuestions : [context]
    }

    const queries = JSON.parse(content)
    if (Array.isArray(queries) && queries.length > 0) {
      // å¦‚æœæœ‰ç§å­é—®é¢˜ï¼Œåˆå¹¶å»é‡
      const allQueries = seedQuestions?.length
        ? [...new Set([...seedQuestions, ...queries])]
        : queries
      console.log(`ğŸ” Question Synthesis ç”Ÿæˆ ${allQueries.length} ä¸ªæ£€ç´¢é—®é¢˜:`, allQueries.slice(0, 3))
      return allQueries.slice(0, 5)
    }

    return seedQuestions?.length ? seedQuestions : [context]
  } catch (error) {
    console.error('Question Synthesis å¤±è´¥:', error)
    return seedQuestions?.length ? seedQuestions : [context]
  }
}

/**
 * æ‰¹é‡ç”Ÿæˆ Embeddings
 *
 * @param texts - è¦ç”Ÿæˆ embedding çš„æ–‡æœ¬æ•°ç»„
 * @param config - API é…ç½®
 * @returns embedding å‘é‡æ•°ç»„
 */
export async function generateEmbeddings(
  texts: string[],
  config: MemoryRetrievalConfig
): Promise<number[][]> {
  const apiKey = config.embeddingApiKey || config.azureApiKey
  if (!apiKey || texts.length === 0) {
    return []
  }

  const endpoint = config.embeddingEndpoint || config.azureEndpoint
  const model = config.embeddingModel || 'text-embedding-3-large'

  try {
    const baseUrl = endpoint.replace(/\/+$/, '')
    const apiUrl = `${baseUrl}/embeddings`

    console.log(`ğŸ“Š æ­£åœ¨ä¸º ${texts.length} ä¸ªæ–‡æœ¬ç”Ÿæˆ embeddings...`)

    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model,
        input: texts,
        dimensions: 1536,
      }),
    })

    if (!response.ok) {
      const error = await response.text()
      console.error('Embedding API error:', response.status, error)
      return []
    }

    const result = await response.json()
    const embeddings = result.data?.map((d: { embedding: number[] }) => d.embedding) || []

    console.log(`ğŸ“Š æˆåŠŸç”Ÿæˆ ${embeddings.length} ä¸ª embeddings`)
    return embeddings
  } catch (error) {
    console.error('generateEmbeddings å¤±è´¥:', error)
    return []
  }
}

/**
 * Mean Reciprocal Rank (MRR) èåˆç®—æ³•
 *
 * å°†å¤šä¸ªæŸ¥è¯¢çš„æœç´¢ç»“æœåˆå¹¶ï¼Œæ ¹æ®æ’åè®¡ç®—ç»¼åˆåˆ†æ•°
 * MRR å…¬å¼: score = sum(1/rank) å¯¹äºæ¯ä¸ªå‡ºç°çš„æŸ¥è¯¢
 *
 * @example
 * Memory A åœ¨ Query1 æ’ç¬¬1, Query3 æ’ç¬¬2
 * score = 1/1 + 1/2 = 1.5
 *
 * @param resultSets - å¤šä¸ªæŸ¥è¯¢çš„æœç´¢ç»“æœ
 * @returns èåˆå¹¶æ’åºåçš„è®°å¿†åˆ—è¡¨
 */
export function mergeWithMRR(resultSets: MultiQueryResult[]): MergedMemoryResult[] {
  const scores = new Map<string, {
    mrrScore: number
    content: string
    tag: string
    importance: number
    queryHits: number
  }>()

  for (const result of resultSets) {
    const existing = scores.get(result.memory_id)
    const reciprocalRank = 1 / result.rank

    if (existing) {
      existing.mrrScore += reciprocalRank
      existing.queryHits += 1
      existing.importance = Math.max(existing.importance, result.importance_score)
    } else {
      scores.set(result.memory_id, {
        mrrScore: reciprocalRank,
        content: result.content,
        tag: result.tag,
        importance: result.importance_score,
        queryHits: 1,
      })
    }
  }

  const sorted = [...scores.entries()]
    .map(([memory_id, data]) => ({
      memory_id,
      content: data.content,
      tag: data.tag,
      mrrScore: data.mrrScore,
      importance: data.importance,
    }))
    .sort((a, b) => {
      const scoreDiff = b.mrrScore - a.mrrScore
      if (Math.abs(scoreDiff) > 0.01) return scoreDiff
      return b.importance - a.importance
    })

  console.log(`ğŸ”€ MRR èåˆ: ${resultSets.length} æ¡ç»“æœ â†’ ${sorted.length} æ¡å»é‡ç»“æœ`)
  if (sorted.length > 0) {
    console.log(`ğŸ”€ Top 3 MRR scores:`, sorted.slice(0, 3).map(m => ({ tag: m.tag, score: m.mrrScore.toFixed(2) })))
  }

  return sorted
}

/**
 * åœ¨æŒ‡å®šå±‚çº§æœç´¢è®°å¿†
 *
 * @param supabase - Supabase å®¢æˆ·ç«¯
 * @param userId - ç”¨æˆ· ID
 * @param embeddings - æŸ¥è¯¢å‘é‡æ•°ç»„
 * @param tier - å±‚çº§ï¼š'hot' | 'warm' | 'cold'
 * @returns æœç´¢ç»“æœ
 */
export async function searchMemoriesInTier(
  supabase: SupabaseClient,
  userId: string,
  embeddings: number[][],
  tier: 'hot' | 'warm' | 'cold'
): Promise<TieredSearchResult[]> {
  console.log(`ğŸ” [Tiered] æœç´¢ ${tier} å±‚è®°å¿†...`)

  const embeddingStrings = embeddings.map(e => JSON.stringify(e))

  const { data, error } = await supabase.rpc('tiered_search_memories', {
    p_user_id: userId,
    p_embeddings: embeddingStrings,
    p_threshold: MEMORY_SIMILARITY_THRESHOLD,
    p_limit_per_query: MEMORY_LIMIT_PER_QUERY,
    p_tier: tier,
    p_hot_days: HOT_TIER_DAYS,
    p_warm_days: WARM_TIER_DAYS,
  })

  if (error) {
    console.error(`[Tiered] ${tier} å±‚æœç´¢é”™è¯¯:`, error)
    return []
  }

  console.log(`ğŸ” [Tiered] ${tier} å±‚è¿”å› ${data?.length || 0} æ¡ç»“æœ`)
  return data || []
}

/**
 * åˆ¤æ–­æœç´¢ç»“æœæ˜¯å¦"å¤Ÿç”¨"
 *
 * æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶å³ä¸º"å¤Ÿç”¨"ï¼š
 * 1. ç»“æœæ•°é‡ >= MIN_HOT_RESULTS
 * 2. æœ‰ä»»æ„ä¸€æ¡ç»“æœç›¸ä¼¼åº¦ >= MIN_SIMILARITY_FOR_ENOUGH
 * 3. ç»“æœè¦†ç›– >= MIN_TAG_DIVERSITY ç§ä¸åŒæ ‡ç­¾
 *
 * @param results - æœç´¢ç»“æœ
 * @returns æ˜¯å¦å¤Ÿç”¨
 */
export function isResultsEnough(results: TieredSearchResult[]): boolean {
  if (results.length === 0) {
    return false
  }

  // æ¡ä»¶ 1: æ•°é‡è¶³å¤Ÿ
  if (results.length >= MIN_HOT_RESULTS) {
    console.log(`âœ… [Tiered] å¤Ÿç”¨ï¼šæ•°é‡ ${results.length} >= ${MIN_HOT_RESULTS}`)
    return true
  }

  // æ¡ä»¶ 2: é«˜ç›¸ä¼¼åº¦å‘½ä¸­
  const highSimilarity = results.some(r => r.similarity >= MIN_SIMILARITY_FOR_ENOUGH)
  if (highSimilarity) {
    console.log(`âœ… [Tiered] å¤Ÿç”¨ï¼šæœ‰é«˜ç›¸ä¼¼åº¦ç»“æœ >= ${MIN_SIMILARITY_FOR_ENOUGH}`)
    return true
  }

  // æ¡ä»¶ 3: æ ‡ç­¾å¤šæ ·æ€§
  const uniqueTags = new Set(results.map(r => r.tag))
  if (uniqueTags.size >= MIN_TAG_DIVERSITY) {
    console.log(`âœ… [Tiered] å¤Ÿç”¨ï¼šæ ‡ç­¾å¤šæ ·æ€§ ${uniqueTags.size} >= ${MIN_TAG_DIVERSITY}`)
    return true
  }

  console.log(`âš ï¸ [Tiered] ä¸å¤Ÿç”¨ï¼šæ•°é‡=${results.length}, æ— é«˜ç›¸ä¼¼åº¦, æ ‡ç­¾ç§ç±»=${uniqueTags.size}`)
  return false
}

/**
 * æ›´æ–°è®°å¿†çš„è®¿é—®æ—¶é—´å’Œè®¿é—®æ¬¡æ•°
 *
 * åœ¨è®°å¿†è¢«æ£€ç´¢åè°ƒç”¨ï¼Œç”¨äºç»´æŠ¤çƒ­/æ¸©/å†·åˆ†å±‚
 *
 * @param supabase - Supabase å®¢æˆ·ç«¯
 * @param memoryIds - è¦æ›´æ–°çš„è®°å¿† ID æ•°ç»„
 */
export async function updateMemoryAccessTime(
  supabase: SupabaseClient,
  memoryIds: string[]
): Promise<void> {
  if (memoryIds.length === 0) return

  try {
    const { error } = await supabase.rpc('update_memory_access', {
      p_memory_ids: memoryIds,
    })

    if (error) {
      console.warn('[Tiered] æ›´æ–°è®¿é—®æ—¶é—´å¤±è´¥:', error)
    } else {
      console.log(`ğŸ“ [Tiered] å·²æ›´æ–° ${memoryIds.length} æ¡è®°å¿†çš„è®¿é—®æ—¶é—´`)
    }
  } catch (e) {
    console.warn('[Tiered] æ›´æ–°è®¿é—®æ—¶é—´å¼‚å¸¸:', e)
  }
}

/**
 * Multi-Query RAG æ‰§è¡Œï¼ˆä¸å«åˆ†å±‚ï¼Œä½¿ç”¨ multi_query_search_memories RPCï¼‰
 *
 * @param supabase - Supabase å®¢æˆ·ç«¯
 * @param userId - ç”¨æˆ· ID
 * @param questions - æ£€ç´¢é—®é¢˜æ•°ç»„
 * @param config - API é…ç½®
 * @param limit - è¿”å›ç»“æœæ•°é‡é™åˆ¶
 * @returns èåˆåçš„è®°å¿†ç»“æœ
 */
export async function multiQueryRAG(
  supabase: SupabaseClient,
  userId: string,
  questions: string[],
  config: MemoryRetrievalConfig,
  limit: number = MAX_FINAL_MEMORIES
): Promise<MergedMemoryResult[]> {
  const startTime = Date.now()

  try {
    // 1. ç”Ÿæˆ embeddings
    const embeddings = await generateEmbeddings(questions, config)

    if (embeddings.length === 0) {
      console.warn('âš ï¸ Embedding ç”Ÿæˆå¤±è´¥')
      return []
    }

    // 2. å¤šæŸ¥è¯¢å‘é‡æœç´¢
    const embeddingStrings = embeddings.map(e => JSON.stringify(e))

    const { data: searchResults, error } = await supabase.rpc('multi_query_search_memories', {
      p_user_id: userId,
      p_embeddings: embeddingStrings,
      p_threshold: MEMORY_SIMILARITY_THRESHOLD,
      p_limit_per_query: MEMORY_LIMIT_PER_QUERY,
    })

    if (error) {
      console.error('multi_query_search_memories RPC é”™è¯¯:', error)
      return []
    }

    if (!searchResults || searchResults.length === 0) {
      console.log('ğŸ” Multi-Query RAG æœªæ‰¾åˆ°ç›¸å…³è®°å¿†')
      return []
    }

    // 3. MRR èåˆ
    const fusedResults = mergeWithMRR(searchResults as MultiQueryResult[])

    // 4. æ›´æ–°è®¿é—®æ—¶é—´
    const memoryIds = fusedResults.slice(0, limit).map(m => m.memory_id)
    await updateMemoryAccessTime(supabase, memoryIds)

    const elapsedMs = Date.now() - startTime
    console.log(`âœ… Multi-Query RAG å®Œæˆ: ${fusedResults.length} æ¡è®°å¿†, è€—æ—¶ ${elapsedMs}ms`)

    return fusedResults.slice(0, limit)
  } catch (error) {
    console.error('Multi-Query RAG æ‰§è¡Œå¤±è´¥:', error)
    return []
  }
}

/**
 * åˆ†å±‚ Multi-Query RAG æ‰§è¡Œ
 *
 * åˆ†å±‚ç­–ç•¥ï¼š
 * 1. å…ˆæœçƒ­å±‚ï¼ˆPREF/EFFECTIVE + æœ€è¿‘7å¤©è®¿é—®ï¼‰
 * 2. å¦‚æœçƒ­å±‚ä¸å¤Ÿç”¨ï¼Œæ‰©å±•åˆ°æ¸©å±‚ï¼ˆ7-30å¤©ï¼‰
 * 3. å†·å±‚æš‚ä¸æœç´¢ï¼Œé¿å…å»¶è¿Ÿ
 *
 * @param supabase - Supabase å®¢æˆ·ç«¯
 * @param userId - ç”¨æˆ· ID
 * @param questions - æ£€ç´¢é—®é¢˜æ•°ç»„
 * @param config - API é…ç½®
 * @param limit - è¿”å›ç»“æœæ•°é‡é™åˆ¶
 * @returns æ ¼å¼åŒ–çš„è®°å¿†å­—ç¬¦ä¸²æ•°ç»„
 */
export async function tieredMultiQueryRAG(
  supabase: SupabaseClient,
  userId: string,
  questions: string[],
  config: MemoryRetrievalConfig,
  limit: number = MAX_FINAL_MEMORIES
): Promise<string[]> {
  const startTime = Date.now()

  try {
    // 1. ç”Ÿæˆ embeddings
    const embeddings = await generateEmbeddings(questions, config)

    if (embeddings.length === 0) {
      console.warn('âš ï¸ Embedding ç”Ÿæˆå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ£€ç´¢')
      return []
    }

    // 2. æœç´¢çƒ­å±‚
    let allResults: TieredSearchResult[] = await searchMemoriesInTier(
      supabase, userId, embeddings, 'hot'
    )

    // 3. å¦‚æœçƒ­å±‚ä¸å¤Ÿç”¨ï¼Œæ‰©å±•åˆ°æ¸©å±‚
    if (!isResultsEnough(allResults)) {
      console.log('ğŸ” [Tiered] çƒ­å±‚ä¸å¤Ÿç”¨ï¼Œæ‰©å±•åˆ°æ¸©å±‚...')
      const warmResults = await searchMemoriesInTier(
        supabase, userId, embeddings, 'warm'
      )
      // åˆå¹¶ç»“æœï¼Œçƒ­å±‚ä¼˜å…ˆ
      allResults = [...allResults, ...warmResults]
    }

    if (allResults.length === 0) {
      console.log('ğŸ” [Tiered] æœªæ‰¾åˆ°ç›¸å…³è®°å¿†')
      return []
    }

    // 4. è½¬æ¢ä¸º MultiQueryResult æ ¼å¼ï¼Œè¿›è¡Œ MRR èåˆ
    const multiQueryResults: MultiQueryResult[] = allResults.map((r, idx) => ({
      query_index: 0, // åˆ†å±‚æœç´¢ä¸åŒºåˆ†æŸ¥è¯¢ç´¢å¼•
      memory_id: r.memory_id,
      content: r.content,
      tag: r.tag,
      confidence: r.confidence,
      importance_score: r.importance_score,
      similarity: r.similarity,
      rank: idx + 1, // ä½¿ç”¨ä½ç½®ä½œä¸ºæ’å
    }))

    const fusedResults = mergeWithMRR(multiQueryResults)

    // 5. æ›´æ–°è®¿é—®æ—¶é—´
    const memoryIds = fusedResults.slice(0, limit).map(m => m.memory_id)
    await updateMemoryAccessTime(supabase, memoryIds)

    // 6. æ ¼å¼åŒ–è¾“å‡º
    const formattedMemories = fusedResults
      .slice(0, limit)
      .map(m => {
        const context = TAG_CONTEXT[m.tag] || ''
        return `${m.content} ${context}`.trim()
      })

    const elapsedMs = Date.now() - startTime
    console.log(`âœ… Tiered Multi-Query RAG å®Œæˆ: ${formattedMemories.length} æ¡è®°å¿†, è€—æ—¶ ${elapsedMs}ms`)

    return formattedMemories
  } catch (error) {
    console.error('Tiered Multi-Query RAG æ‰§è¡Œå¤±è´¥:', error)
    return []
  }
}

/**
 * ä»ç¯å¢ƒå˜é‡æ„å»ºé…ç½®å¯¹è±¡
 *
 * @returns è®°å¿†æ£€ç´¢é…ç½®
 */
export function getConfigFromEnv(): MemoryRetrievalConfig {
  return {
    azureEndpoint: Deno.env.get('AZURE_AI_ENDPOINT') || 'https://conta-mcvprtb1-eastus2.openai.azure.com',
    azureApiKey: Deno.env.get('AZURE_AI_API_KEY') || '',
    embeddingEndpoint: Deno.env.get('AZURE_EMBEDDING_ENDPOINT'),
    embeddingApiKey: Deno.env.get('AZURE_EMBEDDING_API_KEY'),
    modelName: Deno.env.get('MEMORY_EXTRACTOR_MODEL') || 'gpt-5.1-chat',
    embeddingModel: Deno.env.get('MEMORY_EMBEDDING_MODEL') || 'text-embedding-3-large',
  }
}
