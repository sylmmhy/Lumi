/**
 * Memory Compressor Edge Function
 *
 * å¤œé—´å‹ç¼©ä»»åŠ¡ï¼šè‡ªåŠ¨æ¸…ç†ä½ä»·å€¼è®°å¿†ã€è§£å†³çŸ›ç›¾è®°å¿†
 *
 * åŠŸèƒ½ï¼š
 * 1. evaluateImportance - LLM è¯„ä¼°è®°å¿†é‡è¦æ€§
 * 2. resolveContradictions - æ£€æµ‹å¹¶è§£å†³çŸ›ç›¾è®°å¿†
 * 3. compressLowValueMemories - æ¸…ç†ä½ä»·å€¼è®°å¿†
 *
 * è°ƒç”¨æ–¹å¼ï¼š
 * - POST { action: 'compress_all' } - å‹ç¼©æ‰€æœ‰ç”¨æˆ·ï¼ˆcron è°ƒç”¨ï¼‰
 * - POST { action: 'compress_user', userId: 'xxx' } - å‹ç¼©å•ä¸ªç”¨æˆ·
 */

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
}

// Azure AI é…ç½®
const AZURE_ENDPOINT = Deno.env.get('AZURE_AI_ENDPOINT') || 'https://conta-mcvprtb1-eastus2.openai.azure.com'
const AZURE_API_KEY = Deno.env.get('AZURE_AI_API_KEY')
const MODEL_NAME = Deno.env.get('MEMORY_EXTRACTOR_MODEL') || 'gpt-5.1-chat'

// å‹ç¼©é…ç½®
const LOW_IMPORTANCE_THRESHOLD = 0.3  // ä½äºæ­¤å€¼è€ƒè™‘åˆ é™¤
const MIN_AGE_DAYS = 7                // è‡³å°‘ 7 å¤©å‰çš„è®°å¿†æ‰è€ƒè™‘å‹ç¼©
const BATCH_SIZE = 100                // æ¯æ‰¹å¤„ç†çš„è®°å¿†æ•°
const MAX_USERS_PER_RUN = 50          // æ¯æ¬¡è¿è¡Œæœ€å¤šå¤„ç†çš„ç”¨æˆ·æ•°

/**
 * å‹ç¼©å€™é€‰è®°å¿†çš„ç»“æ„
 */
interface CompressionCandidate {
  memory_id: string
  user_id: string
  content: string
  tag: string
  importance_score: number
  confidence: number
  access_count: number
  days_since_update: number
  days_since_access: number
}

/**
 * çŸ›ç›¾è®°å¿†å¯¹çš„ç»“æ„
 */
interface ContradictionPair {
  memory_id_1: string
  memory_id_2: string
  content_1: string
  content_2: string
  tag: string
  similarity: number
  created_at_1: string
  created_at_2: string
}

/**
 * å‹ç¼©ç»“æœç»Ÿè®¡
 */
interface CompressionStats {
  usersProcessed: number
  totalEvaluated: number
  totalDeleted: number
  totalCompressed: number
  contradictionsResolved: number
  errors: string[]
}

/**
 * ä½¿ç”¨ LLM è¯„ä¼°è®°å¿†çš„é‡è¦æ€§
 * è¿”å› 0-1 çš„è¯„åˆ†
 */
async function evaluateImportance(memories: CompressionCandidate[]): Promise<Map<string, number>> {
  const results = new Map<string, number>()

  if (!AZURE_API_KEY || memories.length === 0) {
    // æ²¡æœ‰ API key æ—¶ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„è¯„ä¼°
    for (const m of memories) {
      results.set(m.memory_id, m.importance_score)
    }
    return results
  }

  // æ‰¹é‡è¯„ä¼°ï¼ˆä¸€æ¬¡æœ€å¤š 10 æ¡ï¼‰
  const batches = []
  for (let i = 0; i < memories.length; i += 10) {
    batches.push(memories.slice(i, i + 10))
  }

  for (const batch of batches) {
    const memoriesText = batch.map((m, i) => `${i + 1}. [${m.tag}] ${m.content}`).join('\n')

    const prompt = `Evaluate the importance of each memory for an AI coach app. Rate each 0.0-1.0:

- 0.0-0.2: Trivial/temporary (e.g., "user had coffee today") â†’ DELETE
- 0.3-0.5: Some reference value but not critical â†’ SOFT DELETE
- 0.6-0.8: Important behavioral patterns â†’ KEEP
- 0.9-1.0: Core insights about user â†’ PERMANENT

Memories:
${memoriesText}

Output ONLY a JSON object with memory numbers as keys and scores as values:
{"1": 0.7, "2": 0.2, "3": 0.9}`

    try {
      const apiUrl = `${AZURE_ENDPOINT}/openai/v1/chat/completions`

      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${AZURE_API_KEY}`,
        },
        body: JSON.stringify({
          model: MODEL_NAME,
          messages: [
            { role: 'system', content: 'You are a memory importance evaluator. Output only valid JSON.' },
            { role: 'user', content: prompt }
          ],
          max_completion_tokens: 200,
          temperature: 0.1,
        }),
      })

      if (!response.ok) {
        console.error('Importance evaluation API error:', response.status)
        // å›é€€åˆ°åŸå§‹åˆ†æ•°
        for (const m of batch) {
          results.set(m.memory_id, m.importance_score)
        }
        continue
      }

      const result = await response.json()
      const content = result.choices?.[0]?.message?.content?.trim()

      if (content) {
        const scores = JSON.parse(content)
        for (let i = 0; i < batch.length; i++) {
          const score = scores[String(i + 1)]
          if (typeof score === 'number' && score >= 0 && score <= 1) {
            results.set(batch[i].memory_id, score)
          } else {
            results.set(batch[i].memory_id, batch[i].importance_score)
          }
        }
      }
    } catch (error) {
      console.error('Importance evaluation failed:', error)
      for (const m of batch) {
        results.set(m.memory_id, m.importance_score)
      }
    }
  }

  return results
}

/**
 * ä½¿ç”¨ LLM åˆ¤æ–­ä¸¤æ¡è®°å¿†æ˜¯å¦çŸ›ç›¾
 * è¿”å›: 'keep_newer' | 'keep_older' | 'merge' | 'keep_both'
 */
async function analyzeContradiction(
  content1: string,
  content2: string,
  tag: string
): Promise<{ action: 'keep_newer' | 'keep_older' | 'merge' | 'keep_both'; merged?: string }> {
  if (!AZURE_API_KEY) {
    // æ²¡æœ‰ API keyï¼Œé»˜è®¤ä¿ç•™è¾ƒæ–°çš„
    return { action: 'keep_newer' }
  }

  const prompt = `Analyze if these two memories about a user contradict each other:

Memory 1 (older): "${content1}"
Memory 2 (newer): "${content2}"
Category: ${tag}

Determine:
1. Are they contradictory? (e.g., "likes blue" vs "likes green")
2. Or complementary/additive? (e.g., "likes blue" and "also likes reading")
3. Or is one just an update of the other?

Output JSON:
{
  "action": "keep_newer" | "keep_older" | "merge" | "keep_both",
  "reason": "brief explanation",
  "merged": "merged content if action is merge"
}`

  try {
    const apiUrl = `${AZURE_ENDPOINT}/openai/v1/chat/completions`

    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${AZURE_API_KEY}`,
      },
      body: JSON.stringify({
        model: MODEL_NAME,
        messages: [
          { role: 'system', content: 'You are analyzing user memories for contradictions. Output only valid JSON.' },
          { role: 'user', content: prompt }
        ],
        max_completion_tokens: 300,
        temperature: 0.1,
      }),
    })

    if (!response.ok) {
      return { action: 'keep_newer' }
    }

    const result = await response.json()
    const content = result.choices?.[0]?.message?.content?.trim()

    if (content) {
      const parsed = JSON.parse(content)
      return {
        action: parsed.action || 'keep_newer',
        merged: parsed.merged,
      }
    }

    return { action: 'keep_newer' }
  } catch (error) {
    console.error('Contradiction analysis failed:', error)
    return { action: 'keep_newer' }
  }
}

/**
 * è§£å†³ç”¨æˆ·çš„çŸ›ç›¾è®°å¿†
 */
async function resolveContradictions(
  supabase: ReturnType<typeof createClient>,
  userId: string
): Promise<number> {
  let resolved = 0

  // è·å–æ½œåœ¨çŸ›ç›¾è®°å¿†å¯¹
  const { data: contradictions, error } = await supabase.rpc('find_potential_contradictions', {
    p_user_id: userId,
    p_similarity_threshold: 0.7,
    p_limit: 20,
  })

  if (error || !contradictions || contradictions.length === 0) {
    return 0
  }

  console.log(`ğŸ” å‘ç° ${contradictions.length} å¯¹æ½œåœ¨çŸ›ç›¾è®°å¿†`)

  for (const pair of contradictions as ContradictionPair[]) {
    const analysis = await analyzeContradiction(pair.content_1, pair.content_2, pair.tag)

    switch (analysis.action) {
      case 'keep_newer':
        // æ ‡è®°æ—§è®°å¿†ä¸ºè¢«æ›¿ä»£
        await supabase.rpc('supersede_memory', {
          p_old_memory_id: pair.memory_id_1,
          p_new_memory_id: pair.memory_id_2,
        })
        resolved++
        console.log(`âœ… ä¿ç•™è¾ƒæ–°è®°å¿†ï¼Œæ—§è®°å¿†è¢«æ›¿ä»£`)
        break

      case 'keep_older':
        // æ ‡è®°æ–°è®°å¿†ä¸ºè¢«æ›¿ä»£
        await supabase.rpc('supersede_memory', {
          p_old_memory_id: pair.memory_id_2,
          p_new_memory_id: pair.memory_id_1,
        })
        resolved++
        console.log(`âœ… ä¿ç•™è¾ƒæ—§è®°å¿†ï¼Œæ–°è®°å¿†è¢«æ›¿ä»£`)
        break

      case 'merge':
        // åˆå¹¶ä¸¤æ¡è®°å¿†
        if (analysis.merged) {
          // æ›´æ–°è¾ƒæ–°çš„è®°å¿†ä¸ºåˆå¹¶ç‰ˆæœ¬
          await supabase
            .from('user_memories')
            .update({
              content: analysis.merged,
              merged_from: [pair.memory_id_1],
              metadata: {
                mergedAt: new Date().toISOString(),
                originalContents: [pair.content_1, pair.content_2],
              },
            })
            .eq('id', pair.memory_id_2)

          // æ ‡è®°æ—§è®°å¿†ä¸ºå‹ç¼©
          await supabase
            .from('user_memories')
            .update({
              compression_status: 'compressed',
              superseded_by: pair.memory_id_2,
            })
            .eq('id', pair.memory_id_1)

          resolved++
          console.log(`âœ… åˆå¹¶ä¸¤æ¡è®°å¿†`)
        }
        break

      case 'keep_both':
        // ä¸åšå¤„ç†
        console.log(`â„¹ï¸ ä¿ç•™ä¸¤æ¡è®°å¿†ï¼ˆéçŸ›ç›¾ï¼‰`)
        break
    }
  }

  return resolved
}

/**
 * å‹ç¼©å•ä¸ªç”¨æˆ·çš„ä½ä»·å€¼è®°å¿†
 */
async function compressUserMemories(
  supabase: ReturnType<typeof createClient>,
  userId: string
): Promise<{ evaluated: number; deleted: number; compressed: number; contradictions: number }> {
  const stats = { evaluated: 0, deleted: 0, compressed: 0, contradictions: 0 }

  // 1. è§£å†³çŸ›ç›¾è®°å¿†
  stats.contradictions = await resolveContradictions(supabase, userId)

  // 2. è·å–å‹ç¼©å€™é€‰
  const { data: candidates, error } = await supabase.rpc('get_compression_candidates', {
    p_user_id: userId,
    p_min_age_days: MIN_AGE_DAYS,
    p_low_importance_threshold: LOW_IMPORTANCE_THRESHOLD,
    p_limit: BATCH_SIZE,
  })

  if (error) {
    console.error(`è·å–å‹ç¼©å€™é€‰å¤±è´¥ (user=${userId}):`, error)
    return stats
  }

  if (!candidates || candidates.length === 0) {
    console.log(`ç”¨æˆ· ${userId} æ²¡æœ‰éœ€è¦å‹ç¼©çš„è®°å¿†`)
    return stats
  }

  stats.evaluated = candidates.length
  console.log(`ğŸ“‹ è¯„ä¼° ${candidates.length} æ¡å€™é€‰è®°å¿†`)

  // 3. LLM è¯„ä¼°é‡è¦æ€§
  const importanceScores = await evaluateImportance(candidates as CompressionCandidate[])

  // 4. æ ¹æ®è¯„ä¼°ç»“æœåˆ†ç±»å¤„ç†
  const toDelete: string[] = []
  const toCompress: string[] = []

  for (const candidate of candidates as CompressionCandidate[]) {
    const newScore = importanceScores.get(candidate.memory_id) ?? candidate.importance_score

    if (newScore < 0.2) {
      // æä½ä»·å€¼ â†’ åˆ é™¤
      toDelete.push(candidate.memory_id)
    } else if (newScore < 0.4) {
      // ä½ä»·å€¼ â†’ è½¯åˆ é™¤ï¼ˆå‹ç¼©ï¼‰
      toCompress.push(candidate.memory_id)
    }
    // å¦åˆ™ä¿ç•™

    // æ›´æ–° importance_score
    if (newScore !== candidate.importance_score) {
      await supabase
        .from('user_memories')
        .update({ importance_score: newScore })
        .eq('id', candidate.memory_id)
    }
  }

  // 5. æ‰§è¡Œå‹ç¼©æ“ä½œ
  if (toDelete.length > 0) {
    const { data: deletedCount } = await supabase.rpc('mark_memories_compressed', {
      p_memory_ids: toDelete,
      p_action: 'delete',
    })
    stats.deleted = deletedCount || toDelete.length
    console.log(`ğŸ—‘ï¸ åˆ é™¤ ${stats.deleted} æ¡ä½ä»·å€¼è®°å¿†`)
  }

  if (toCompress.length > 0) {
    const { data: compressedCount } = await supabase.rpc('mark_memories_compressed', {
      p_memory_ids: toCompress,
      p_action: 'compress',
    })
    stats.compressed = compressedCount || toCompress.length
    console.log(`ğŸ“¦ å‹ç¼© ${stats.compressed} æ¡è®°å¿†`)
  }

  return stats
}

/**
 * å‹ç¼©æ‰€æœ‰ç”¨æˆ·çš„è®°å¿†
 */
async function compressAllUsers(
  supabase: ReturnType<typeof createClient>
): Promise<CompressionStats> {
  const stats: CompressionStats = {
    usersProcessed: 0,
    totalEvaluated: 0,
    totalDeleted: 0,
    totalCompressed: 0,
    contradictionsResolved: 0,
    errors: [],
  }

  // è·å–æœ‰è®°å¿†çš„æ´»è·ƒç”¨æˆ·
  const { data: users, error } = await supabase
    .from('user_memories')
    .select('user_id')
    .eq('compression_status', 'active')
    .order('updated_at', { ascending: true })
    .limit(MAX_USERS_PER_RUN)

  if (error) {
    stats.errors.push(`è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: ${error.message}`)
    return stats
  }

  // å»é‡ç”¨æˆ· ID
  const uniqueUserIds = [...new Set((users || []).map(u => u.user_id))]
  console.log(`ğŸ“Š å¼€å§‹å¤„ç† ${uniqueUserIds.length} ä¸ªç”¨æˆ·çš„è®°å¿†å‹ç¼©`)

  for (const userId of uniqueUserIds) {
    try {
      console.log(`\nğŸ‘¤ å¤„ç†ç”¨æˆ·: ${userId}`)
      const userStats = await compressUserMemories(supabase, userId)

      stats.usersProcessed++
      stats.totalEvaluated += userStats.evaluated
      stats.totalDeleted += userStats.deleted
      stats.totalCompressed += userStats.compressed
      stats.contradictionsResolved += userStats.contradictions
    } catch (error) {
      const errorMsg = `ç”¨æˆ· ${userId} å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`
      console.error(errorMsg)
      stats.errors.push(errorMsg)
    }
  }

  return stats
}

serve(async (req) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  try {
    // åˆå§‹åŒ– Supabase client
    const supabaseUrl = Deno.env.get('SUPABASE_URL')!
    const supabaseServiceKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    const supabase = createClient(supabaseUrl, supabaseServiceKey)

    const body = await req.json()
    const { action, userId } = body

    console.log(`ğŸš€ Memory Compressor å¯åŠ¨: action=${action}`)

    let result: CompressionStats | { evaluated: number; deleted: number; compressed: number; contradictions: number }

    switch (action) {
      case 'compress_all':
        // å‹ç¼©æ‰€æœ‰ç”¨æˆ·ï¼ˆcron è°ƒç”¨ï¼‰
        result = await compressAllUsers(supabase)
        break

      case 'compress_user': {
        // å‹ç¼©å•ä¸ªç”¨æˆ·
        if (!userId) {
          throw new Error('Missing userId for compress_user action')
        }
        const userStats = await compressUserMemories(supabase, userId)
        result = userStats
        break
      }

      default:
        throw new Error(`Unknown action: ${action}`)
    }

    console.log(`âœ… Memory Compressor å®Œæˆ:`, result)

    return new Response(
      JSON.stringify(result),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  } catch (error) {
    console.error('Memory Compressor error:', error)
    return new Response(
      JSON.stringify({ error: error instanceof Error ? error.message : String(error) }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  }
})
